Topic,Count,Name,Representation,Representative_Docs
-1,18188,-1_neural_brain_cognitive_neurons,"['neural', 'brain', 'cognitive', 'neurons', 'computational', 'experiments', 'experimental', 'processing', 'analysis', 'visual']","[""Spatio-temporal pattern analysis of single-trial EEG signals recorded during visual object recognition Object discrimination is a fundamental cognitive function for human brains. In this study, we utilized an analysis approach for single-trial electroencephalography (EEG) to analyze the spatio-temporal activation patterns of visual objects processing in human brains, and attempted to apply it to discriminate different visual objects. The spatial patterns were respectively extracted from scalp EEG and the reconstructed cortical sources, while the experiment participants were perceiving 4 different categories of visual objects (faces, buildings, cats and cars). By classifying the patterns extracted from single-trial EEG, the presented visual objects could be discriminated by a computer, and the classification accuracies may provide a quantitative index to evaluate the spatial differences of the brain activations related to different visual objects. Our results demonstrated that the spatial patterns on both the scalp and the sources levels resulted in higher classification accuracies than chance rate. We also examined the classification results using temporally non-overlapping time intervals of different event-related potential (ERP) components. The temporal changes of classification accuracies may reflect the temporal distribution of the discriminative information in the EEG responses. The present pattern extraction and classification methods may compose a computational model for single-trial EEG data analysis in investigations of the spatio-temporal activation patterns for object recognition. These spatio-temporal patterns in EEG may be useful to identifying the discriminative spatial areas and time stages to improve the accuracies and efficiencies of object discrimination. In addition, investigating and utilizing humans' cognitive mechanisms of object recognition may improve computers' processing efficiency of visual information."", 'Multi-Center Brain Imaging Classification Using a Novel 3D CNN Approach With the development of brain imaging technology, increasing amounts of magnetic resonance imaging data are being acquired, and traditional computational analysis methods based on single sites and small samples are facing substantial challenges. Deep learning technology, which is born via artificial intelligence, has shown the powerful ability to solve the classification problem based on big data in many studies, while it has not been widely used in brain imaging classification. Herein, we utilized our proposed novel 3-D deep adding neural network to classify 6008 samples from the largest data sets in the brain imaging field collected from more than 61 centers. The proposed method utilizes multiple convolutional layers to extract gradient information in different orientations and combines spatial information at two scales via the adding operation. High accuracy (over 92.5%) was obtained with a standard fivefold cross-validation strategy, demonstrating that the proposed method can effectively handle big data classifications from multiple centers. Compared with some traditional classification methods and some deep learning architectures, the proposed method was more accurate, demonstrating its stronger power to classify data from multiple centers. Our cross-site classification results prove that the proposed method is robust when training on a data set and testing on another data set. To the best of our knowledge, this paper is the first to classify neuroimaging data on such a large scale from multiple centers with such high accuracy. With its improved performance in classification and transferable program codes, the proposed method can potentially be used in intelligent medical treatment strategies and clinical practices based on mobile terminal.', 'Brain-computer interface analysis of a dynamic visuo-motor task Results: The results have shown that the EEG signals measured during the dVM tasks carry enough information about the subjects&apos; wrist movements for them to be successfully decoded using the presented methodology. Reasonably high values of the correlation coefficients suggest that the validation of the proposed approach is satisfactory. Moreover, since the causality of the rhythm filtering and the PCA transformation has been achieved, we have shown that these methods can also be used in a real-time, brain-computer interface. The study revealed that using non-causal, optimized methods yields better prediction results in comparison with the causal, non-optimized methodology; however, taking into account that the causality of these methods allows real-time processing, the minor decrease in prediction quality is acceptable. Materials and methods: For the case of this study two types of measurements were performed, i.e., the electroencephalographic (EEG) signals and the wrist movements were measured simultaneously, during the subject&apos;s performance of a dynamic visuo-motor task. Wrist-movement predictions were computed by using the EEG data-processing methodology of double brain-rhythm filtering, double phase demodulation and double principal component analyses (PCA), each with a separate set of parameters. For the movement-prediction model a fuzzy inference system was used. Objective: In this paper the authors would like to present a continuation of their previous work on the brain-information-decoding analysis of visuo-motor (VM) tasks. The present study shows that EEG data measured during more complex, dynamic visuo-motor (dVM) tasks carries enough information about the currently performed motor action to be successfully extracted by using the appropriate signal-processing and identification methods. The aim of this paper is therefore to present a mathematical model, which by means of the EEG measurements as its inputs predicts the course of the wrist movements as applied by each subject during the task in simulated or real time (BCI analysis). However, several modifications to the existing methodology are needed to achieve optimal decoding results and a real-time, data-processing ability. The information extracted from the EEG could, therefore, be further used for the development of a closed-loop, non-invasive, brain-computer interface. Background: The area of brain-computer interfaces (BCIs) represents one of the more interesting fields in neurophysiological research, since it investigates the development of the machines that perform different transformations of the brain&apos;s """"thoughts"""" to certain pre-defined actions. Experimental studies have reported some successful implementations of BC&apos;s; however, much of the field still remains unexplored. According to some recent reports the phase coding of informational content is an important mechanism in the brain&apos;s function and cognition, and has the potential to explain various mechanisms of the brain&apos;s data transfer, but it has yet to be scrutinized in the context of brain-computer interface. Therefore, if the mechanism of phase coding is plausible, one should be able to extract the phase-coded content, carried by brain signals, using appropriate signal-processing methods. In our previous studies we have shown that by using a phase-demodulation-based signal-processing approach it is possible to decode some relevant information on the current motor action in the brain from electroencephalographic (EEG) data. Conclusion: The study suggests that the methodology that was proposed in our previous studies is also valid for identifying the EEG-coded content during dVM tasks, albeit with various modifications, which allow better prediction results and real-time data processing. The results have shown that wrist movements can be predicted in simulated or real time; however, the results of the non-causal, optimized methodology (simulated) are slightly better. Nevertheless, the study has revealed that these methods should be suitable for use in the development of a non-invasive, brain-computer interface. (C) 2010 Elsevier B.V. All rights reserved.']"
0,1249,0_fuzzy_neural_algorithms_systems,"['fuzzy', 'neural', 'algorithms', 'systems', 'algorithm', 'adaptive', 'system', 'intuitionistic', 'stochastic', 'rough']","['A fuzzy neural network with fuzzy impact grades Fuzzy rule derivation is often difficult and time-consuming, and requires expert knowledge. This creates a common bottleneck in fuzzy system design. In order to solve this problem, many fuzzy systems that automatically generate fuzzy rules from numerical data have been proposed. in this paper, we propose a fuzzy neural network based on mutual subsethood (MSBFNN) and its fuzzy rule identification algorithms. In our approach, fuzzy rules are described by different fuzzy sets. For each fuzzy set representing a fuzzy rule, the universe of discourse is defined as the summation of weighted membership grades of input linguistic terms that associate with the given fuzzy rule. In this manner, MSBFNN fully considers the contribution of input variables to the joint firing strength of fuzzy rules. Afterwards, the proposed fuzzy neural network quantifies the impacts of fuzzy rules on the consequent parts by fuzzy connections based on mutual subsethood. Furthermore, to enhance the knowledge representation and interpretation of the rules, a linear transformation from consequent parts to output is incorporated into MSBFNN so that higher accuracy can be achieved. In the parameter identification phase, the backpropagation algorithm is employed, and proper linear transformation is also determined dynamically. To demonstrate the capability of the MSBFNN, simulations in different areas including classification, regression and time series prediction are conducted. The proposed MSBFNN shows encouraging performance when benchmarked against other models. (C) 2009 Elsevier B.V. All rights reserved.', 'FUZZY-SYSTEMS AS UNIVERSAL APPROXIMATORS An additive fuzzy system can uniformly approximate any real continuous function on a compact domain to any degree of accuracy.  An additive fuzzy system approximates the function by covering its graph with fuzzy patches in the input-output state space and averaging patches that overlap.  The fuzzy system computes a conditional expectation E[Y \\ X] if we view the fuzzy sets as random sets.  Each fuzzy rule defines a fuzzy patch and connects commonsense knowledge with state-space geometry.  Neural or statistical clustering systems can approximate the unknown fuzzy patches from training data.  These adaptive fuzzy systems approximate a function at two levels.  At the local level the neural system approximates and tunes the fuzzy rules.  At the global level the rules or patches approximate the function.', ""A multi-layer fuzzy model based on fuzzy-rule clustering for prediction tasks Fuzzy systems are widely used for solving complex and non-linear problems that cannot be addressed using precise mathematical models. Their performance, however, is critically affected by how they are constructed as well as their fuzzy rule base. Inspired by neural networks that apply a multi-layer structure to improve their performance, we propose a multi-layer fuzzy model with modified fuzzy rules to improve the approximation ability of fuzzy systems without losing efficiency. In practical applications, the fuzzy rule base extracted from numerical data is often incomplete, which makes a fuzzy system less robust. To address this problem, a non-linear function is used as the consequent of each fuzzy rule based on fuzzy-rule clustering to enhance the approximation ability of the fuzzy rule base. In addition, exact matching of fuzzy rules is employed based on the fuzzy rule's antecedent for prediction. By doing so, only one rule will be triggered in each layer, which is very efficient. Experimental results from two simulated functions and three practical applications confirm that our proposed multi-layer fuzzy model can outperform other well-established fuzzy models in terms of accuracy and robustness without sacrificing efficiency. (C) 2020 Elsevier B.V. All rights reserved.""]"
1,971,1_neurodegenerative_dopaminergic_brain_disorder,"['neurodegenerative', 'dopaminergic', 'brain', 'disorder', 'pd', 'disorders', 'dopamine', 'diagnostic', 'lateral', 'disease']","[""A computerized method to assess Parkinson's disease severity from gait variability based on gender Parkinson's disease (PD) is related to dopaminergic neuronal loss and it is progressive. Although there is no available cure for the disease yet, symptom-based treatments are available. PD can be clinically misdiagnosed in early stages because motor features become evident long after the onset of neuronal loss. Therefore, different remote monitoring tests were studied by the scholars for early detection. It has shown that people with PD exhibit gait variability with respect to healthy subjects. In this study, gait signals of PD patients were analyzed to detect severity of PD. Gait signals were converted to fuzzy recurrence plots and deep features were extracted. Machine learning techniques were applied to perform several classification experiments. Binary classifications to discriminate PD patients and multiclass classifications to predict the disease severity based on gender were conducted. Experimental results were assessed with different performance metrics. In PD severity prediction, gender based classification tests produced better performances than the test involving all cases. Proposed system produced state of the art results. The system estimated the disease severity with 1.00 and 0.99 accuracies for females and males respectively."", ""Detecting Sensitive Mobility Features for Parkinson's Disease Stages Via Machine Learning Background: It is not clear how specific gait measures reflect disease severity across the disease spectrum in Parkinson's disease (PD). Conclusions: Applying machine-learning to multiple, wearable-derived features reveals that different measures of gait and mobility are associated with and discriminate distinct stages of PD. These disparate feature sets can augment the objective monitoring of disease progression and may be useful for cohort selection and power analyses in clinical trials of PD. (c) 2021 International Parkinson and Movement Disorder Society Methods: Cross-sectional wearable-sensor records were collected in 332 patients with PD (Hoehn and Yahr scale I-III) and 100 age-matched healthy controls. Sensors were adhered to the participant's lower back, bilateral ankles, and wrists. Study participants walked in a similar to 15-meter corridor for 1 minute under two walking conditions: (1) preferred, usual walking speed and (2) walking while engaging in a cognitive task (dual-task). A subgroup (n = 303, 67% PD) also performed the Timed Up and Go test. Multiple machine-learning feature selection and classification algorithms were applied to discriminate between controls and PD and between the different PD severity stages. Objective: To identify the gait and mobility measures that are most sensitive and reflective of PD motor stages and determine the optimal sensor location in each disease stage. Results: High discriminatory values were found between motor disease stages with mean sensitivity in the range 72%-83%, specificity 69%-80%, and area under the curve (AUC) 0.76-0.90. Measures from upper-limb sensors best discriminated controls from early PD, turning measures obtained from the trunk sensor were prominent in mid-stage PD, and stride timing and regularity were discriminative in more advanced stages."", ""A low-cost vision system based on the analysis of motor features for recognition and severity rating of Parkinson's Disease Background Assessment and rating of Parkinson's Disease (PD) are commonly based on the medical observation of several clinical manifestations, including the analysis of motor activities. In particular, medical specialists refer to the MDS-UPDRS (Movement Disorder Society - sponsored revision of Unified Parkinson's Disease Rating Scale) that is the most widely used clinical scale for PD rating. However, clinical scales rely on the observation of some subtle motor phenomena that are either difficult to capture with human eyes or could be misclassified. This limitation motivated several researchers to develop intelligent systems based on machine learning algorithms able to automatically recognize the PD. Nevertheless, most of the previous studies investigated the classification between healthy subjects and PD patients without considering the automatic rating of different levels of severity. Methods In this context, we implemented a simple and low-cost clinical tool that can extract postural and kinematic features with the Microsoft Kinect v2 sensor in order to classify and rate PD. Thirty participants were enrolled for the purpose of the present study: sixteen PD patients rated according to MDS-UPDRS and fourteen healthy paired subjects. In order to investigate the motor abilities of the upper and lower body, we acquired and analyzed three main motor tasks: (1) gait, (2) finger tapping, and (3) foot tapping. After preliminary feature selection, different classifiers based on Support Vector Machine (SVM) and Artificial Neural Networks (ANN) were trained and evaluated for the best solution. Results Concerning the gait analysis, results showed that the ANN classifier performed the best by reaching 89.4% of accuracy with only nine features in diagnosis PD and 95.0% of accuracy with only six features in rating PD severity. Regarding the finger and foot tapping analysis, results showed that an SVM using the extracted features was able to classify healthy subjects versus PD patients with great performances by reaching 87.1% of accuracy. The results of the classification between mild and moderate PD patients indicated that the foot tapping features were the most representative ones to discriminate (81.0% of accuracy). Conclusions The results of this study have shown how a low-cost vision-based system can automatically detect subtle phenomena featuring the PD. Our findings suggest that the proposed tool can support medical specialists in the assessment and rating of PD patients in a real clinical scenario.""]"
2,879,2_epilepsy_epileptic_epileptogenic_seizures,"['epilepsy', 'epileptic', 'epileptogenic', 'seizures', 'epileptiform', 'seizure', 'electroencephalogram', 'electroencephalography', 'brain', 'intracranial']","['Epileptic seizure detection on EEG signals using machine learning techniques and advanced preprocessing methods Electroencephalography (EEG) is a common tool used for the detection of epileptic seizures. However, the visual analysis of long-term EEG recordings is characterized by its subjectivity, time-consuming procedure and its erroneous detection. Various epileptic seizure detection algorithms have been proposed to deal with such issues. In this study, a novel automatic seizure-detection approach is proposed. Three different strategies are suggested to the user whereby he/she could choose the appropriate one for a given classification problem. Indeed, the feature extraction step, including both linear and nonlinear measures, is performed either directly from the EEG signals, or from the derived sub-bands of tunable-Q wavelet transform (TQWT), or even from the intrinsic mode functions (IMFs) of multivariate empirical mode decomposition (MEMD). The classification procedure is executed using a support vector machine (SVM). The performance of the proposed method is evaluated through a publicly available database from which six binary classification cases are formulated to discriminate between healthy, seizure and non-seizure EEG signals. Our results show high performance in terms of accuracy (ACC), sensitivity (SEN) and specificity (SPE) compared to the state-of-the-art approaches. Thus, the proposed approach for automatic seizure detection can be considered as a valuable alternative to existing methods, able to alleviate the overload of visual analysis and accelerate the seizure detection.', 'A Unified Framework and Method for EEG-Based Early Epileptic Seizure Detection and Epilepsy Diagnosis Electroencephalogram (EEG) contains important physiological information that can reflect the activity of human brain, making it useful for epileptic seizure detection and epilepsy diagnosis. However visual inspection of large amounts of EEG by human expert is time-consuming, and meanwhile there are often inconsistences in judgement between physicians. In this paper, we develop a unified framework for early epileptic seizure detection and epilepsy diagnosis, which includes two phases. In the first phase, the signal intensity is first calculated for each data point of the given EEG, enabling the well-known autoregressive moving average (ARMA) model to characterize the dynamic behavior of the EEG time series. The residual error between the predicted value of learned ARMA model and the actually observed value is used as the anomaly score to support a null hypothesis testing for making epileptic seizure decision. The epileptic seizure detection phase can provide a quick detection for anomaly EEG patterns, but the resulting suspicious segment may include epilepsy or other disordering EEG activities thus required to be identified. Therefore, in the second phase, we use pattern recognition technique to classify the suspicious EEG segments. In particular, we propose a new and practical classifier based on a pairwise of one-class SVMs for epilepsy diagnosis. The proposed classifier requires normal and epilepsy data for training, but can recognize normal, epilepsy and even other disorders that would not be trained in the training samples. This point is practical and meaningful in real clinic scenarios as the input EEG may include other brain disordering diseases besides of epilepsy. We conducted experiments on the publicly-available Bern-Barcelona and CHB-MIT EEG database, respectively, to validate the effectiveness of the proposed framework, and our method achieved classification accuracy of 93% and 94% on them. Comprehensive experimental results, outperforming the state-of-the-arts, suggest its great potentials in real applications.', 'Optimized deep neural network architecture for robust detection of epileptic seizures using EEG signals Conclusions: We demonstrate the clinical feasibility of our seizure detection approach achieving superior performance over the cutting-edge techniques in terms of seizure detection performance and robustness. Significance: Our seizure detection approach can contribute to accurate and robust detection of epileptic seizures in ideal and real-life situations. (C) 2018 International Federation of Clinical Neurophysiology. Published by Elsevier B.V. All rights reserved. Methods: A deep Long Short-Term Memory (LSTM) network is first used to learn the high-level representations of different EEG patterns. Then, a Fully Connected (FC) layer is adopted to extract the most robust EEG features relevant to epileptic seizures. Finally, these features are supplied to a softmax layer to output predicted labels. Objective: Automatic detection of epileptic seizures based on deep learning methods received much attention last year. However, the potential of deep neural networks in seizure detection has not been fully exploited in terms of the optimal design of the model architecture and the detection power of the time-series brain data. In this work, a deep neural network architecture is introduced to learn the temporal dependencies in Electroencephalogram (EEG) data for robust detection of epileptic seizures. Results: The results on a benchmark clinical dataset reveal the prevalence of the proposed approach over the baseline techniques; achieving 100% classification accuracy, 100% sensitivity, and 100% specificity. Our approach is additionally shown to be robust in noisy and real-life conditions. It maintains high detection performance in the existence of common EEG artifacts (muscle activities and eye movement) as well as background noise.']"
3,858,3_faces_face_facial_recognition,"['faces', 'face', 'facial', 'recognition', 'pose', 'biometrics', 'biometric', 'features', 'images', 'model']","['A multi-task model for simultaneous face identification and facial expression recognition Regarded as two independent tasks, both face identification and facial expression recognition perform poorly given small size training sets. To address this problem, we propose a multi-task facial inference model (MT-FIM) for simultaneous face identification and facial expression recognition. In particular, face identification and facial expression recognition are learnt simultaneously by extracting and utilizing appropriate shared information across them in the framework of multi-task learning, in which the shared information refers to the parameter controlling the sparsity. MT-FIM simultaneously minimizes the within-class scatter and maximizes the distance between different classes to enable the robust performance of each individual task. We conduct comprehensive experiments on three face image databases. The experimental results show that our algorithm outperforms the state-of-the-art algorithms. (C) 2015 Elsevier B.V. All rights reserved.', ""Face recognition using part-based dense sampling local features For years, researchers have made great efforts to find an appropriate face representation for face recognition. A fusion strategy of Local Binary Pattern (LBP) and Gabor filters yields great achievements. LBP is good at coding fine details of facial appearance and texture, whereas Gabor features can encode facial shape and appearance over a range of coarser scales. Despite the great performance, this fusion representation suffers from low effectiveness and resolution variance. In this paper, we propose a novel representation strategy of face images which is fast and robust to resolution variance. We apply dense sampling around each detected feature point, extract Local Difference Feature (LDF),for face representation, then utilize Principal Component Analysis (PCA)+Linear Discriminant Analysis (LDA) to reduce feature dimension and finally use cosine similarity evaluation for recognition. We have utilized our proposed face representation strategy on two databases, namely self-collected Second Generation ID Card of China and Driver's License (SGIDCDL) database and public Facial Recognition Technology (FERET) database. Our experimental results show that the proposed strategy has good performance on face recognition with fast speed. (C) 2015 Elsevier B.V. All rights reserved."", ""A New Virtual Samples-Based CRC Method for Face Recognition The research of automatic face recognition has attracted much attention from many researchers because of human faces' uniqueness and usability. However, in the real-world applications, the acquisition equipment of face images is affected by illumination changes, facial expression variations, different postures and other environment factors, resulting in limited number of face images collected. This situation has become an obstacle to the development of face recognition technology. Therefore, in this paper, we utilize the information of the left-half face and right-half face to generate respectively two virtual 'axis-symmetrical' face images from an original face image and adopt collaborative representation based classification method (CRC) to perform classification. The first and second virtual face images convey more information of the right-half face and left-half face, respectively. Experiments have been performed on the Extended Yale_B, ORL, AR and FERET face databases and the experimental results show that our method can improve the recognition accuracy effectively.""]"
4,806,4_tumors_tumor_malignant_glioblastoma,"['tumors', 'tumor', 'malignant', 'glioblastoma', 'cancer', 'imaging', 'tumour', 'glioma', 'mri', 'prognosis']","[""Application of deep learning for automatic segmentation of brain tumors on magnetic resonance imaging: a heuristic approach in the clinical scenario Purpose Accurate brain tumor segmentation on magnetic resonance imaging (MRI) has wide-ranging applications such as radiosurgery planning. Advances in artificial intelligence, especially deep learning (DL), allow development of automatic segmentation that overcome the labor-intensive and operator-dependent manual segmentation. We aimed to evaluate the accuracy of the top-performing DL model from the 2018 Brain Tumor Segmentation (BraTS) challenge, the impact of missing MRI sequences, and whether a model trained on gliomas can accurately segment other brain tumor types. Methods We trained the model using Medical Decathlon dataset, applied it to the BraTS 2019 glioma dataset, and developed additional models using individual and multimodal MRI sequences. The Dice score was calculated to assess the model's accuracy compared to ground truth labels by neuroradiologists on BraTS dataset. The model was then applied to a local dataset of 105 brain tumors, performance of which was qualitatively evaluated. Results The DL model using pre- and post-gadolinium contrast T1 and T2 FLAIR sequences performed best, with a Dice score 0.878 for whole tumor, 0.732 tumor core, and 0.699 active tumor. Lack of T1 or T2 sequences did not significantly degrade performance, but FLAIR and T1C were important contributors. All segmentations performed by the model in the local dataset, including non-glioma cases, were considered accurate by a pool of specialists. Conclusion The DL model could use available MRI sequences to optimize glioma segmentation and adopt transfer learning to segment non-glioma tumors, thereby serving as a useful tool to improve treatment planning and personalized surveillance of patients."", ""Brain tumor segmentation and grading of lower-grade glioma using deep learning in MRI images Gliomas are the most common malignant brain tumors with different grades that highly determine the rate of survival in patients. Tumor segmentation and grading using magnetic resonance imaging (MRI) are common and essential for diagnosis and treatment planning. To achieve this clinical need, a deep learning approach that combines convolutional neural networks (CNN) based on the U-net for tumor segmentation and transfer learning based on a pre-trained convolution-base of Vgg16 and a fully connected classifier for tumor grading was developed. The segmentation and grading models use the same pipeline of T1-precontrast, fluid attenuated inversion recovery (FLAIR), and T1-postcontrast MRI images of 110 patients of lower-grade glioma (LGG) for training and evaluations. The mean dice similarity coefficient (DSC) and tumor detection accuracy achieved by the segmentation model are 0.84 and 0.92, respectively. The grading model classifies LGG into grade II and grade III with accuracy, sensitivity, and specificity of 0.89, 0.87, and 0.92, respectively at the MRI images' level and 0.95, 0.97, and 0.98 at the patients' level. This work demonstrates the potential of using deep learning in MRI images to provide a non-invasive tool for simultaneous and automated tumor segmentation, detection, and grading of LGG for clinical applications."", ""A Novel Approach for Fully Automatic Intra-Tumor Segmentation With 3D U-Net Architecture for Gliomas Materials and Methods: In this study, we have designed a novel 3D U-Net architecture that segments various radiologically identifiable sub-regions like edema, enhancing tumor, and necrosis. Weighted patch extraction scheme from the tumor border regions is proposed to address the problem of class imbalance between tumor and non-tumorous patches. The architecture consists of a contracting path to capture context and the symmetric expanding path that enables precise localization. The Deep Convolutional Neural Network (DCNN) based architecture is trained on 285 patients, validated on 66 patients and tested on 191 patients with Glioma from Brain Tumor Segmentation (BraTS) 2018 challenge dataset. Three dimensional patches are extracted from multi-channel BraTS training dataset to train 3D U-Net architecture. The efficacy of the proposed approach is also tested on an independent dataset of 40 patients with High Grade Glioma from our tertiary cancer center. Segmentation results are assessed in terms of Dice Score, Sensitivity, Specificity, and Hausdorff 95 distance (ITCN intra-tumoral classification network). Result: Our proposed architecture achieved Dice scores of 0.88, 0.83, and 0.75 for the whole tumor, tumor core and enhancing tumor, respectively, on BraTS validation dataset and 0.85, 0.77, 0.67 on test dataset. The results were similar on the independent patients' dataset from our hospital, achieving Dice scores of 0.92, 0.90, and 0.81 for the whole tumor, tumor core and enhancing tumor, respectively. Purpose: Gliomas are the most common primary brain malignancies, with varying degrees of aggressiveness and prognosis. Understanding of tumor biology and intra-tumor heterogeneity is necessary for planning personalized therapy and predicting response to therapy. Accurate tumoral and intra-tumoral segmentation on MRI is the first step toward understanding the tumor biology through computational methods. The purpose of this study was to design a segmentation algorithm and evaluate its performance on pre-treatment brain MRIs obtained from patients with gliomas. Conclusion: The results of this study show the potential of patch-based 3D U-Net for the accurate intra-tumor segmentation. From experiments, it is observed that the weighted patch-based segmentation approach gives comparable performance with the pixel-based approach when there is a thin boundary between tumor subparts.""]"
5,786,5_stroke_rehabilitation_robotics_robotic,"['stroke', 'rehabilitation', 'robotics', 'robotic', 'treadmill', 'wrist', 'assistive', 'robot', 'exercises', 'exoskeletons']","['Effects of robot-assisted therapy on upper limb recovery after stroke: A systematic review Objective. The aim of the study was to present a systematic review of studies that investigate the effects of robot-assisted therapy on motor and functional recovery in patients with stroke. Methods. A database of articles published up to October 2006 was compiled using the following Medline key words: cerebral vascular accident, cerebral vascular disorders, stroke, paresis, hemiplegia, upper extremity, arm, and robot. References listed in relevant publications were also screened. Studies that satisfied the following selection criteria were included: (1) patients were diagnosed with cerebral vascular accident; (2) effects of robot-assisted therapy for the upper limb were investigated; (3) the outcome was measured in terms of motor and/or functional recovery of the upper paretic limb; and (4) the study was a randomized clinical trial (RCT). For each outcome measure, the estimated effect size (ES) and the summary effect size (SES) expressed in standard deviation units (SDU) were calculated for motor recovery and functional ability (activities of daily living [ADLs]) using fixed and random effect models. Ten studies, involving 218 patients, were included in the synthesis. Their methodological quality ranged from 4 to 8 on a (maximum) 10-point scale. Results. Meta-analysis showed a nonsignificant heterogeneous SES in terms of upper limb motor recovery. Sensitivity analysis of studies involving only shoulder-elbow robotics subsequently demonstrated a significant homogeneous SES for motor recovery of the upper paretic limb. No significant SES was observed for functional ability (ADL). Conclusion. As a result of marked heterogeneity in studies between distal and proximal arm robotics, no overall significant effect in favor of robot-assisted therapy was found in the present meta-analysis. However, subsequent sensitivity analysis showed a significant improvement in upper limb motor function after stroke for upper arm robotics. No significant improvement was found in ADL function. However, the administered ADL scales in the reviewed studies fail to adequately reflect recovery of the paretic upper limb, whereas valid instruments that measure outcome of dexterity of the paretic arm and hand are mostly absent in selected studies. Future research into the effects of robot-assisted therapy should therefore distinguish between upper and lower robotics arm training and concentrate on kinematical analysis to differentiate between genuine upper limb motor recovery and functional recovery due to compensation strategies by proximal control of the trunk and upper limb.', 'Exoskeleton-Robot Assisted Therapy in Stroke Patients: A Lesion Mapping Study Background: Technology-supported rehabilitation is emerging as a solution to support therapists in providing a high-intensity, repetitive and task-specific treatment, aimed at improving stroke recovery. End-effector robotic devices are known to positively affect the recovery of arm functions, however there is a lack of evidence regarding exoskeletons. This paper evaluates the impact of cerebral lesion load on the response to a validated robotic-assisted rehabilitation protocol. Methods: Fourteen hemiparetic patients were assessed in a within-subject design (age 66.9 +/- 11.3 years; 10 men and 4 women). Patients, in post-acute phase, underwent 7 weeks of bilateral arm training assisted by an exoskeleton robot combined with a conventional treatment (consisting of simple physical activity together with occupational therapy). Clinical and neuroimaging evaluations were performed immediately before and after rehabilitation treatments. Fugl-Meyer (FM) and Motricity Index (MI) were selected to measure primary outcomes, i.e., motor function and strength. Functional independance measure (FIM) and Barthel Index were selected to measure secondary outcomes, i.e., daily living activities. Voxel-based lesion symptom mapping (VLSM) was used to determine the degree of cerebral lesions associated with motor recovery. Results: Robot-assisted rehabilitation was effective in improving upper limb motor function recovery, considering both primary and secondary outcomes. VLSM detected that lesion load in the superior region of the corona radiata, internal capsule and putamen were significantly associated with recovery of the upper limb as defined by the FM scores (p-level < 0.01). Conclusions: The probability of functional recovery from stroke by means of exoskeleton robotic rehabilitation relies on the integrity of specific subcortical regions involved in the primary motor pathway. This is consistent with previous evidence obtained with conventional neurorehabilitation approaches.', 'Effects of robot-assisted upper limb rehabilitation in stroke patients: a systematic review with meta-analysis Technology-supported training is emerging as a solution to support therapists in their efforts providing high-intensity, repetitive, and task-specific treatment, in order to enhance the recovery process. The aim of this review is to assess the effectiveness of different robotic devices (end-effector and exoskeleton robots) in comparison with any other type of intervention. Furthermore, we aim to assess whether or not better improvements are obtained in the sub-acute phase after stroke onset than in the chronic phase. A research was conducted in the electronic bibliographic databases Cochrane, MEDLINE, and EMBASE. A total of 17 studies were included: 14 randomized controlled trials, 2 systematic reviews, and one meta-analysis. Fugl-Meyer and modified Ashworth scale were selected to measure primary outcomes, i.e., motor function and muscle tone. Functional independence measure and motor activity log were selected to measure secondary outcomes, i.e., activities of daily living. In comparison with conventional therapy, the robot-assisted rehabilitation is more effective in improving upper limb motor function recovery, especially in chronic stroke patients. No significant improvements are observed in the reduction of muscle tone or daily living activities. The present systematic review shows that the use of robotic devices can positively affect the recovery of arm function in patients with stroke.']"
6,712,6_alzheimer_dementia_amyloid_cognitive,"['alzheimer', 'dementia', 'amyloid', 'cognitive', 'neurodegenerative', 'neuroimaging', 'hippocampal', 'hippocampus', 'brain', 'cognitively']","[""Automated Detection of Alzheimer's Disease and Mild Cognitive Impairment Using Whole Brain MRI Early diagnosis is critical for the development and success of interventions, and neuroimaging is one of the most promising areas for early detection of Alzheimer's disease (AD). This study is aimed to develop a deep learning method to extract valuable AD biomarkers from structural magnetic resonance imaging (sMRI) and classify brain images into AD, mild cognitive impairment (MCI), and cognitively normal (CN) groups. In this work, we adapted and trained convolutional neural networks (CNNs) on sMRI images of the brain from ADNI datasets available in online databases. Our proposed mechanism was used to combine features from different layers to hierarchically transform the images from magnetic resonance imaging into more compact high-level features. The proposed method has a reduced number of parameters which reduces the computation complexity. The method is compared with the existing state-of-the-art works for AD classification, which show superior results for the widely used evaluation metrics, including accuracy, an area under the ROC curve, etc., suggesting that our proposed convolution operation is suitable for the AD diagnosis"", ""A parameter-efficient deep learning approach to predict conversion from mild cognitive impairment to Alzheimer's disease Our approach is flexible and can in principle integrate other imaging modalities, such as PET, and diverse other sets of clinical data. The convolutional framework is potentially applicable to any 3D image dataset and gives the flexibility to design a computer-aided diagnosis system targeting the prediction of several medical conditions and neuropsychiatric disorders via multi-modal imaging and tabular clinical data. The most predictive combination of inputs were the structural MRI images and the demographic, neuropsychological, and APOe4 data. In contrast, the warp field metrics were of little added predictive value. The algorithm was able to distinguish the MCI patients developing AD within 3 years from those patients with stable MCI over the same time-period with an area under the curve (AUC) of 0.925 and a 10-fold cross-validated accuracy of 86%, a sensitivity of 87.5%, and specificity of 85%. To our knowledge, this is the highest performance achieved so far using similar datasets. The same network provided an AUC of 1 and 100% accuracy, sensitivity, and specificity when classifying patients with AD from healthy controls. Our classification framework was also robust to the use of different co-registration templates and potentially irrelevant features/image portions. Some forms of mild cognitive impairment (MCI) are the clinical precursors of Alzheimer's disease (AD), while other MCI types tend to remain stable over-time and do not progress to AD. To identify and choose effective and personalized strategies to prevent or slow the progression of AD, we need to develop objective measures that are able to discriminate the MCI patients who are at risk of AD from those MCI patients who have less risk to develop AD. Here, we present a novel deep learning architecture, based on dual learning and an ad hoc layer for 3D separable convolutions, which aims at identifying MCI patients who have a high likelihood of developing AD within 3 years. Our deep learning procedures combine structural magnetic resonance imaging (MRI), demographic, neuropsychological, and APOe4 genetic data as input measures. The most novel characteristics of our machine learning model compared to previous ones are the following: 1) our deep learning model is multi-tasking, in the sense that it jointly learns to simultaneously predict both MCI to AD conversion as well as AD vs. healthy controls classification, which facilitates relevant feature extraction for AD prognostication; 2) the neural network classifier employs fewer parameters than other deep learning architectures which significantly limits data-overfitting (we use similar to 550,000 network parameters, which is orders of magnitude lower than other network designs); 3) both structural MRI images and their warp field characteristics, which quantify local volumetric changes in relation to the MRI template, were used as separate input streams to extract as much information as possible from the MRI data. All analyses were performed on a subset of the database made publicly available via the Alzheimer's Disease Neuroimaging Initiative (ADNI), (n = 785 participants, n = 192 AD patients, n = 409 MCI patients (including both MCI patients who convert to AD and MCI patients who do not covert to AD), and n = 184 healthy controls)."", ""A multi-model deep convolutional neural network for automatic hippocampus segmentation and classification in Alzheimer's disease Alzheimer's disease (AD) is a progressive and irreversible brain degenerative disorder. Mild cognitive impairment (MCI) is a clinical precursor of AD. Although some treatments can delay its progression, no effective cures are available for AD. Accurate early-stage diagnosis of AD is vital for the prevention and intervention of the disease progression. Hippocampus is one of the first affected brain regions in AD. To help AD diagnosis, the shape and volume of the hippocampus are often measured using structural magnetic resonance imaging (MRI). However, these features encode limited information and may suffer from segmentation errors. Additionally, the extraction of these features is independent of the classification model, which could result in sub-optimal performance. In this study, we propose a multi-model deep learning framework based on convolutional neural network (CNN) for joint automatic hippocampal segmentation and AD classification using structural MRI data. Firstly, a multi-task deep CNN model is constructed for jointly learning hippocampal segmentation and disease classification. Then, we construct a 3D Densely Connected Convolutional Networks (3D DenseNet) to learn features of the 3D patches extracted based on the hippocampal segmentation results for the classification task. Finally, the learned features from the multi-task CNN and DenseNet models are combined to classify disease status. Our method is evaluated on the baseline T1-weighted structural MRI data collected from 97 AD, 233 MCI, 119 Normal Control (NC) subjects in the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The proposed method achieves a dice similarity coefficient of 87.0% for hippocampal segmentation. In addition, the proposed method achieves an accuracy of 88.9% and an AUC (area under the ROC curve) of 92.5% for classifying AD vs. NC subjects, and an accuracy of 76.2% and an AUC of 77.5% for classifying MCI vs. NC subjects. Our empirical study also demonstrates that the proposed multi-model method outperforms the single-model methods and several other competing methods.""]"
7,668,7_vector_vectors_svms_minimization,"['vector', 'vectors', 'svms', 'minimization', 'svr', 'lssvm', 'regression', 'optimization', 'algorithms', 'algorithm']","['Adaptive pruning algorithm for least squares support vector machine classifier As a new version of support vector machine (SVM), least squares SVM (LS-SVM) involves equality instead of inequality constraints and works with a least squares cost function. A well-known drawback in the LS-SVM applications is that the sparseness is lost. In this paper, we develop an adaptive pruning algorithm based on the bottom-to-top strategy, which can deal with this drawback. In the proposed algorithm, the incremental and decremental learning procedures are used alternately and a small support vector set, which can cover most of the information in the training set, can be formed adaptively. Using this set, one can construct the final classifier. In general, the number of the elements in the support vector set is much smaller than that in the training set and a sparse solution is obtained. In order to test the efficiency of the proposed algorithm, we apply it to eight UCI datasets and one benchmarking dataset. The experimental results show that the presented algorithm can obtain adaptively the sparse solutions with losing a little generalization performance for the classification problems with no-noises or noises, and its training speed is much faster than sequential minimal optimization algorithm (SMO) for the large-scale classification problems with no-noises.', 'Improved sparse least-squares support vector machine classifiers The least-squares support vector machines (LS-SVM) can be obtained by solving a simpler optimization problem than that in standard support vector machines (SVM). Its shortcoming is the loss of sparseness and this usually results in slow testing speed. Several pruning methods have been proposed. It is found that these methods can be further improved for classification problems. In this paper a different reduced training set is selected to re-train LS-SVM. Then a new procedure is proposed to obtain the sparseness. The performance of the proposed method is compared with other typical ones and the results indicate that it is more effective. (c) 2006 Elsevier B.V. All rights reserved.', 'Functional iterative approaches for solving support vector classification problems based on generalized Huber loss Classical support vector machine (SVM) and its twin variant twin support vector machine (TWSVM) utilize the Hinge loss that shows linear behaviour, whereas the least squares version of SVM (LSSVM) and twin least squares support vector machine (LSTSVM) uses L-2-norm of error which shows quadratic growth. The robust Huber loss function is considered as the generalization of Hinge loss and L-2-norm loss that behaves like the quadratic L-2-norm loss for closer error points and the linear Hinge loss after a specified distance. Three functional iterative approaches based on generalized Huber loss function are proposed in this paper to solve support vector classification problems of which one is based on SVM, i.e. generalized Huber support vector machine and the other two are in the spirit of TWSVM, namely generalized Huber twin support vector machine and regularization on generalized Huber twin support vector machine. The proposed approaches iteratively find the solutions and eliminate the requirements to solve any quadratic programming problem (QPP) as for SVM and TWSVM. The main advantages of the proposed approach are: firstly, utilize the robust Huber loss function for better generalization and for lesser sensitivity towards noise and outliers as compared to quadratic loss; secondly, it uses functional iterative scheme to find the solution that eliminates the need to solving QPP and also makes the proposed approaches faster. The efficacy of the proposed approach is established by performing numerical experiments on several real-world datasets and comparing the result with related methods, viz. SVM, TWSVM, LSSVM and LSTSVM. The classification results are convincing.']"
8,666,8_brain_devices_electroencephalogram_algorithm,"['brain', 'devices', 'electroencephalogram', 'algorithm', 'stimulus', 'computer', 'stimuli', 'mental', 'interfaces', 'interface']","['Benefits of deep learning classification of continuous noninvasive brain-computer interface control Objective. Noninvasive brain-computer interfaces (BCIs) assist paralyzed patients by providing access to the world without requiring surgical intervention. Prior work has suggested that EEG motor imagery based BCI can benefit from increased decoding accuracy through the application of deep learning methods, such as convolutional neural networks (CNNs). Approach. Here, we examine whether these improvements can generalize to practical scenarios such as continuous control tasks (as opposed to prior work reporting one classification per trial), whether valuable information remains latent outside of the motor cortex (as no prior work has compared full scalp coverage to motor only electrode montages), and the existing challenges to the practical implementation of deep-learning based continuous BCI control. Main results. We report that: (1) deep learning methods significantly increase offline performance compared to standard methods on an independent, large, and longitudinal online motor imagery BCI dataset with up to 4-classes and continuous 2D feedback; (2) our results suggest that a variety of neural biomarkers for BCI, including those outside the motor cortex, can be detected and used to improve performance through deep learning methods, and (3) tuning neural network output will be an important step in optimizing online BCI control, as we found the CNN models trained with full scalp EEG also significantly reduce the average trial length in a simulated online cursor control environment. Significance. This work demonstrates the benefits of CNNs classification during BCI control while providing evidence that electrode montage selection and the mapping of CNN output to device control will be important design choices in CNN based BCIs.', ""An artificial intelligence that increases simulated brain-computer interface performance Objective. Brain-computer interfaces (BCIs) translate neural activity into control signals for assistive devices in order to help people with motor disabilities communicate effectively. In this work, we introduce a new BCI architecture that improves control of a BCI computer cursor to type on a virtual keyboard. Approach. Our BCI architecture incorporates an external artificial intelligence (AI) that beneficially augments the movement trajectories of the BCI. This AI-BCI leverages past user actions, at both long (100 s of seconds ago) and short (100 s of milliseconds ago) timescales, to modify the BCI's trajectories. Main results. We tested our AI-BCI in a closed-loop BCI simulator with nine human subjects performing a typing task. We demonstrate that our AI-BCI achieves: (1) categorically higher information communication rates, (2) quicker ballistic movements between targets, (3) improved precision control to 'dial in' on targets, and (4) more efficient movement trajectories. We further show that our AI-BCI increases performance across a wide control quality spectrum from poor to proficient control. Significance. This AI-BCI architecture, by increasing BCI performance across all key metrics evaluated, may increase the clinical viability of BCI systems."", ""A 1D CNN for high accuracy classification and transfer learning in motor imagery EEG-based brain-computer interface Objective. Brain-computer interface (BCI) aims to establish communication paths between the brain processes and external devices. Different methods have been used to extract human intentions from electroencephalography (EEG) recordings. Those based on motor imagery (MI) seem to have a great potential for future applications. These approaches rely on the extraction of EEG distinctive patterns during imagined movements. Techniques able to extract patterns from raw signals represent an important target for BCI as they do not need labor-intensive data pre-processing. Approach. We propose a new approach based on a 10-layer one-dimensional convolution neural network (1D-CNN) to classify five brain states (four MI classes plus a 'baseline' class) using a data augmentation algorithm and a limited number of EEG channels. In addition, we present a transfer learning method used to extract critical features from the EEG group dataset and then to customize the model to the single individual by training its late layers with only 12-min individual-related data. Main results. The model tested with the 'EEG Motor Movement/Imagery Dataset' outperforms the current state-of-the-art models by achieving a 99.38% <i accuracy at the group level. In addition, the transfer learning approach we present achieves an average accuracy of 99.46% Significance. The proposed methods could foster the development of future BCI applications relying on few-channel portable recording devices and individual-based training.""]"
9,618,9_emotions_emotion_emotional_affective,"['emotions', 'emotion', 'emotional', 'affective', 'stimuli', 'electroencephalogram', 'neural', 'electroencephalography', 'recognition', 'brain']","['Emotional state classification from EEG data using machine learning approach Recently, emotion classification from EEG data has attracted much attention with the rapid development of dry electrode techniques, machine learning algorithms, and various real-world applications of brain-computer interface for normal people. Until now, however, researchers had little understanding of the details of relationship between different emotional states and various EEG features. To improve the accuracy of EEG-based emotion classification and visualize the changes of emotional states with time, this paper systematically compares three kinds of existing EEG features for emotion classification, introduces an efficient feature smoothing method for removing the noise unrelated to emotion task, and proposes a simple approach to tracking the trajectory of emotion changes with manifold learning. To examine the effectiveness of these methods introduced in this paper, we design a movie induction experiment that spontaneously leads subjects to real emotional states and collect an EEG data set of six subjects. From experimental results on our EEG data set, we found that (a) power spectrum feature is superior to other two kinds of features; (b) a linear dynamic system based feature smoothing method can significantly improve emotion classification accuracy; and (c) the trajectory of emotion changes can be visualized by reducing subject-independent features with manifold learning. (C) 2013 Elsevier B.V. All rights reserved.', 'Interpretable Emotion Recognition Using EEG Signals Electroencephalogram (EEG) signal-based emotion recognition has attracted wide interests in recent years and has been broadly adopted in medical, affective computing, and other relevant fields. However, the majority of the research reported in this field tends to focus on the accuracy of classification whilst neglecting the interpretability of emotion progression. In this paper, we propose a new interpretable emotion recognition approach with the activation mechanism by using machine learning and EEG signals. This paper innovatively proposes the emotional activation curve to demonstrate the activation process of emotions. The algorithm first extracts features from EEG signals and classifies emotions using machine learning techniques, in which different parts of a trial are used to train the proposed model and assess its impact on emotion recognition results. Second, novel activation curves of emotions are constructed based on the classification results, and two emotion coefficients, i.e., the correlation coefficients and entropy coefficients. The activation curve can not only classify emotions but also reveals to a certain extent the emotional activation mechanism. Finally, a weight coefficient is obtained from the two coefficients to improve the accuracy of emotion recognition. To validate the proposed method, experiments have been carried out on the DEAP and SEED dataset. The results support the point that emotions are progressively activated throughout the experiment, and the weighting coefficients based on the correlation coefficient and the entropy coefficient can effectively improve the EEG-based emotion recognition accuracy.', ""Improving BCI-based emotion recognition by combining EEG feature selection and kernel classifiers Current emotion recognition computational techniques have been successful on associating the emotional changes with the EEG signals, and so they can be identified and classified from EEG signals if appropriate stimuli are applied. However, automatic recognition is usually restricted to a small number of emotions classes mainly due to signal's features and noise, EEG constraints and subject-dependent issues. In order to address these issues, in this paper a novel feature-based emotion recognition model is proposed for EEG based Brain-Computer Interfaces. Unlike other approaches, our method explores a wider set of emotion types and incorporates additional features which are relevant for signal pre-processing and recognition classification tasks, based on a dimensional model of emotions: Valence and Arousal. It aims to improve the accuracy of the emotion classification task by combining mutual information based feature selection methods and kernel classifiers. Experiments using our approach for emotion classification which combines efficient feature selection methods and efficient kernel-based classifiers on standard EEG datasets show the promise of the approach when compared with state-of-the-art computational methods. (C) 2015 Elsevier Ltd. All rights reserved.""]"
10,588,10_sleepiness_sleep_wakefulness_circadian,"['sleepiness', 'sleep', 'wakefulness', 'circadian', 'insomnia', 'wake', 'night', 'sensitivity', 'accuracy', 'analysis']","['A Residual Based Attention Model for EEG Based Sleep Staging Sleep staging is to score the sleep state of a subject into different sleep stages such as Wake and Rapid Eye Movement (REM). It plays an indispensable role in the diagnosis and treatment of sleep disorders. As manual sleep staging through well-trained sleep experts is time consuming, tedious, and subjective, many automatic methods have been developed for accurate, efficient, and objective sleep staging. Recently, deep learning based methods have been successfully proposed for electroencephalogram (EEG) based sleep staging with promising results. However, most of these methods directly take EEG raw signals as input of convolutional neural networks (CNNs) without considering the domain knowledge of EEG staging. Apart from that, to capture temporal information, most of the existing methods utilize recurrent neural networks such as LSTM (Long Short Term Memory) which are not effective for modelling global temporal context and difficult to train. Therefore, inspired by the clinical guidelines of sleep staging such as AASM (American Academy of Sleep Medicine) rules where different stages are generally characterized by EEG waveforms of various frequencies, we propose a multi-scale deep architecture by decomposing an EEG signal into different frequency bands as input to CNNs. To model global temporal context, we utilize the multi-head self-attention module of the transformer model to not only improve performance, but also shorten the training time. In addition, we choose residual based architecture which makes training end-to-end. Experimental results on two widely used sleep staging datasets, Montreal Archive of Sleep Studies (MASS) and sleep-EDF datasets, demonstrate the effectiveness and significant efficiency (up to 12 times less training time) of our proposed method over the state-of-the-art.', ""A Method for Sleep Quality Analysis Based on CNN Ensemble With Implementation in a Portable Wireless Device The quality of sleep can be affected by the occurrence of a sleep related disorder and, among these disorders, obstructive sleep apnea is commonly undiagnosed. Polysomnography is considered to be the gold standard for sleep analysis. However, it is an expensive and labor-intensive exam that is unavailable to a large group of the world population. To address these issues, the main goal of this work was to develop an automatic scoring algorithm to analyze the single-lead electrocardiogram signal, performing a minute-by-minute and an overall estimation of both quality of sleep and obstructive sleep apnea. The method employs a cross-spectral coherence technique which produces a spectrographic image that fed three one-dimensional convolutional neural networks for the classification ensemble. The predicted quality of sleep was based on the electroencephalogram cyclic alternating pattern rate, a sleep stability metric. Two methods were developed to indirectly evaluate this metric, creating two sleep quality predictions that were combined with the sleep apnea diagnosis to achieve the final global sleep quality estimation. It was verified that the quality of sleep of the nineteen tested subjects was correctly identified by the proposed model, advocating the significance of clinical analysis. The model was implemented in a non-invasive and simple to self-assemble device, producing a tool that can estimate the quality of sleep and diagnose the obstructive sleep apnea at the patient's home without requiring the attendance of a specialized technician. Therefore, increasing the accessibility of the population to sleep analysis."", ""Transfer Learning Convolutional Neural Network for Sleep Stage Classification Using Two-Stage Data Fusion Framework The most important part of sleep quality assessment is the classification of sleep stages, which helps to diagnose sleep-related disease. In the traditional sleep staging method, subjects have to spend a night in the sleep clinic for recording polysomnogram. Sleep expert classifies the sleep stages by monitoring the signals, which is time consuming and frustrating task and can be affected by human error. New studies propose fully automated techniques for classifying sleep stages that makes sleep scoring possible at home. Despite comprehensive studies have been presented in this field the classification results have not yet reached the gold standard due to the concentration on the use of a limited source of information such as single channel EEG. Therefore, this article introduces a new method for fusing two sources of information, including electroencephalogram (EEG) and electrooculogram (EOG), to achieve promising results in the classification of sleep stages. In the proposed method, extracted features from the EEG and EOG signals, are divided into two feature sets consisting of the EEG features and fused features of EEG and EOG. Then, each feature set transformed into a horizontal visibility graph (HVG). The images of the HVG are produced in a novel framework and classified by proposed transfer learning convolutional neural network for data fusion (TLCNN-DF). Employing transfer learning at the training stage of the model has accelerated the training process of the CNN and improved the performance of the model. The proposed algorithm is used to classify the Sleep-EDF and Sleep-EDFx benchmark datasets. The algorithm can classify the Sleep-EDF dataset with an accuracy of 93.58% and Cohen's kappa coefficient of 0.899. The results show proposed method can achieve superior performance compared to state-of-the-art studies on classification of sleep stages. Furthermore, it can attain reliable results as an alternative to conventional sleep staging.""]"
11,539,11_synchronization_stochastic_chaotic_delays,"['synchronization', 'stochastic', 'chaotic', 'delays', 'delay', 'adaptive', 'dynamical', 'stability', 'intermittent', 'delayed']","['Synchronization of memristive delayed neural networks via hybrid impulsive control Synchronization control problem is an important problem for the dynamical behaviors of neural networks. In this paper, by structuring hybrid impulsive and feedback controllers, synchronization problem of the memristive delayed neural networks is firstly promoted. Then, based on differential inclusions, several synchronization criteria for the memristive delayed neural networks are obtained by impulsive control theories, special inequalities and Lyapunov-type functional. In order to deduce synchronization conditions, the hybrid impulsive and feedback controllers are simultaneously used to control the memristive delayed neural networks, which promote and enrich the published results. Finally, the effectiveness of synchronization criteria is illustrated by two numerical examples. (c) 2017 Published by Elsevier B.V.', 'Finite-Time and Fixed-Time Synchronization of Coupled Memristive Neural Networks With Time Delay This article is devoted to analyzing the finite-time and fixed-time synchronization of coupled memristive neural networks with time delays. The synchronization is leaderless rather than leader-follower as the tracking targets are uncertain. By designing a proper controller and using the Lyapunov method, several sufficient conditions are obtained to achieve the finite-time and fixed-time synchronization of coupled memristive neural networks by introducing a class of special auxiliary matrices. Moreover, the settling times can be estimated for finite-time synchronization that depends on the initial values as well as fixed-time synchronization that is uniformly bounded for any initial values. Finally, two examples are presented to substantiate the effectiveness of the theoretical results.', 'New synchronization schemes for delayed chaotic neural networks with impulses This paper considers the exponential synchronization problem for chaotic neural networks with mixed delays and impulsive effects. The mixed delays include time-varying delays and unbounded distributed delays. Some delay-dependent schemes are designed to guarantee the exponential synchronization of the addressed systems by constructing suitable Lyapunov-Krasovskii functional and employing stability theory. The synchronization conditions are given in terms of LMIs, which can be easily checked via MATLAB LMI toolbox. Moreover, the synchronization conditions obtained are mild and more general than previously known criteria. Finally, two numerical examples and their simulations are given to show the effectiveness of the proposed chaos synchronization schemes.']"
12,535,12_algorithms_algorithm_optimization_gradient,"['algorithms', 'algorithm', 'optimization', 'gradient', 'neural', 'learning', 'training', 'adaptive', 'feedforward', 'trained']","['Improving the convergence of the backpropagation algorithm using learning rate adaptation methods This article focuses on gradient-based backpropagation algorithms that use either a common adaptive learning rate for all weights or an individual adaptive learning rate for each weight and apply the Goldstein/Armijo line search. The learning-rate adaptation is based on descent techniques and estimates of the local Lipschitz constant that are obtained without additional error function and gradient evaluations. The proposed algorithms improve the backpropagation training in terms of both convergence rate and convergence characteristics, such as stable learning and robustness to oscillations. Simulations are conducted to compare and evaluate the convergence behavior of these gradient-based training algorithms with several popular training methods.', 'A modified backpropagation training algorithm for feedforward neural networks In this paper, a new efficient learning procedure for training single hidden layer feedforward network is proposed. This procedure trains the output layer and the hidden layer separately. A new optimization criterion for the hidden layer is proposed. Existing methods to find fictitious teacher signal for the output of each hidden neuron, modified standard backpropagation algorithm and the new optimization criterion are combined to train the feedforward neural networks. The effectiveness of the proposed procedure is shown by the simulation results.', ""A non-iterative method for pruning hidden neurons in neural networks with random weights Neural networks with random weights have the advantage of fast computational time in both training and testing. However, one of the main challenges of single layer feedforward neural networks is the selection of the optimal number of neurons in the hidden layer, since few/many neurons lead to problems of underfitting/overfitting. Adapting Garson's algorithm, this paper introduces a new efficient and fast non-iterative algorithm for the selection of neurons in the hidden layer for randomization based neural networks. The proposed approach is divided into three steps: (1) train the network with h hidden neurons, (2) apply Garson's algorithm to the matrix of the hidden layer, and (3) perform pruning reducing hidden layer neurons based on the harmonic mean. Our experiments in regression and classification problems confirmed that the combination of the pruning technique with these types of neural networks improved their predictive performance in terms of mean square error and accuracy. Additionally, we tested our proposed pruning method with neural networks trained under sequential learning algorithms, where Random Vector Functional Link obtained, in general, the best predictive performance compared to online sequential versions of extreme learning machines and single hidden layer neural network with random weights. (C) 2018 Elsevier B.V. All rights reserved.""]"
13,524,13_elms_elm_learning_algorithms,"['elms', 'elm', 'learning', 'algorithms', 'algorithm', 'neural', 'experimental', 'machines', 'training', 'machine']","['Surface reconstruction based on extreme learning machine In this paper, extreme learning machine (ELM) is used to reconstruct a surface with a high speed. It is shown that an improved ELM, called polyharmonic extreme learning machine (P-ELM), is proposed to reconstruct a smoother surface with a high accuracy and robust stability. The proposed P-ELM improves ELM in the sense of adding a polynomial in the single-hidden-layer feedforward networks to approximate the unknown function of the surface. The proposed P-ELM can not only retain the advantages of ELM with an extremely high learning speed and a good generalization performance but also reflect the intrinsic properties of the reconstructed surface. The detailed comparisons of the P-ELM, RBF algorithm, and ELM are carried out in the simulation to show the good performances and the effectiveness of the proposed algorithm.', 'Genetic ensemble of extreme learning machine Extreme learning machine (ELM) was proposed as a new learning algorithm to train single-hidden-layer feedforward neural networks (SLFNs). ELM has been proven to perform in high efficiency, however, due to the random determination of parameters for hidden nodes, some un-optimal parameters may be generated to influence the generalization performance and stability. Moreover, ELM may suffer from overtraining problem as the entire training dataset is used to minimize training error. In this paper, a hybrid model is proposed to alleviate such weaknesses of ELM. The model adopts genetic algorithms (GAs) to produce a group of candidate networks first, and according to a specific ranking strategy, some of the networks are selected to ensemble a new network. To verify the performance of our method, empirical comparisons were carried out with the canonical ELM, E-ELM, simple ensemble, EE-ELM, EN-ELM, Bagging and Adaboost to solve both regression and classification problems. The results have shown that our method is able to generate more robust networks with better generalization performance. (C) 2013 Elsevier B.V. All rights reserved.', 'Extreme learning machine and its applications Recently, a novel learning algorithm for single-hidden-layer feedforward neural networks (SLFNs) named extreme learning machine (ELM) was proposed by Huang et al. The essence of ELM is that the learning parameters of hidden nodes, including input weights and biases, are randomly assigned and need not be tuned while the output weights can be analytically determined by the simple generalized inverse operation. The only parameter needed to be defined is the number of hidden nodes. Compared with other traditional learning algorithms for SLFNs, ELM provides extremely faster learning speed, better generalization performance and with least human intervention. This paper firstly introduces a brief review of ELM, describing the principle and algorithm of ELM. Then, we put emphasis on the improved methods or the typical variants of ELM, especially on incremental ELM, pruning ELM, error-minimized ELM, two-stage ELM, online sequential ELM, evolutionary ELM, voting-based ELM, ordinal ELM, fully complex ELM, and symmetric ELM. Next, the paper summarized the applications of ELM on classification, regression, function approximation, pattern recognition, forecasting and diagnosis, and so on. In the last, the paper discussed several open issues of ELM, which may be worthy of exploring in the future.']"
14,521,14_auditory_audiovisual_audio_speakers,"['auditory', 'audiovisual', 'audio', 'speakers', 'sound', 'sounds', 'hearing', 'vocal', 'noise', 'voice']","['Brain Prediction of Auditory Emphasis by Facial Expressions During Audiovisual Continuous Speech The visual cues involved in auditory speech processing are not restricted to information from lip movements but also include head or chin gestures and facial expressions such as eyebrow movements. The fact that visual gestures precede the auditory signal implicates that visual information may influence the auditory activity. As visual stimuli are very close in time to the auditory information for audiovisual syllables, the cortical response to them usually overlaps with that for the auditory stimulation; the neural dynamics underlying the visual facilitation for continuous speech therefore remain unclear. In this study, we used a three-word phrase to study continuous speech processing. We presented video clips with even (without emphasis) phrases as the frequent stimuli and with one word visually emphasized by the speaker as the non-frequent stimuli. Negativity in the resulting ERPs was detected after the start of the emphasizing articulatory movements but before the auditory stimulus, a finding that was confirmed by the statistical comparisons of the audiovisual and visual stimulation. No such negativity was present in the control visual-only condition. The propagation of this negativity was observed between the visual and fronto-temporal electrodes. Thus, in continuous speech, the visual modality evokes predictive coding for the auditory speech, which is analysed by the cerebral cortex in the context of the phrase even before the arrival of the corresponding auditory signal.', 'Time-frequency representations in speech perception Nowadays applications demand a comprehensive view of voice and speech perception to build more complex and competitive procedures amenable of extracting as much knowledge from sound-based human communication as possible. Many knowledge-extraction tasks from speech and voice may share signal treatment procedures which can be devised under the point of view of bio-inspiration. The present paper examines a hierarchy of sound processing functionalities at the auditory and perceptual levels on the Auditory Neural pathways which can be translated into bio-inspired speech-processing techniques, their fundamental characteristics being analyzed in relation with current tendencies in cognitive audio processing. The pathways linking the peripheral auditory system (cochlear complex) with the brain cortex are briefly examined, with special attention to the study of neuronal structures showing specific capabilities under the point of view of formant analysis and the build-up of a semantic hierarchy from the time-frequency structure of speech to explore their capability of conveying semantics to speech processing and understanding from the minimal acoustic clues with elementary meaning or """"sematoms"""". The replication of known biological functionality by algorithmic methods through bio-inspiration is a secondary aim of the research. Examples extracted from speech processing tasks in the domain of acoustic-phonetics are presented. These may find applicability in speech recognition, speaker\'s characterization and biometry, emotion detection, and others related. (C) 2008 Elsevier B.V. All rights reserved.', ""Analysis of music/speech via integration of audio content and functional brain response Effective analysis of music/speech data such as clustering, retrieval, and classification has received significant attention in recent years. Traditional methods mainly rely on the low-level acoustic features derived from digital audio stream, and the accuracy of these methods is limited by the well-known semantic gap. To alleviate this problem, we propose a novel framework for music/speech clustering, retrieval, and classification by integrating the low-level acoustic features derived from audio content with the functional magnetic resonance imaging (fMRI) measured features that represent the brain's functional response when subjects are listening to the music/speech excerpts. First, the brain networks and regions of interest (ROIs) involved in the comprehension of audio stimuli, such as the auditory, emotion, attention, and working memory systems, are located by a new approach named dense individualized and common connectivity-based cortical landmarks (DICC-COLs). Then the functional connectivity matrix measuring the similarity between the fMRI signals of different ROIs is adopted to represent the brain's comprehension of audio semantics. Afterwards, we propose an improved twin Gaussian process (ITGP) model based on self-training to predict the fMRI-measured features of testing data without fMRI scanning. Finally, multi-view learning algorithms are proposed to integrate acoustic features with fMRI-measured features for music/speech clustering, retrieval, and classification, respectively. The experimental results demonstrate the superiority of our proposed work in comparison with existing methods and suggest the advantage of integrating functional brain responses via fMRI data for music/speech analysis. (C) 2014 Elsevier Inc. All rights reserved.""]"
15,482,15_atlases_segmentation_atlas_segmentations,"['atlases', 'segmentation', 'atlas', 'segmentations', 'segmented', 'brain', 'brains', 'imaging', 'subcortical', 'datasets']","['Construction and validation of mean shape atlas templates for atlas-based brain image segmentation In this paper, we evaluate different schemes for constructing a mean shape anatomical atlas for atlas-based segmentation of MR brain images. Each atlas is constructed and validated using a database of 20 images for which detailed manual delineations of 49 different subcortical structures are available. Atlas construction and atlas based segmentation are performed by non-rigid intensity-based registration using a viscous fluid deformation model with parameters that were optimally tuned for this particular task. The segmentation performance of each atlas scheme is evaluated on the same database using a leave-one-out approach and measured by the volume overlap of corresponding regions in the ground-truth manual segmentation and the warped atlas label image.', 'Improving label fusion in multi-atlas based segmentation by locally combining atlas selection and performance estimation This paper presents a new label fusion method which is a local version of the SIMPLE method that has two advantages: when a large atlas set is available it improves the accuracy of label fusion and when this is not the case it gives the same accuracy as the original SIMPLE method, but with considerably fewer atlases. This is made possible by better utilizing the local information contained in propagated segmentations that would otherwise be discarded. Our method (semi-)automatically divides the propagated segmentations in multiple regions. A label fusion process can then be applied to each of these regions separately and the end result can be reconstructed out of multiple partial results. We demonstrate that the number of atlases needed can be reduced to 20 atlases without compromising segmentation quality. Our method is validated in an application to segmentation of the prostate, using an atlas set of 125 manually segmented images. (C) 2014 Elsevier Inc. All rights reserved. Multi-atlas based segmentation is a segmentation method that allows fully automatic segmentation of image populations that exhibit a large variability in shape and image quality. Fusing the results of multiple atlases makes this technique robust and reliable. Previously, we have presented the SIMPLE method for label fusion and have shown that it outperforms existing methods. However, the downside of this method is its computation time and the fact that it requires a large atlas set. This is not always a problem, but in some cases segmentation may be time-critical or large atlas sets are not available. In multi-atlas based segmentation, a target image is segmented by registering multiple atlas images to this target image and propagating the corresponding atlas segmentations. These propagated segmentations are then combined into a single segmentation in a process called label fusion.', 'A review of atlas-based segmentation for magnetic resonance brain images Normal and abnormal brains can be segmented by registering the target image with an atlas. Here, an atlas is defined as the combination of an intensity image (template) and its segmented image (the atlas labels). After registering the atlas template and the target image, the atlas labels are propagated to the target image. We define this process as atlas-based segmentation. In recent years, researchers have investigated registration algorithms to match atlases to query subjects and also strategies for atlas construction. In this paper we present a review of the automated approaches for atlas-based segmentation of magnetic resonance brain images. We aim to point out the strengths and weaknesses of atlas-based methods and suggest new research directions. We use two different criteria to present the methods. First, we refer to the algorithms according to their atlas-based strategy: label propagation, multi-atlas methods, and probabilistic techniques. Subsequently, we classify the methods according to their medical target: the brain and its internal structures, tissue segmentation in healthy subjects, tissue segmentation in fetus, neonates and elderly subjects, and segmentation of damaged brains. A quantitative comparison of the results reported in the literature is also presented. (C) 2011 Elsevier Ireland Ltd. All rights reserved.']"
16,463,16_stability_delays_delay_stochastic,"['stability', 'delays', 'delay', 'stochastic', 'multistability', 'delayed', 'periodic', 'neural', 'exponential', 'robust']","['Exponential stability analysis for neural networks with time-varying delay This correspondence paper focuses on the problem of exponential stability for neural networks with a time-varying delay. The relationship among the time-varying delay, its upper bound, and their difference is taken into account. As a result, an improved linear-matrix-inequality-based delay-dependent exponential stability criterion is obtained without ignoring any terms in the derivative of Lyapunov-Krasovskii functional. Two numerical examples are given to demonstrate its effectiveness.', 'New results for global exponential stability of neural networks with varying delays In this paper, the problem of global exponential stability for a class of neural networks with interval time-varying delay is investigated. The time-delay pattern is quite general and including fast time-varyings. It is assumed that the time delay belongs to a given interval, but the derivative of a time-varying delay be less than 1 is removed, or the delay function is not necessary to be differentiable. By constructing a set of improved Lyapunov-Krasovskii functionals combined with a known integral inequality, new delay-dependent exponential stability criteria with explicitly exponential convergence rate are established in terms of LMIs (linear matrix inequalities). The stability criteria are less conservative than the existing results in the literatures. Numerical examples are given to illustrate the effectiveness of the results. (c) 2012 Elsevier B.V. All rights reserved.', 'New Delay-Dependent Stability Criteria for Neural Networks With Time-Varying Delay Using Delay-Decomposition Approach This brief is concerned with the problem of asymptotic stability of neural networks with time-varying delays. The activation functions are monotone nondecreasing with known lower and upper bounds. Novel stability criteria are derived by employing new Lyapunov-Krasovskii functional and the integral inequality. The developed stability criteria have delay dependencies and the results are characterized by linear matrix inequalities. New and less conservative solutions to the global stability problem are provided in terms of feasibility testing. Numerical examples are finally given to demonstrate the effectiveness of the proposed method.']"
17,452,17_pain_neuralgia_painful_nerve,"['pain', 'neuralgia', 'painful', 'nerve', 'stimulation', 'analgesic', 'questionnaire', 'chronic', 'neuropathic', 'migraine']","[""Modeling Pain Using fMRI: From Regions to Biomarkers Pain is a subjective and complex phenomenon. Its complexity is related to its heterogeneity: multiple component processes, including sensation, affect, and cognition, contribute to pain experience and reporting. These components are likely to be encoded in distributed brain networks that interact to create pain experience and pain-related decision-making. Therefore, to understand pain, we must identify these networks and build models of these interactions that yield testable predictions about pain-related outcomes. We have developed several such models or 'signatures' of pain, by (1) integrating activity across multiple systems, and (2) using pattern-recognition to identify processes related to pain experience. One model, the Neurologic Pain Signature, is sensitive and specific to pain in individuals, involves brain regions that receive nociceptive afferents, and shows little effect of expectation or self-regulation in tests to date. Another, the 'Stimulus Intensity-Independent Pain Signature', explains substantial additional variation in trial-to-trial pain reports. It involves many brain regions that do not show increased activity in proportion to noxious stimulus intensity, including medial and lateral prefrontal cortex, nucleus accumbens, and hippocampus. Responses in this system mediate expectancy and perceived control effects in several studies. Overall, this approach provides a pathway to understanding pain by identifying multiple systems that track different aspects of pain. Such componential models can be combined in unique ways on a subject-by-subject basis to explain an individual's pain experience."", 'The Effectiveness of an Online Mind-Body Intervention for Older Adults With Chronic Pain Perspective: This article documents the outcomes of an Internet-based self-care pain management intervention that focused on mind-body exercises. The study suggests that the Internet can be an efficient mode for delivering self-care education to older adults with chronic pain and has potential benefits that complement clinical care. (C) 2009 by the American Pain Society The Self-care Pain Management Project assessed the feasibility and efficacy of delivering online mind-body self-care techniques to 78 adults aged 55 and older with chronic pain. To assess feasibility, the study monitored use of the intervention and documented participant satisfaction. A randomized trial with intervention (n = 41) and waiting list comparison groups (n = 37) was used to assess changes in pain intensity, limitations due to pain, pain self-efficacy, depression, anxiety, and awareness of responses to pain from baseline to follow-up at 6 weeks. There were statistically significant results for between-group difference in awareness of responses to pain, improvements in pain intensity and pain interference for both groups, and increases in confidence with using non-medical self-care techniques to manage pain for the intervention group. Reductions in mean pain scores reported by the intervention group at log on and log off also suggest that the intervention may have an immediate impact on reducing pain. Findings document the feasibility of a relatively short-term, online mind-body pain management intervention that can have benefits for participants. The characteristics of those who volunteered for an online self-care pain management intervention also have implications for identifying target populations for such interventions.', 'Magnetic resonance imaging for chronic pain: diagnosis, manipulation, and biomarkers Pain is a multidimensional subjective experience with biological, psychological, and social factors. Whereas acute pain can be a warning signal for the body to avoid excessive injury, long-term and ongoing pain may be developed as chronic pain. There are more than 100 million people in China living with chronic pain, which has raised a huge socioeconomic burden. Studying the mechanisms of pain and developing effective analgesia approaches are important for basic and clinical research. Recently, with the development of brain imaging and data analytical approaches, the neural mechanisms of chronic pain have been widely studied. In the first part of this review, we briefly introduced the magnetic resonance imaging and conventional analytical approaches for brain imaging data. Then, we reviewed brain alterations caused by several chronic pain disorders, including localized and widespread primary pain, primary headaches and orofacial pain, musculoskeletal pain, and neuropathic pain, and present meta-analytical results to show brain regions associated with the pathophysiology of chronic pain. Next, we reviewed brain changes induced by pain interventions, such as pharmacotherapy, neuromodulation, and acupuncture. Lastly, we reviewed emerging studies that combined advanced machine learning and neuroimaging techniques to identify diagnostic, prognostic, and predictive biomarkers in chronic pain patients.']"
18,442,18_adaptive_control_tracking_controller,"['adaptive', 'control', 'tracking', 'controller', 'nonlinear', 'dynamic', 'simulation', 'algorithm', 'dynamics', 'systems']","['Adaptive neural control of nonlinear MIMO systems with unknown time delays In this paper, a novel adaptive NN control scheme is proposed for a class of uncertain multi-input and multi-output (MIMO) nonlinear time-delay systems. RBF NNs are used to tackle unknown nonlinear functions, then the adaptive NN tracking controller is constructed by combining Lyapunov-Krasovskii functionals and the dynamic surface control (DSC) technique along with the minimal-learning-parameters (MLP) algorithm. The proposed controller guarantees uniform ultimate boundedness (UUB) of all the signals in the closed-loop system, while the tracking error converges to a small neighborhood of the origin. An advantage of the proposed control scheme lies in that the number of adaptive parameters for each subsystem is reduced to one, triple problems of """"explosion of complexity"""", """"curse of dimension"""" and """"controller singularity"""" are solved, respectively. Finally, a numerical simulation is presented to demonstrate the effectiveness and performance of the proposed scheme. (C) 2011 Elsevier B.V. All rights reserved.', 'Decentralized adaptive tracking control scheme for nonlinear large-scale interconnected systems via adaptive dynamic programming In this paper, the decentralized tracking problem for nonlinear large-scale interconnected systems is firstly transformed to optimal regulation problem for N augmented subsystems composed of the error system dynamics and the command generator dynamic associated with each isolated subsystems. The proposed novel formulation of decentralized adaptive tracking control strategy consists of a steady-state controller and a modified optimal feedback controller. Design parameters-dependent feasibility conditions are formulated by using Lyapunov theory to guarantee the existence of our proposed decentralized control scheme. A single critic neural network (NN)-based adaptive dynamic programming algorithm is used to find the estimation of optimal control policy, which is implemented online in real-time. By employing a stabilizing term in the critic NN weight updating law, there is no requirement for adopting initial admissible control in the proposed algorithm. Stability analysis of the closed-loop augmented subsystem is performed to show that all tracking errors and NN weight approximation errors are uniformly ultimately bounded (UUB). Furthermore, the approximated tracking control policy converges to the ideal control input with a small bounded error. Finally, the effectiveness of the proposed approach is demonstrated by some simulation results.', 'Neural-network-based output-feedback adaptive dynamic surface control for a class of stochastic nonlinear time-delay systems with unknown control directions This paper focuses on the problem of output-feedback adaptive stabilization for a class of stochastic nonlinear time-delay systems with unknown control directions. First, based on a linear state transformation, the unknown control coefficients are lumped together and the original system is transformed to a new system for which control design becomes feasible. Then, after the introduction of an observer, an adaptive neural network (NN) output-feedback control scheme is presented for such systems by using dynamic surface control (DSC) technique and Lyapunov-Krasovskii method. The designed controller ensures that all the signals in the closed-loop system are 4-Moment (or 2-Moment) semi-globally uniformly ultimately bounded. Finally, a numerical example is given to demonstrate the feasibility and effectiveness of the proposed control design. (C) 2013 Elsevier B.V. All rights reserved.']"
19,439,19_cognition_cognitive_neuroscience_consciousness,"['cognition', 'cognitive', 'neuroscience', 'consciousness', 'brain', 'neural', 'mental', 'cortex', 'psychology', 'conceptual']","['The rise of machine consciousness: Studying consciousness with computational models Efforts to create computational models of consciousness have accelerated over the last two decades, creating a field that has become known as artificial consciousness. There have been two main motivations for this controversial work: to develop a better scientific understanding of the nature of human/animal consciousness and to produce machines that genuinely exhibit conscious awareness. This review begins by briefly explaining some of the concepts and terminology used by investigators working on machine consciousness, and summarizes key neurobiological correlates of human consciousness that are particularly relevant to past computational studies. Models of consciousness developed over the last twenty years are then surveyed. These models are largely found to fall into five categories based on the fundamental issue that their developers have selected as being most central to consciousness: a global workspace, information integration, an internal self-model, higher-level representations, or attention mechanisms. For each of these five categories, an overview of past work is given, a representative example is presented in some detail to illustrate the approach, and comments are provided on the contributions and limitations of the methodology. Three conclusions are offered about the state of the field based on this review: (1) computational modeling has become an effective and accepted methodology for the scientific study of consciousness, (2) existing computational models have successfully captured a number of neurobiological, cognitive, and behavioral correlates of conscious information processing as machine simulations, and (3) no existing approach to artificial consciousness has presented a compelling demonstration of phenomenal machine consciousness, or even clear evidence that artificial phenomenal consciousness will eventually be possible. The paper concludes by discussing the importance of continuing work in this area, considering the ethical issues it raises, and making predictions concerning future developments. (C) 2013 Elsevier Ltd. All rights reserved.', 'What are the computational correlates of consciousness? Cognitive phenomenology refers to the idea that our subjective experiences include deliberative thought processes and high-level cognition. The recent ascendance of cognitive phenomenology in philosophy has important implications for biologically-inspired cognitive architectures and the role that these models can play in understanding the fundamental nature of consciousness. To the extent that cognitive phenomenology occurs, it provides a new route to a deeper understanding of consciousness via neurocomputational studies of cognition. This route involves identifying computational correlates of consciousness in neurocomputational models of high-level cognitive functions that are associated with subjective mental states. Here we develop this idea and compile a summary of potential neurocomputational correlates of consciousness that have been proposed/recognized during the last several years based on biologically-inspired cognitive architectures. We conclude that the identification and study of computational correlates of consciousness will lead to a better understanding of phenomenal consciousness, a framework for creating a conscious machine, and a better understanding of the mind-brain problem in general. (C) 2016 Elsevier B.V. All rights reserved.', 'Integrating a cognitive computational model of planning and decision-making considering affective information Planning and decision-making are two of the cognitive functions involved in the solution of problems. These functions, among others, have been studied from the point of view of a new field known as cognitive informatics focused on the development of cognitive architectures, autonomous agents, and human robots that are capable of showing human-like behavior. We present an exhaustive study of current biological and computational models proposed in the fields of neuroscience, psychology, and cognitive informatics. Also, we present a deep review of the brain areas involved in planning, decision-making, and affection. However, the majority of the proposed computational models are seeking to mimic human external behavior. This paper aims to contribute to the cognitive informatics field with an innovative cognitive computational model of planning and decision-making. The two main differences of our model with respect to the current models in the literature are: (i) our model considers affective and motivational information as a basic and essential trigger in planning and decision-making processes; (ii) our model attempts to mimic both the internal human brain as well as the external human behavior. We developed a computational model capable of offering a direct mapping from human brain areas to computational modules of our model. Thus, in this paper we present our model from a conceptual, formal, and computational approach in order to show how our proposal must be implemented. Finally, a set of tests were conducted in order to validate our proposal. These tests show an interesting comparison between the behavior of our prototype and the behavior exhibited by some people involved in a case study. (C) 2017 Elsevier B.V. All rights reserved.']"
20,421,20_autism_autistic_neurodevelopmental_disorder,"['autism', 'autistic', 'neurodevelopmental', 'disorder', 'disorders', 'asd', 'neurotypical', 'brain', 'developmental', 'child']","['Visual Attention Analysis and Prediction on Human Faces for Children with Autism Spectrum Disorder The focus of this article is to analyze and predict the visual attention of children with Autism Spectrum Disorder (ASD) when looking at human faces. Social difficulties are the hallmark features of ASD and will lead to atypical visual attention toward various stimuli more or less, especially on human faces. Learning the visual attention of children with ASD could contribute to related research in the field of medical science, psychology, and education. We first construct a Visual Attention on Faces for Autism Spectrum Disorder (VAFA) database, which consists of 300 natural scene images with human faces and corresponding eye movement data collected from 13 children with ASD. Compared with matched typically developing (TD) controls, we quantify atypical visual attention on human faces in ASD. Statistics show that some high-level factors such as face size, facial features, face pose, and facial emotions have different impacts on the visual attention of children with ASD. Combining the feature maps extracted from the state-of-the-art saliency models, we get the visual attention model on human faces for individuals with ASD. The proposed model shows the best performance among all competitors. With the help of our proposed model, researchers in related fields could design specialized education contents containing human faces for the children with ASD or produce the specific model for rapidly screening ASD using their eye movement data.', ""A review of methods for classification and recognition of ASD using fMRI data Autism spectrum disorder (ASD) is a severe neuropsychiatric brain disorder that affects people's social communication and daily routine. Considering the phenomenon of abnormal brain function in the early stage of ASD, functional magnetic resonance imaging (fMRI), an excellent technique that measures brain activity, pro-vides effective data to study ASD. Therefore, based on fMRI data of ASD cases, this paper reviews the progress of machine learning methods and deep learning methods in ASD classification and recognition in the last three years and summarizes the different research results of fMRI data extracted from the Autism Brain Imaging Data Exchange (ABIDE). From the classification performance of classification and recognition of ASD by the two methods, comparing the important classification indicators such as accuracy, sensitivity and specificity, the current challenges and future development trends are reported, which can provide an essential reference for the early diagnosis of ASD cases."", ""A Review of Machine Learning Methods of Feature Selection and Classification for Autism Spectrum Disorder Autism Spectrum Disorder (ASD), according to DSM-5 in the American Psychiatric Association, is a neurodevelopmental disorder that includes deficits of social communication and social interaction with the presence of restricted and repetitive behaviors. Children with ASD have difficulties in joint attention and social reciprocity, using non-verbal and verbal behavior for communication. Due to these deficits, children with autism are often socially isolated. Researchers have emphasized the importance of early identification and early intervention to improve the level of functioning in language, communication, and well-being of children with autism. However, due to limited local assessment tools to diagnose these children, limited speech-language therapy services in rural areas, etc., these children do not get the rehabilitation they need until they get into compulsory schooling at the age of seven years old. Hence, efficient approaches towards early identification and intervention through speedy diagnostic procedures for ASD are required. In recent years, advanced technologies like machine learning have been used to analyze and investigate ASD to improve diagnostic accuracy, time, and quality without complexity. These machine learning methods include artificial neural networks, support vector machines, a priori algorithms, and decision trees, most of which have been applied to datasets connected with autism to construct predictive models. Meanwhile, the selection of features remains an essential task before developing a predictive model for ASD classification. This review mainly investigates and analyzes up-to-date studies on machine learning methods for feature selection and classification of ASD. We recommend methods to enhance machine learning's speedy execution for processing complex data for conceptualization and implementation in ASD diagnostic research. This study can significantly benefit future research in autism using a machine learning approach for feature selection, classification, and processing imbalanced data.""]"
21,419,21_stroke_infarction_infarct_cerebral,"['stroke', 'infarction', 'infarct', 'cerebral', 'outcomes', 'artery', 'clinical', 'patients', 'predictive', 'patient']","[""Deep learning derived automated ASPECTS on non-contrast CT scans of acute ischemic stroke patients Ischemic stroke is the most common type of stroke, ranked as the second leading cause of death worldwide. The Alberta Stroke Program Early CT Score (ASPECTS) is considered as a systematic method of assessing ischemic change on non-contrast CT scans (NCCT) of acute ischemic stroke (AIS) patients, while still suffering from the requirement of experts' experience and also the inconsistent results between readers. In this study, we proposed an automated ASPECTS method to utilize the powerful learning ability of neural networks for objectively scoring CT scans of AIS patients. First, we proposed to use the CT perfusion (CTP) from one-stop stroke imaging to provide the golden standard of ischemic regions for ASPECTS scoring. Second, we designed an asymmetry network to capture features when comparing the left and right sides for each ASPECTS region to estimate its ischemic status. Third, we performed experiments in a large main dataset of 870 patients, as well as an independent testing dataset consisting of 207 patients with radiologists' scorings. Experimental results show that our network achieved remarkable performance, as sensitivity and accuracy of 93.7 and 92.4% in the main dataset, and 95.5 and 91.3% in the independent testing dataset, respectively. In the latter dataset, our analysis revealed a high positive correlation between the ASPECTS score and the prognosis of patients in 90DmRs. Also, we found ASPECTS score is a good indicator of the size of CTP core volume of an infraction. The proposed method shows its potential for automated ASPECTS scoring on NCCT images."", ""Evaluation of machine learning methods to stroke outcome prediction using a nationwide disease registry Introduction: Being able to predict functional outcomes after a stroke is highly desirable for clinicians. This allows clinicians to set reasonable goals with patients and relatives, and to reach shared after-care decisions for recovery or rehabilitation. The aim of this study was to apply various machine learning (ML) methods for 90-day stroke outcome predictions, using a nationwide disease registry. Conclusion: The study showed that ML techniques trained from large, cross-reginal registry datasets were able to predict functional outcome after stroke with high accuracy. The follow-up data is important which can further improve the predictive models' performance. With similar performances among different ML techniques, the algorithm's characteristics and performance on severe stroke patients will be the primary focus when we further develop inference models and artificial intelligence tools for potential medical. Published by Elsevier B.V. Methods: This study used the Taiwan Stroke Registry (TSR) which has prospectively collected data from stroke patients since 2006. Three known ML models (support vector machine, random forest, and artificial neural network), and a hybrid artificial neural network were implemented and evaluated by 10-time repeated hold-out with 10-fold cross-validation. Results: ML techniques present over 0.94 AUC in both ischemic and hemorrhagic stroke using preadmission and inpatient data. By adding follow-up data, the prediction ability improved to 0.97 AUC. We screened 206 clinical variables to identify 17 important features from the ischemic stroke dataset and 22 features from the hemorrhagic stroke dataset without losing much performance. Error analysis revealed that most prediction errors come from more severe stroke patients."", ""Development and Validation of Prediction Models for Severe Complications After Acute Ischemic Stroke: A Study Based on the Stroke Registry of Northwestern Germany Background The treatment of stroke has been undergoing rapid changes. As treatment options progress, prediction of those under risk for complications becomes more important. Available models have, however, frequently been built based on data no longer representative of today's care, in particular with respect to acute stroke management. Our aim was to build and validate prediction models for 4 clinically important, severe outcomes after stroke. Methods and Results We used German registry data from 152 710 patients with acute ischemic stroke obtained in 2016 (development) and 2017 (validation). We took into account potential predictors that were available at admission and focused on in-hospital mortality, intracranial mass effect, secondary intracerebral hemorrhage, and deep vein thrombosis as outcomes. Validation cohort prediction and calibration performances were assessed using the following 4 statistical approaches: logistic regression with backward selection, l1-regularized logistic regression, k-nearest neighbor, and gradient boosting classifier. In-hospital mortality and intracranial mass effects could be predicted with high accuracy (both areas under the curve, 0.90 [95% CI, 0.90-0.90]), whereas the areas under the curve for intracerebral hemorrhage (0.80 [95% CI, 0.80-0.80]) and deep vein thrombosis (0.73 [95% CI, 0.73-0.73]) were considerably lower. Stroke severity was the overall most important predictor. Models based on gradient boosting achieved better performances than those based on logistic regression for all outcomes. However, area under the curve estimates differed by a maximum of 0.02. Conclusions We validated prediction models for 4 severe outcomes after acute ischemic stroke based on routinely collected, recent clinical data. Model performance was superior to previously proposed approaches. These predictions may help to identify patients at risk early after stroke and thus facilitate an individualized level of care.""]"
22,411,22_traffic_congestion_road_vehicles,"['traffic', 'congestion', 'road', 'vehicles', 'driving', 'lane', 'driver', 'transportation', 'prediction', 'forecasting']","['LSTM-based traffic flow prediction with missing data Traffic flow prediction plays a key role in intelligent transportation systems. However, since traffic sensors are typically manually controlled, traffic flow data with varying length, irregular sampling and missing data are difficult to exploit effectively. To overcome this problem, we propose a novel approach that is based on Long Short-Term Memory (LSTM) in this paper. In addition, the multiscale temporal smoothing is employed to infer lost data and the prediction residual is learned by our approach. We demonstrate the performance of our approach on both the Caltrans Performance Measurement System (PeMS) data set and our own traffic flow data set. According to the experimental results, our approach obtains higher accuracy in traffic flow prediction compared with other approaches. (C) 2018 Elsevier B.V. All rights reserved.', 'A grey convolutional neural network model for traffic flow prediction under traffic accidents Accurate traffic flow prediction can effectively improve traffic efficiency and safety. This has become a trending topic in intelligent transportation systems. However, the occurrence of traffic accidents will cause great fluctuations of traffic flow in a short time, thus affecting the accuracy of flow prediction. This paper analyses the influence of traffic accident information on traffic flow, and proposes a grey convolutional neural network called G-CNN for traffic flow prediction. First, considering the small sample size of traffic accidents and the incomplete information description, the traffic flow and traffic speed change rate are defined to represent traffic accident grey information, and a grey fixed-weight clustering method for extracting the characteristics of traffic accident grey information is established. Second, the spatiotemporal characteristics of traffic flow are analysed, and a third-order tensor is developed to fuse them with the accident characteristics and serve as the input of the G-CNN. Then the G-CNN model is built to predict traffic flow in a traffic accident environment. The Canadian Whitemud Drive experiment on traffic flow without traffic accident information reveals that the developed G-CNN model has a better ability to predict future traffic flow with better accuracy and stability. Meanwhile, it is verified that the fluctuation of the traffic change rate will cause traffic accidents, and the probability of traffic accidents at a certain time point will be obtained through feature extraction of traffic accidents. Finally, the model is verified for the traffic flow of Hangzhou Viaduct in China, which demonstrates that the G-CNN model outperforms all of the compared models.(c) 2022 Elsevier B.V. All rights reserved.', 'Learning for an aesthetic model for estimating the traffic state in the traffic video With the increasing number of vehicles running on the urban roads, the traffic jam becomes much more serious. Properly estimating the traffic jam level from traffic videos is essential for the department of transportation management and drivers. Currently, for estimating the traffic state on videos, most solutions are built on evaluating traffic flow by counting the running vehicles per time unit or detecting their moving speed. However, the main challenge of these solutions is on the vehicle tracking method, in which the vehicles are necessary to be effectively and integrally segmented from the scenes. The solutions should tradeoff the accuracy of the estimation results and the efficiency of the method. In this paper, we propose a learning-based aesthetic model to estimate the traffic state on videos. The model uses multiple video-based perceptual features about traffic state to train the random forest classifier with the labeled data, and estimates traffic state by data classification. The evaluation experiments are conducted on a testing image set, and the results show that the traffic state estimation accuracy of the proposed model is higher than 98% and the efficiency performance is achieved in real-time. (C) 2015 Elsevier B.V. All rights reserved.']"
23,410,23_schizophrenia_schizophrenic_psychosis_psychiatric,"['schizophrenia', 'schizophrenic', 'psychosis', 'psychiatric', 'psychotic', 'psychiatry', 'neuroimaging', 'brain', 'mental', 'disorder']","[""Identifying Schizophrenia Using Structural MRI With a Deep Learning Algorithm Although distinctive structural abnormalities occur in patients with schizophrenia, detecting schizophrenia with magnetic resonance imaging (MRI) remains challenging. This study aimed to detect schizophrenia in structural MRI data sets using a trained deep learning algorithm. Conclusions Five public MRI data sets (BrainGluSchi, COBRE, MCICShare, NMorphCH, and NUSDAST) from schizophrenia patients and normal subjects, for a total of 873 structural MRI data sets, were used to train a deep convolutional neural network. Method Objective Results The deep learning algorithm showed good performance in detecting schizophrenia and identified relevant structural features from structural brain MRI data; it had an acceptable classification performance in a separate group of patients at an earlier stage of the disease. Deep learning can be used to delineate the structural characteristics of schizophrenia and to provide supplementary diagnostic information in clinical settings. The deep learning algorithm trained with structural MR images detected schizophrenia in randomly selected images with reliable performance (area under the receiver operating characteristic curve [AUC] of 0.96). The algorithm could also identify MR images from schizophrenia patients in a previously unencountered data set with an AUC of 0.71 to 0.90. The deep learning algorithm's classification performance degraded to an AUC of 0.71 when a new data set with younger patients and a shorter duration of illness than the training data sets was presented. The brain region contributing the most to the performance of the algorithm was the right temporal area, followed by the right parietal area. Semitrained clinical specialists hardly discriminated schizophrenia patients from healthy controls (AUC: 0.61) in the set of 100 randomly selected brain images."", ""Predicting individual variability in task-evoked brain activity in schizophrenia What goes wrong in a schizophrenia patient's brain that makes it so different from a healthy brain? In this study, we tested the hypothesis that the abnormal brain activity in schizophrenia is tightly related to alterations in brain connectivity. Using functional magnetic resonance imaging (fMRI), we demonstrated that both resting-state functional connectivity and brain activity during the well-validated N-back task differed significantly between schizophrenia patients and healthy controls. Nevertheless, using a machine-learning approach we were able to use resting-state functional connectivity measures extracted from healthy controls to accurately predict individual variability in the task-evoked brain activation in the schizophrenia patients. The predictions were highly accurate, sensitive, and specific, offering novel insights regarding the strong coupling between brain connectivity and activity in schizophrenia. On a practical perspective, these findings may allow to generate task activity maps for clinical populations without the need to actually perform any tasks, thereby reducing patients inconvenience while saving time and money."", 'Advanced EEG-based learning approaches to predict schizophrenia: Promises and pitfalls The complexity and heterogeneity of schizophrenia symptoms challenge an objective diagnosis, which is typically based on behavioral and clinical manifestations. Moreover, the boundaries of schizophrenia are not precisely demarcated from other nosologic categories, such as bipolar disorder. The early detection of schizophrenia can lead to a more effective treatment, improving patients? quality of life. Over the last decades, hundreds of studies aimed at specifying the neurobiological mechanisms that underpin clinical manifestations of schizophrenia, using techniques such as electroencephalography (EEG). Changes in event-related potentials of the EEG have been associated with sensory and cognitive deficits and proposed as biomarkers of schizophrenia. Besides contributing to a more effective diagnosis, biomarkers can be crucial to schizophrenia onset prediction and prognosis. However, any proposed biomarker requires substantial clinical research to prove its validity and costeffectiveness. Fueled by developments in computational neuroscience, automatic classification of schizophrenia at different stages (prodromal, first episode, chronic) has been attempted, using brain imaging pattern recognition methods to capture differences in functional brain activity. Advanced learning techniques have been studied for this purpose, with promising results. This review provides an overview of recent machine learningbased methods for schizophrenia classification using EEG data, discussing their potentialities and limitations. This review is intended to serve as a starting point for future developments of effective EEG-based models that might predict the onset of schizophrenia, identify subjects at high-risk of psychosis conversion or differentiate schizophrenia from other disorders, promoting more effective early interventions.']"
24,373,24_retrieval_recognition_features_sensing,"['retrieval', 'recognition', 'features', 'sensing', 'visual', 'feature', 'classification', 'images', 'detection', 'dataset']","[""Joint image representation and classification in random semantic spaces Local feature based image representation has been widely used for image classification in recent years. Although this strategy has been proven very effective, the image representation and classification processes are relatively independent. This means the image classification performance may be hindered by the representation efficiency. To jointly consider the image representation and classification in an unified framework, in this paper, we propose a novel algorithm by combining image representation and classification in the random semantic spaces. First, we encode local features with the sparse coding technique and use the encoding parameters for raw image representation. These image representations are then randomly selected to generate the random semantic spaces and images are then mapped to these random semantic spaces by classifier training. The mapped semantic representation is then used as the final image representation. In this way, we are able to jointly consider the image representation and classification in order to achieve better performances. We evaluate the performances of the proposed method on several public image datasets and experimental results prove the proposed method's effectiveness. (C) 2015 Elsevier B.V. All rights reserved."", 'Unsupervised selective rank fusion for image retrieval tasks Several visual features have been developed for content-based image retrieval in the last decades, including global, local and deep learning-based approaches. However, despite the huge advances in features development and mid-level representations, a single visual descriptor is often insufficient to achieve effective retrieval results in several scenarios. Mainly due to the diverse aspects involved in human visual perception, the combination of different features has been establishing as a relevant trend in image retrieval. An intrinsic difficulty consists in the task of selecting the features to combine, which is often supported by supervised learning approaches. Therefore, in the absence of labeled data, selecting features in an unsupervised way is a very challenging, although essential task. In this paper, an unsupervised framework is proposed to select and fuse visual features in order to improve the effectiveness of image retrieval tasks. The framework estimates the effectiveness and correlation among features through a rank-based analysis and uses a list of ranker pairs to determine the selected features combinations. High-effective retrieval results were achieved through a comprehensive experimental evaluation conducted on 5 public datasets, involving 41 different features and comparison with other methods. Relative gains up to +55% were obtained in relation to the highest effective isolated feature. (c) 2019 Elsevier B.V. All rights reserved.', 'Scene image retrieval with siamese spatial attention pooling Content-based image retrieval (CBIR) aims to retrieve images from a given image collection according to similarities of image contents. In this paper, we focus on retrieval of scene images. We propose a siamese spatial attentive model which bases on siamese architecture and incorporates attention mechanism to generate compatible image embeddings. It extracts local features with a convolutional neural network (CNN), which starts with pre-trained parameters and is well fine-tuned for retrieval. Spatial attention pooling is proposed to take feature maps as input and generate weights for local features, which are then used to refine local features via weighted sum-pooling. Such pooling alleviates impacts from disturbance and concentrates on meaningful parts of images. Therefore, the model is able to output robust representations for noisy images. We also propose a multi-stage training scheme for the model, which leads to better performance than normal one-pass training scheme. Extensive experimental results on benchmark image retrieval datasets show that our model is competitive in retrieval performance. (c) 2020 Elsevier B.V. All rights reserved.']"
25,368,25_depressive_depression_depressed_psychiatric,"['depressive', 'depression', 'depressed', 'psychiatric', 'antidepressant', 'mental', 'mood', 'antidepressants', 'disorder', 'disorders']","[""Deep Neural Networks for Depression Recognition Based on 2D and 3D Facial Expressions Under Emotional Stimulus Tasks The proportion of individuals with depression has rapidly increased along with the growth of the global population. Depression has been the currently most prevalent mental health disorder. An effective depression recognition system is especially crucial for the early detection of potential depression risk. A depression-related dataset is also critical while evaluating the system for depression or potential depression risk detection. Due to the sensitive nature of clinical data, availability and scale of such datasets are scarce. To our knowledge, there are few extensively practical depression datasets for the Chinese population. In this study, we first create a large-scale dataset by asking subjects to perform five mood-elicitation tasks. After each task, subjects' audio and video are collected, including 3D information (depth information) of facial expressions via a Kinect. The constructed dataset is from a real environment, i.e., several psychiatric hospitals, and has a specific scale. Then we propose a novel approach for potential depression risk recognition based on two kinds of different deep belief network (DBN) models. One model extracts 2D appearance features from facial images collected by an optical camera, while the other model extracts 3D dynamic features from 3D facial points collected by a Kinect. The final decision result comes from the combination of the two models. Finally, we evaluate all proposed deep models on our built dataset. The experimental results demonstrate that (1) our proposed method is able to identify patients with potential depression risk; (2) the recognition performance of combined 2D and 3D features model outperforms using either 2D or 3D features model only; (3) the performance of depression recognition is higher in the positive and negative emotional stimulus, and females' recognition rate is generally higher than that for males. Meanwhile, we compare the performance with other methods on the same dataset. The experimental results show that our integrated 2D and 3D features DBN is more reasonable and universal than other methods, and the experimental paradigm designed for depression is reasonable and practical."", ""Deep learning for prediction of depressive symptoms in a large textual dataset Depression is a common illness worldwide with potentially severe implications. Early identification of depressive symptoms is a crucial first step towards assessment, intervention, and relapse prevention. With an increase in data sets with relevance for depression, and the advancement of machine learning, there is a potential to develop intelligent systems to detect symptoms of depression in written material. This work proposes an efficient approach using Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) to identify texts describing self-perceived symptoms of depression. The approach is applied on a large dataset from a public online information channel for young people in Norway. The dataset consists of youth's own text-based questions on this information channel. Features are then provided from a one-hot process on robust features extracted from the reflection of possible symptoms of depression pre-defined by medical and psychological experts. The features are better than conventional approaches, which are mostly based on the word frequencies (i.e., some topmost frequent words are chosen as features from the whole text dataset and applied to model the underlying events in any text message) rather than symptoms. Then, a deep learning approach is applied (i.e., RNN) to train the time-sequential features discriminating texts describing depression symptoms from posts with no such descriptions (non-depression posts). Finally, the trained RNN is used to automatically predict depression posts. The system is compared against conventional approaches where it achieved superior performance than others. The linear discriminant space clearly reveals the robustness of the features by generating better clustering than other traditional features. Besides, since the features are based on the possible symptoms of depression, the system may generate meaningful explanations of the decision from machine learning models using an explainable Artificial Intelligence (XAI) algorithm called Local Interpretable Model-Agnostic Explanations (LIME). The proposed depression symptom feature-based approach shows superior performance compared to the traditional general word frequency-based approaches where frequency of the features gets more importance than the specific symptoms of depression. Although the proposed approach is applied on a Norwegian dataset, a similar robust approach can be applied on other depression datasets developed in other languages with proper annotations and symptom-based feature extraction. Thus, the depression prediction approach can be adopted to contribute to develop better mental health care technologies such as intelligent chatbots."", 'Depression Analysis and Recognition Based on Functional Near-Infrared Spectroscopy Depression is the result of a complex interaction of social, psychological and physiological elements. Research into the brain disorders of patients suffering from depression can help doctors to understand the pathogenesis of depression and facilitate its diagnosis and treatment. Functional near-infrared spectroscopy (fNIRS) is a non-invasive approach to the detection of brain functions and activities. In this paper, a comprehensive fNIRS-based depression-processing architecture, including the layers of source, feature and model, is first established to guide the deep modeling for fNIRS. In view of the complexity of depression, we propose a methodology in the time and frequency domains for feature extraction and deep neural networks for depression recognition combined with current research. It is found that compared to non-depression people, patients with depression have a weaker encephalic area connectivity and lower level of activation in the prefrontal lobe during brain activity. Finally, based on raw data, manual features and channel correlations, the AlexNet model shows the best performance, especially in terms of the correlation features and presents an accuracy rate of 0.90 and a precision rate of 0.91, which is higher than ResNet18 and machine-learning algorithms on other data. Therefore, the correlation of brain regions can effectively recognize depression (from cases of non-depression), making it significant for the recognition of brain functions in the clinical diagnosis and treatment of depression.']"
26,366,26_clustering_cluster_clusters_datasets,"['clustering', 'cluster', 'clusters', 'datasets', 'hierarchical', 'data', 'algorithms', 'similarity', 'algorithm', 'analysis']","['New feature analysis-based elastic net algorithm with clustering objective function Cluster analysis, as one of the core methods of data mining, is critical in discovering the natural structure of data to obtain useful information from massive amounts of data. However, many existing clustering algorithms have problems such as poor clustering accuracy and high sensitivity to noise points. These problems are particularly prominent when solving high-dimensional and large-data clustering problems. To overcome these problems, a new feature analysis-based elastic net algorithm with a clustering objective function (FAENC) is proposed in this paper. The new algorithm redefines a cost function based on the goal of clustering, and a new energy function of the clustering elastic net is presented based on the cost function and maximum entropy principle. The proposed model is an unsupervised optimization method. By minimizing the energy function, clustering problems can be solved through self-learning, without manual training or intervention. Additionally, a method for calculating the dispersion degree of the feature attributes is proposed, and the noise attributes can be identified. Each feature attribute is weighted automatically according to the weighting strategy, which can eliminate the influence of noise variables and improve the clustering quality and efficiency. The proposed FAENC algorithm can significantly reduce the impact of the internal structure of the dataset, identify clusters of different sizes, shapes, and densities, and obtain higher clustering quality. Compared with several classical and state-of-the-art clustering methods, FAENC substantially improves the accuracy of clustering results on a large number of synthetic and real-world datasets.(c) 2022 Elsevier B.V. All rights reserved.', 'Joint Feature Selection with Dynamic Spectral Clustering Current clustering algorithms solved a few of the issues around clustering such as similarity measure learning, or the cluster number estimation. For instance, some clustering algorithms can learn the data similarity matrix, but to do so they need to know the cluster number beforehand. On the other hand, some clustering algorithms estimate the cluster number, but to do so they need the similarity matrix as an input. Real-world data often contains redundant features and outliers, which many algorithms are susceptive to. None of the current clustering algorithms are able to learn the data similarity measure and the cluster number simultaneously, and at the same time reduce the influence of outliers and redundant features. Here we propose a joint feature selection with dynamic spectral clustering (FSDS) algorithm that not only learns the cluster number k and data similarity measure simultaneously, but also employs the L-2,L-1-norm to reduce the influence of outliers and redundant features. The optimal performance could be reached when all the separated stages are combined in a unified way. Experimental results on eight real-world benchmark datasets show that our FSDS clustering algorithm outperformed the comparison clustering algorithms in terms of two evaluation metrics for clustering algorithms including ACC and Purity.', 'Towards understanding hierarchical clustering: A data distribution perspective A very important category of clustering methods is hierarchical clustering. There are considerable research efforts which have been focused on algorithm-level improvements of the hierarchical clustering process. In this paper, our goal is to provide a systematic understanding of hierarchical clustering from a data distribution perspective. Specifically, we investigate the issues about how the """"true"""" cluster distribution can make impact on the clustering performance, and what is the relationship between hierarchical clustering schemes and validation measures with respect to different data distributions. To this end, we provide an organized study to illustrate these issues. Indeed, one of our key findings reveals that hierarchical clustering tends to produce clusters with high variation on cluster sizes regardless of """"true"""" cluster distributions. Also, our results show that F-measure, an external clustering validation measure, has bias towards hierarchical clustering algorithms which tend to increase the variation on cluster sizes. Viewed in light of this, we propose F-norm. the normalized version of the F-measure, to solve the cluster validation problem for hierarchical clustering. Experimental results show that F-norm is indeed more suitable than the unnormalized F-measure in evaluating the hierarchical clustering results across data sets with different data distributions. (c) 2009 Elsevier B.V. All rights reserved.']"
27,359,27_robots_robotics_robotic_robot,"['robots', 'robotics', 'robotic', 'robot', 'interacting', 'humanoid', 'artificial', 'interaction', 'autonomous', 'interactions']","[""Communication and knowledge sharing in human-robot interaction and learning from demonstration Inexpensive personal robots will soon become available to a large portion of the population. Currently, most consumer robots are relatively simple single-purpose machines or toys. In order to be cost effective and thus widely accepted, robots will need to be able to accomplish a wide range of tasks in diverse conditions. Learning these tasks from demonstrations offers a convenient mechanism to customize and train a robot by transferring task related knowledge from a user to a robot. This avoids the time-consuming and complex process of manual programming. The way in which the user interacts with a robot during a demonstration plays a vital role in terms of how effectively and accurately the user is able to provide a demonstration. Teaching through demonstrations is a social activity, one that requires bidirectional communication between a teacher and a student. The work described in this paper studies how the user's visual observation of the robot and the robot's auditory cues affect the user's ability to teach the robot in a social setting. Results show that auditory cues provide important knowledge about the robot's internal state, while visual observation of a robot can hinder an instructor due to incorrect mental models of the robot and distractions from the robot's movements. (C) 2010 Published by Elsevier Ltd"", ""Can Real-Time, Adaptive Human-Robot Motor Coordination Improve Humans' Overall Perception of a Robot? Previous research on social interaction among humans suggested that interpersonal motor coordination can help to establish social rapport. Our research addresses the question of whether, in a human-humanoid interaction experiment, the human's overall perception of a robot can be improved by realizing motor coordination behavior that allows the robot to adapt in real-time to a person's behavior. A synchrony detection method using information distance was adopted to realize the real-time human-robot motor coordination behavior, which guided the humanoid robot to coordinate its movements to a human by measuring the behavior synchrony between the robot and the human. The feedback of the participants indicated that most of the participants preferred to interact with the humanoid robot with the adaptive motor coordination capability. The results of this proof-of-concept study suggest that the motor coordination mechanism improved humans' overall perception of the humanoid robot. Together with our previous findings, namely that humans actively coordinate their behaviors to a humanoid robot's behaviors, this study further supports the hypothesis that bidirectional motor coordination could be a valid approach to facilitate adaptive human-humanoid interaction."", ""On the Imitation of Goal Directed Movements of a Humanoid Robot Interacting with a social robot should give people a better understanding of the robot's actions and intentions. In terms of human-human interaction (HHI), people can interpret actions of others in an effortless way. However, it is still unclear whether people can do the same with humanoid robots. Imitation (of the robot's actions) provides us with an intuitive means for solving this puzzle, because it is closely related to interpreting another's actions. In the study of human imitation, the theory of goal-directed imitation holds that the imitator tends to imitate the action goals whenever the action goals are salient, otherwise people tend to imitate the action means. We investigated this theory for human robot interaction by manipulating the presence and absence of the goal object when people imitate the robot's pointing gestures. The results showed that the presence of a goal object reduces people's goal errors. Moreover, we found that most people tend to match their action means rather than the goals of the robot's action. To ensure that participants considered the robot as a social agent, we designed a natural interaction task where the turn-taking cue was included: we let the robot look at the human after completing the pointing gesture at varying latencies. As expected, we found that the earlier the robot gazes at people, the shorter the reaction time of people was to start to imitate. Our results show that people are responsive to a robot's social gaze cues, and that they are responsive to the action goals of robots, although not as much as in HHI.""]"
28,356,28_voltage_circuit_converters_converter,"['voltage', 'circuit', 'converters', 'converter', 'electrical', 'capacitor', 'power', 'dielectric', 'boost', 'current']","[""An Ultra High Step-Up DC-DC Converter Based on the Boost, Luo, and Voltage Doubler Structure: Mathematical Expression, Simulation, and Experimental This paper presents a novel design of step-up DC-DC converters whose merits are: (i) The continuity of the input current has been kept; (ii) The polarity of the output voltage has been kept positive which provides the same ground of the input source and load; (iii) The low voltage gain of the quadratic converters has been solved that it can increase the input voltage to 10 times more by the low value of the duty cycle; (iv) Apart from the high value of the voltage gain, the semiconductors' voltage and current stresses were lower than the output voltage and input current of the converter which are the highest value of the voltage and current respectively and semiconductor based components do not suffer from high value of the current/voltage stresses; (v) Additionally, the voltage/current stresses are low, and the efficiency is good according to its 90 percent value. The analysis of the non-ideal voltage gain has been done and its better function has been deduced by comparing it with the recently proposed non-isolated topologies. Additionally, the non-isolated voltage gain has been studied for different output power levels. The efficiency has been extracted and discussed for varying duty cycles and output power based on ignoring some losses. Experimental results and simulation outcomes from the PLECS software have been compared along with theoretical relationships. The prototype of the topology has been tested at 100 W output power, 100 V output voltage, and 10 V input voltage."", 'Transformerless High Step-Up DC-DC Converter With Low Voltage Stress for Fuel Cells Conventional dc-dc boost converter has limited boost capacity, and its power device suffers high voltage stress. A novel hybrid Z-source dc-dc converter featured with high step-up capability and low device voltage stress is proposed in this article. Compared with the basic structure, the proposed topology can achieve higher voltage gain under the same duty ratio, and reduce the voltage stresses on the switch and diode under the same output condition. Moreover, the duty ratio is not limited. The detailed analysis and a comparison considering the proposed and other structures are also presented, which confirms its unique advantages. To verify the proposed converter performance, a prototype circuit with 40V-60V input voltage, 400V output voltage and 200W output power is built in the laboratory. Experiment results confirm the analysis and the boost capacity of the proposed converter.', 'Switched-Capacitor High Voltage Gain Z-Source Converter With Common Ground and Reduced Passive Component Conventional dc-dc Boost converter has limited boost capacity, and its power device suffers high voltage stress. A novel Z-source based dc-dc boost converter featured with high step-up capability and low device voltage stress is proposed in this paper. The proposed topology can also provide a common ground for input and output, which is lacking in the traditional Z-source topology. Compared with other high step-up topologies, the proposed converter can achieve higher voltage gain under the same duty ratio and maintain low voltage stresses on the switch and diode. Moreover, there are fewer passive components in the proposed structure than in other structures. The steady-state analysis for the continuous conduction mode and discontinuous conduction mode is also provided in this manuscript. Finally, a prototype circuit with 40V-60V input voltage, 400V output voltage and 200W output power is implemented in the laboratory. Experiment results confirm the analysis and the features of the proposed converter.']"
29,350,29_neurosurgeons_neurosurgery_neurosurgical_simulators,"['neurosurgeons', 'neurosurgery', 'neurosurgical', 'simulators', 'simulator', 'virtual', 'interactive', 'intraoperative', 'preoperative', 'dextroscope']","[""Augmented reality in neurosurgical navigation: A survey Background Neurosurgery has exceptionally high requirements for minimally invasive and safety. This survey attempts to analyse the practical application of AR in neurosurgical navigation. Also, this survey describes future trends in augmented reality neurosurgical navigation systems. Methods In this survey, we searched related keywords 'augmented reality', 'virtual reality', 'neurosurgery', 'surgical simulation', 'brain tumour surgery', 'neurovascular surgery', 'temporal bone surgery' and 'spinal surgery' through Google Scholar, World Neurosurgery, PubMed and Science Direct. We collected 85 articles published over the past 5 years in areas related to this survey. Results Detailed study has been conducted on the application of AR in neurosurgery and found that AR is constantly improving the overall efficiency of doctor training and treatment, which can help neurosurgeons learn and practice surgical procedures with zero risks. Conclusions Neurosurgical navigation is essential in neurosurgery. Despite certain technical limitations, it is still a necessary tool for the pursuit of maximum security and minimal intrusiveness."", 'Enhancing Reality: A Systematic Review of Augmented Reality in Neuronavigation and Education CONCLUSIONS: Although various AR systems have been successfully utilized across many neurosurgical disciplines, more research is needed to improve accuracy in registration and to assess whether AR-assisted surgery is safe and effective for widespread adoption. METHODS: PubMed search was performed for """" augmented reality and neurosurgery"""" and """"mixed reality and neurosurgery"""" from 2010. A total of 113 articles written in the last 5 years were retrieved, and 39 were ultimately included in the systematic review. OBJECTIVE: Augmented reality (AR) is increasingly being explored as an adjunct to conventional neuronavigation systems. AR affords the ability to superimpose 3-dimensional images onto the real environment. A natural extension of this technology is to help guide neurosurgical planning and a means of stereotactic planning and guidance. Here we review the literature on the use of AR in neurosurgery with a focus on current technologies and limitations. Furthermore, we discuss this technology in the context of neurosurgical training as an educational tool. RESULTS: The most common use of AR in neurosurgery was in cranial surgery (n = 26). Other uses included spine surgery (n = 9) and education (n = 2). Devices used for display of AR images varied as did image-to-patient registration methods and overall system accuracy.', 'Intraoperative clinical application of augmented reality in neurosurgery: A systematic review The interest and potential use of augmented reality (AR) in several medical fields since the early 90\'s has increased consistently. It provides intraoperative guidance for surgical procedures by rendering visible what cannot be seen directly, possibly affecting surgical outcomes. Our objective was to conduct a systematic review of the intraoperative clinical application of augmented reality in neurosurgery, in studies published during the last five years. We carried out an electronic search in the PUBMED database using the terms """"Augmented Reality"""" and """"Neurosurgery."""" After exclusions, 12 published articles that evaluated the utility of intraoperative clinical applications in surgical settings were included in our review. The results evaluated involved AR technique and visualization, time, complications, projection error, and located structures. We can conclude that the neurovascular application is the most frequent type of use for AR in neurosurgery (47.3%), followed by applications in neuro-oncological pathologies (46.7%), and non-vascular and non-neoplasic lesions (5.9%). The use of AR also allows a surgeon to maintain their view on the operative site permanently, and is useful for locating structures, guiding resections, and planning the craniotomy with more precision, decreasing the risk of injury. The intraoperative application of an augmented reality system helps to improve the quality and characteristics of the surgical field image. The injection of 3D images with AR allows for the successful integration of images in vascular, oncological and other lesions without the need of look away from the surgical field, improving safety, surgical experience, or clinical outcome. However, comparative studies are still required to determine its effectiveness.']"
30,345,30_neural_simulations_simulators_neuron,"['neural', 'simulations', 'simulators', 'neuron', 'simulating', 'simulation', 'simulator', 'simulated', 'computational', 'neuroscience']","['Extending the Functional Subnetwork Approach to a Generalized Linear Integrate-and-Fire Neuron Model Engineering neural networks to perform specific tasks often represents a monumental challenge in determining network architecture and parameter values. In this work, we extend our previously-developed method for tuning networks of non-spiking neurons, the """"Functional subnetwork approach"""" (FSA), to the tuning of networks composed of spiking neurons. This extension enables the direct assembly and tuning of networks of spiking neurons and synapses based on the network\'s intended function, without the use of global optimization or machine learning. To extend the FSA, we show that the dynamics of a generalized linear integrate and fire (GLIF) neuron model have fundamental similarities to those of a non-spiking leaky integrator neuron model. We derive analytical expressions that show functional parallels between: (1) A spiking neuron\'s steady-state spiking frequency and a non-spiking neuron\'s steady-state voltage in response to an applied current; (2) a spiking neuron\'s transient spiking frequency and a non-spiking neuron\'s transient voltage in response to an applied current; and (3) a spiking synapse\'s average conductance during steady spiking and a non-spiking synapse\'s conductance. The models become more similar as additional spiking neurons are added to each population """"node"""" in the network. We apply the FSA to model a neuromuscular reflex pathway two different ways: Via non-spiking components and then via spiking components. These results provide a concrete example of how a single non-spiking neuron may model the average spiking frequency of a population of spiking neurons. The resulting model also demonstrates that by using the FSA, models can be constructed that incorporate both spiking and non-spiking units. This work facilitates the construction of large networks of spiking neurons and synapses that perform specific functions, for example, those implemented with neuromorphic computing hardware, by providing an analytical method for directly tuning their parameters without time-consuming optimization or learning.', 'Integration of Continuous-Time Dynamics in a Spiking Neural Network Simulator Contemporary modeling approaches to the dynamics of neural networks include two important classes of models: biologically grounded spiking neuron models and functionally inspired rate-based units. We present a unified simulation framework that supports the combination of the two for multi-scale modeling, enables the quantitative validation of mean-field approaches by spiking network simulations, and provides an increase in reliability by usage of the same simulation code and the same network model specifications for both model classes. While most spiking simulations rely on the communication of discrete events, rate models require time-continuous interactions between neurons. Exploiting the conceptual similarity to the inclusion of gap junctions in spiking network simulations, we arrive at a reference implementation of instantaneous and delayed interactions between rate-based models in a spiking network simulator. The separation of rate dynamics from the general connection and communication infrastructure ensures flexibility of the framework. In addition to the standard implementation we present an iterative approach based on waveform-relaxation techniques to reduce communication and increase performance for large-scale simulations of rate-based models with instantaneous interactions. Finally we demonstrate the broad applicability of the framework by considering various examples from the literature, ranging from random networks to neural-field models. The study provides the prerequisite for interactions between rate-based and spiking models in a joint simulation.', 'Limas to high-speed simulations of spiking neural networks using general-purpose computers To understand how the central nervous system performs computations using recurrent neuronal circuitry, simulations have become an indispensable tool for theoretical neuroscience. To study neuronal circuits and their ability to self-organize, increasing attention has been directed toward synaptic plasticity. In particular spike-timing-dependent plasticity (STDP) creates specific demands for simulations of spiking neural networks. On the one hand a high temporal resolution is required to capture the millisecond timescale of typical STDP windows. On the other hand network simulations have to evolve over hours up to days, to capture the timescale of long-term plasticity. To do this efficiently, fast simulation speed is the crucial ingredient rather than large neuron numbers. Using different medium-sized network models consisting of several thousands of neurons and off-the-shelf hardware, we compare the simulation speed of the simulators: Brian, NEST and Neuron as well as our own simulator Auryn. Our results show that real-time simulations of different plastic network models are possible in parallel simulations in which numerical precision is not a primary concern. Even so, the speed-up margin of parallelism is limited and boosting simulation speeds beyond one tenth of real-time is difficult. By profiling simulation code we show that the run times of typical plastic network simulations encounter a hard boundary. This limit is partly due to latencies in the inter-process communications and thus cannot be overcome by increased parallelism. Overall, these results show that to study plasticity in medium-sized spiking neural networks, adequate simulation tools are readily available which run efficiently on small clusters. However, to run simulations substantially faster than real-time, special hardware is a prerequisite.']"
31,324,31_neural_electroencephalogram_electroencephalography_electroencephalographic,"['neural', 'electroencephalogram', 'electroencephalography', 'electroencephalographic', 'brain', 'electrodes', 'electrode', 'classification', 'recognition', 'learning']","['Cross-Subject EEG Signal Recognition Using Deep Domain Adaptation Network Collecting sufficient labeled electroencephalography (EEG) data to build an individual classifier for each subject is extremely time-consuming and labor-intensive, especially for the disabled patients. A feasible way is to use labeled EEG data from other subjects (source domains) to train a model for classifying EEG data from the new subjects (target domains). However, the model trained using other subjects EEG data may degrade the classification performance of the target subject, when there exists the substantial inter-subject variability of EEG data. In this paper, to account for the domain shift between different subjects, we propose a novel deep domain adaptation network (DDAN) for cross-subject EEG signal recognition. Specifically, a special end-to-end convolutional neural network (CNN) is firstly adopted to automatically extract deep features from the raw EEG data. Then, maximum mean discrepancy (MMD) is used to minimize the distribution discrepancy of deep features between source and target subjects. Finally, a center-based discriminative feature learning (CDFL) method is used to force the deep features closer to their corresponding class centers and make the inter-class centers more separable, so that it is possible to further improve the recognition performance of target domain EEG data. Experiments on public EEG datasets prove the effectiveness of the proposed method. This study may promote the practical use of EEG signal processing technology and expand its application range.', 'Hidden pattern discovery on event related potential EEG signals EEG signals are important to capture brain disorders. They are useful for analyzing the cognitive activity of the brain and diagnosing types of seizure and potential mental health problems. The Event Related Potential can be measured through the EEG signal. However, it is always difficult to interpret due to its low amplitude and sensitivity to changes of the mental activity. In this paper, we propose a novel approach to incrementally detect the pattern of this kind of EEG signal. This approach successfully summarizes the whole stream of the EEG signal by finding the correlations across the electrodes and discriminates the signals corresponding to various tasks into different patterns. It is also able to detect the transition period between different EEG signals and identify the electrodes which contribute the most to these signals. The experimental results show that the proposed method allows the significant meaning of the EEG signal to be obtained from the extracted pattern. (C) 2009 Elsevier Ireland Ltd. All rights reserved.', ""Deep learning for electroencephalogram (EEG) classification tasks: a review Objective. Electroencephalography (EEG) analysis has been an important tool in neuroscience with applications in neuroscience, neural engineering (e.g. Brain-computer interfaces, BCI's), and even commercial applications. Many of the analytical tools used in EEG studies have used machine learning to uncover relevant information for neural classification and neuroimaging. Recently, the availability of large EEG data sets and advances in machine learning have both led to the deployment of deep learning architectures, especially in the analysis of EEG signals and in understanding the information it may contain for brain functionality. The robust automatic classification of these signals is an important step towards making the use of EEG more practical in many applications and less reliant on trained professionals. Towards this goal, a systematic review of the literature on deep learning applications to EEG classification was performed to address the following critical questions: (1) Which EEG classification tasks have been explored with deep learning? (2) What input formulations have been used for training the deep networks? (3) Are there specific deep learning network structures suitable for specific types of tasks? Approach. A systematic literature review of EEG classification using deep learning was performed on Web of Science and PubMed databases, resulting in 90 identified studies. Those studies were analyzed based on type of task, EEG preprocessing methods, input type, and deep learning architecture. Main results. For EEG classification tasks, convolutional neural networks, recurrent neural networks, deep belief networks outperform stacked auto-encoders and multi-layer perceptron neural networks in classification accuracy. The tasks that used deep learning fell into five general groups: emotion recognition, motor imagery, mental workload, seizure detection, event related potential detection, and sleep scoring. For each type of task, we describe the specific input formulation, major characteristics, and end classifier recommendations found through this review. Significance. This review summarizes the current practices and performance outcomes in the use of deep learning for EEG classification. Practical suggestions on the selection of many hyperparameters are provided in the hope that they will promote or guide the deployment of deep learning to EEG datasets in future research.""]"
32,317,32_imaging_brain_mri_diffusion,"['imaging', 'brain', 'mri', 'diffusion', 'tractograms', 'tractography', 'tensor', 'anatomical', 'white', 'visualization']","['Processing and visualization for diffusion tensor MRI This paper presents processing and visualization techniques for Diffusion Tensor Magnetic Resonance Imaging (DT-MRI). In DT-MRI, each voxel is assigned a tensor that describes local water diffusion. The geometric nature of diffusion tensors enables us to quantitatively characterize the local structure in tissues such as bone, muscle, and white matter of the brain. This makes DT-MRI an interesting modality for image analysis. In this paper we present a novel analytical solution to the Stejskal-Tanner diffusion equation system whereby a dual tensor basis, derived from the diffusion sensitizing gradient configuration, eliminates the need to solve this equation for each voxel. We further describe decomposition of the diffusion tensor based on its symmetrical properties, which in turn describe the geometry of the diffusion ellipsoid. A simple anisotropy measure follows naturally from this analysis. We describe how the geometry or shape of the tensor can be visualized using a coloring scheme based on the derived shape measures. In addition, we demonstrate that human brain tensor data when filtered can effectively describe macrostructural diffusion, which is important in the assessment of fiber-tract organization. We also describe how white matter pathways can be monitored with the methods introduced in this paper. DT-MRI tractography is useful for demonstrating neural connectivity (in vivo) in healthy and diseased brain tissue. (C) 2002 Elsevier Science B.V. All rights reserved.', 'Genetic white matter fiber tractography with global optimization Diffusion tensor imaging (DTI) tractography is a novel technique that can delineate the trajectories between cortical region of the human brain non-invasively. In this paper, a novel DTI based white matter fiber tractography using genetic algorithm is presented. Adapting the concepts from evolutionary biology which include selection, recombination and mutation, globally optimized fiber pathways are generated iteratively. Global optimality of the fiber tracts is evaluated using Bayes decision rule, which simultaneously considers both the fiber geometric smoothness and consistency with the tensor field. This global optimality assigns the tracking fibers great immunity to random image noise and other local image artifacts, thus avoiding the detrimental effects of cumulative noise on fiber tracking. Experiments with synthetic and in vivo human DTI data have demonstrated the feasibility and robustness of this new fiber tracking technique. and an improved performance over commonly used probabilistic fiber tracking. (C) 2009 Elsevier B.V. All rights reserved.', 'Approximating anatomical brain connectivity with diffusion tensor MRI using kernel-based diffusion simulations We present a new technique for noninvasively tracing brain white matter fiber tracts using diffusion tensor magnetic resonance imaging (DT-MRI). This technique is based on performing diffusion simulations over a series of overlapping three dimensional diffusion kernels that cover only a small portion of the human brain volume and are geometrically centered upon selected starting voxels where a seed is placed. Synthetic and real DT-MRI data are employed to demonstrate the tracking scheme. It is shown that the synthetic tracts can be accurately replicated, while several major white matter fiber pathways in the human brain can be reproduced noninvasively as well. The primary advantages of the algorithm lie in the handling of fiber branching and crossing and its seamless adaptation to the platform established by new imaging techniques, such as high angular, q-space, or generalized diffusion tensor imaging.']"
33,316,33_depressive_depression_therapy_therapist,"['depressive', 'depression', 'therapy', 'therapist', 'interventions', 'treatment', 'psychological', 'mental', 'treatments', 'anxiety']","[""Transdiagnostic internet treatment for anxiety and depression: A randomised controlled trial Disorder-specific cognitive behavioural therapy programs delivered over the internet (iCBT) with clinician guidance are effective at treating specific anxiety disorders and depression. The present study examined the efficacy of a transdiagnostic iCBT protocol to treat three anxiety disorders and/or depression within the same program (the Wellbeing Program). Seventy-seven individuals with a principal diagnosis of major depression, generalised anxiety disorder, panic disorder, and/or social phobia were randomly assigned to a Treatment or Waitlist Control group. Treatment consisted of CBT-based online educational lessons and homework assignments, weekly email or telephone contact from a clinical psychologist, access to a moderated online discussion forum, and automated emails. Eighty one percent of Treatment group participants completed all 8 lessons within the 10 week program. Post-treatment data were collected from 34/37 Treatment group and 35/37 Control group participants, and 3-month follow-up data were collected from 32/37 Treatment group participants. Relative to Controls, Treatment group participants reported significantly reduced symptoms of anxiety and depression as measured by the Depression Anxiety and Stress Scales-21 item, Patient Health Questionnaire-9 item, and Generalised Anxiety Disorder-7 item scales, with corresponding between-groups effect sizes (Cohen's d) at post treatment of .56, .58, and .52, respectively. The clinician spent a mean time of 84.76 min (SD = 50.37) per person over the program. Participants rated the procedure as highly acceptable, and gains were sustained at follow-up. These results provide preliminary support for the efficacy of transdiagnostic iCBT in the treatment of anxiety and depressive disorders. (C) 2011 Elsevier Ltd. All rights reserved."", 'The Clinical Effectiveness of Web-Based Cognitive Behavioral Therapy With Face-to-Face Therapist Support for Depressed Primary Care Patients: Randomized Controlled Trial Background: Most patients with mild to moderate depression receive treatment in primary care, but despite guideline recommendations, structured psychological interventions are infrequently delivered. Research supports the effectiveness of Internet-based treatment for depression; however, few trials have studied the effect of the MoodGYM program plus therapist support. The use of such interventions could improve the delivery of treatment in primary care. Conclusions: The intervention combining MoodGYM and brief therapist support can be an effective treatment of depression in a sample of primary care patients. The intervention alleviates depressive symptoms and has a significant positive effect on anxiety symptoms and satisfaction with life. Moderate rates of nonadherence and predominately positive evaluations of the treatment also indicate the acceptability of the intervention. The intervention could potentially be used in a stepped-care approach, but remains to be tested in regular primary health care. Methods: Participants (N=106) aged between 18 and 65 years were recruited from primary care and randomly allocated to a treatment condition comprising 6 weeks of therapist-assisted Web-based cognitive behavioral therapy (CBT), or to a 6-week delayed treatment condition. The intervention included the Norwegian version of the MoodGYM program, brief face-to-face support from a psychologist, and reminder emails. The primary outcome measure, depression symptoms, was measured by the Beck Depression Inventory-II (BDI-II). Secondary outcome measures included the Beck Anxiety Inventory (BAI), the Hospital Anxiety and Depression Scale (HADS), the Satisfaction with Life Scale (SWLS), and the EuroQol Group 5-Dimension Self-Report Questionnaire (EQ-5D). All outcomes were based on self-report and were assessed at baseline, postintervention, and at 6-month follow-up. Objective: To evaluate the effectiveness and acceptability of a guided Web-based intervention for mild to moderate depression, which could be suitable for implementation in general practice. Results: Postintervention measures were completed by 37 (71%) and 47 (87%) of the 52 participants in the intervention and 54 participants in the delayed treatment group, respectively. Linear mixed-models analyses revealed a significant difference in time trends between the groups for the BDI-II, (P=.002), for HADS depression and anxiety subscales (P<.001 and P=.001, respectively), and for the SWLS (P<.001). No differential group effects were found for the BAI and the EQ-5D. In comparison to the control group, significantly more participants in the intervention group experienced recovery from depression as measured by the BDI-II. Of the 52 participants in the treatment program, 31 (60%) adhered to the program, and overall treatment satisfaction was high. The reduction of depression and anxiety symptoms was largely maintained at 6-month follow-up, and positive gains in life satisfaction were partly maintained.', ""Treatment of depression and anxiety with internet-based cognitive behavior therapy in patients with a recent myocardial infarction (U-CARE Heart): study protocol for a randomized controlled trial Background: Major depression and depressive symptoms are common in patients with a recent myocardial infarction (MI), and depression is associated with adverse cardiovascular outcomes. Anxiety post-MI is less studied, but occurs commonly in patients with heart disease, and is also considered a risk factor for recurrence of cardiac events. Cognitive behavior therapy (CBT) is an established therapy for depression and anxiety disorders. To the best of our knowledge, there have not been any studies to determine if internet-based CBT (iCBT) can reduce the symptoms of depression and anxiety in patients with a recent MI. The main aim of the U-CARE Heart trial is to evaluate an iCBT intervention for patients with a recent MI. Discussion: The present study is designed to evaluate an iCBT intervention targeting symptoms of depression and anxiety in a post-MI population. If effective, iCBT has several advantages, and will potentially be implemented as an easily accessible treatment option added to modern standard of care. Methods/design: This is a randomized, controlled, prospective study with a multicenter design. A total of 500 participants will be randomized at a 1:1 ratio, around two months after an acute MI, to either iCBT or to a control group. Both groups will receive an optimal standard of care according to guidelines. The intervention consists of a self-help program delivered via the internet with individual online support from a psychologist. Treatment duration is 14 weeks. The primary outcome is change in patients' self-rated anxiety and depression symptoms from baseline to end of treatment. An internal pilot study was conducted indicating sufficient levels of study acceptability and engagement in treatment.""]"
34,313,34_tactile_stimulation_sensory_stimuli,"['tactile', 'stimulation', 'sensory', 'stimuli', 'touch', 'wrist', 'thumb', 'fingertips', 'hand', 'manipulation']","[""Linear Integration of Tactile and Non-tactile Inputs Mediates Estimation of Fingertip Relative Position While skin, joints and muscles receptors alone provide lower level information about individual variables (e.g., exerted limb force and limb displacement), the distance between limb endpoints (i.e., relative position) has to be extracted from high level integration of somatosensory and motor signals. In particular, estimation of fingertip relative position likely involves more complex sensorimotor transformations than those underlying hand or arm position sense: the brain has to estimate where each fingertip is relative to the hand and where fingertips are relative to each other. It has been demonstrated that during grasping, feedback of digit position drives rapid adjustments of fingers force control. However, it has been shown that estimation of fingertips' relative position can be biased by digit forces. These findings raise the question of how the brain combines concurrent tactile (i.e., cutaneous mechanoreceptors afferents induced by skin pressure and stretch) and non-tactile (i.e., both descending motor command and joint/muscle receptors signals associated to muscle contraction) digit force-related inputs for fingertip distance estimation. Here we addressed this question by quantifying the contribution of tactile and non-tactile force-related inputs for the estimation of fingertip relative position. We asked subjects to match fingertip vertical distance relying only on either tactile or non-tactile inputs from the thumb and index fingertip, and compared their performance with the condition where both types of inputs were combined. We found that (a) the bias in the estimation of fingertip distance persisted when tactile inputs and non-tactile force-related signals were presented in isolation; (b) tactile signals contributed the most to the estimation of fingertip distance; (c) linear summation of the matching errors relying only on either tactile or non-tactile inputs was comparable to the matching error when both inputs were simultaneously available. These findings reveal a greater role of tactile signals for sensing fingertip distance and suggest a linear integration mechanism with non-tactile inputs for the estimation of fingertip relative position."", ""A Tactile Virtual Reality for the Study of Active Somatosensation Natural exploration of textures involves active sensing, i.e., voluntary movements of tactile sensors (e.g., human fingertips or rodent whiskers) across a target surface. Somatosensory input during moving tactile sensors varies according to both the movement and the surface texture. Combining motor and sensory information, the brain is capable of extracting textural features of the explored surface. Despite the ecological relevance of active sensing, psychophysical studies on active touch are largely missing. One reason for the lack of informative studies investigating active touch is the considerable challenge of assembling an appropriate experimental setup. A possible solution might be in the realm of virtual tactile reality that provides tactile finger stimulation depending on the position of the hand and the simulated texture of a target surface. In addition to rigorous behavioral studies, the investigation of the neuronal mechanisms of active tactile sensing in humans is highly warranted, requiring neurophysiological experiments using electroencephalography (EEG), magnetoencephalography (MEG) and/or functional magnetic resonance imaging (fMRI). However, current neuroimaging techniques impose specific requirements on the tactile stimulus delivery equipment in terms of compatibility with the neurophysiological methods being used. Here, we present a user-friendly, MEG compatible, tactile virtual reality simulator. The simulator consists of a piezo-electric tactile stimulator capable of independently protruding 16 plastic pistons of 1 mm diameter arranged in a 4 x 4 matrix. The stimulator delivers a spatial pattern of tactile stimuli to the tip of a finger depending on the position of the finger moving across a 2-dimensional plane. In order to demonstrate the functionality of the tactile virtual reality, we determined participants' detection thresholds in active and passive touch conditions. Thresholds in both conditions were higher than reported in the literature. It could well be that the processing of the piston-related stimulation was masked by the sensory input generated by placing the finger on the scanning probe. More so, the thresholds for both the active and passive tasks did not differ significantly. In further studies, the noise introduced by the stimulator in neuromagnetic recordings was quantified and somatosensory evoked fields for active and passive touch were recorded. Due to the compatibility of the stimulator with neuroimaging techniques such as MEG, and based on the feasibility to record somatosensory-related neuromagnetic brain activity the apparatus has immense potential for the exploration of the neural underpinnings of active tactile perception."", ""The effect of tactile augmentation on manipulation and grip force control during force-field adaptation Background When exposed to a novel dynamic perturbation, participants adapt by changing their movements' dynamics. This adaptation is achieved by constructing an internal representation of the perturbation, which allows for applying forces that compensate for the novel external conditions. To form an internal representation, the sensorimotor system gathers and integrates sensory inputs, including kinesthetic and tactile information about the external load. The relative contribution of the kinesthetic and tactile information in force-field adaptation is poorly understood. Methods In this study, we set out to establish the effect of augmented tactile information on adaptation to force-field. Two groups of participants received a velocity-dependent tangential skin deformation from a custom-built skin-stretch device together with a velocity-dependent force-field from a kinesthetic haptic device. One group experienced a skin deformation in the same direction of the force, and the other in the opposite direction. A third group received only the velocity-dependent force-field. Results We found that adding a skin deformation did not affect the kinematics of the movement during adaptation. However, participants who received skin deformation in the opposite direction adapted their manipulation forces faster and to a greater extent than those who received skin deformation in the same direction of the force. In addition, we found that skin deformation in the same direction to the force-field caused an increase in the applied grip-force per amount of load force, both in response and in anticipation of the stretch, compared to the other two groups. Conclusions Augmented tactile information affects the internal representations for the control of manipulation and grip forces, and these internal representations are likely updated via distinct mechanisms. We discuss the implications of these results for assistive and rehabilitation devices.""]"
35,309,35_optimization_algorithm_algorithms_optimal,"['optimization', 'algorithm', 'algorithms', 'optimal', 'neural', 'nonlinear', 'convex', 'linear', 'constrained', 'solving']","['Neural network for nonsmooth pseudoconvex optimization with general convex constraints In this paper, a one-layer recurrent neural network is proposed for solving a class of nonsmooth, pseudoconvex optimization problems with general convex constraints. Based on the smoothing method, we construct a new regularization function, which does not depend on any information of the feasible region. Thanks to the special structure of the regularization function, we prove the global existence, uniqueness and """"slow solution\'\' character of the state of the proposed neural network. Moreover, the state solution of the proposed network is proved to be convergent to the feasible region in finite time and to the optimal solution set of the related optimization problem subsequently. In particular, the convergence of the state to an exact optimal solution is also considered in this paper. Numerical examples with simulation results are given to show the efficiency and good characteristics of the proposed network. In addition, some preliminary theoretical analysis and application of the proposed network for a wider class of dynamic portfolio optimization are included. (c) 2018 Elsevier Ltd. All rights reserved.', 'Neural network for constrained nonsmooth optimization using Tikhonov regularization This paper presents a one-layer neural network to solve nonsmooth convex optimization problems based on the Tikhonov regularization method. Firstly, it is shown that the optimal solution of the original problem can be approximated by the optimal solution of a strongly convex optimization problems. Then, it is proved that for any initial point, the state of the proposed neural network enters the equality feasible region in finite time, and is globally convergent to the unique optimal solution of the related strongly convex optimization problems. Compared with the existing neural networks, the proposed neural network has lower model complexity and does not need penalty parameters. In the end, some numerical examples and application are given to illustrate the effectiveness and improvement of the proposed neural network. (C) 2014 Elsevier Ltd. All rights reserved.', 'A recurrent neural network for solving a class of generalized convex optimization problems In this paper, we propose a penalty-based recurrent neural network for solving a class of constrained optimization problems with generalized convex objective functions. The model has a simple structure described by using a differential inclusion. It is also applicable for any nonsmooth optimization problem with affine equality and convex inequality constraints, provided that the objective function is regular and pseudoconvex on feasible region of the problem. It is proven herein that the state vector of the proposed neural network globally converges to and stays thereafter in the feasible region in finite time, and converges to the optimal solution set of the problem. (C) 2013 Elsevier Ltd. All rights reserved.']"
36,308,36_fmri_brain_neuroimaging_cognitive,"['fmri', 'brain', 'neuroimaging', 'cognitive', 'imaging', 'dataset', 'datasets', 'analyses', 'functional', 'data']","['Multisubject Task-Related fMRI Data Processing via a Two-Stage Generalized Canonical Correlation Analysis Functional magnetic resonance imaging (fMRI) is one of the most popular methods for studying the human brain. Task-related fMRI data processing aims to determine which brain areas are activated when a specific task is performed and is usually based on the Blood Oxygen Level Dependent (BOLD) signal. The background BOLD signal also reflects systematic fluctuations in regional brain activity which are attributed to the existence of resting-state brain networks. We propose a new fMRI data generating model which takes into consideration the existence of common task-related and resting-state components. We first estimate the common task-related temporal component, via two successive stages of generalized canonical correlation analysis and, then, we estimate the common task-related spatial component, leading to a task-related activation map. The experimental tests of our method with synthetic data reveal that we are able to obtain very accurate temporal and spatial estimates even at very low Signal to Noise Ratio (SNR), which is usually the case in fMRI data processing. The tests with real-world fMRI data show significant advantages over standard procedures based on General Linear Models (GLMs).', 'Four-Dimensional Modeling of fMRI Data via Spatio-Temporal Convolutional Neural Networks (ST-CNNs) Since the human brain functional mechanism has been enabled for investigation by the functional magnetic resonance imaging (fMRI) technology, simultaneous modeling of both the spatial and temporal patterns of brain functional networks from 4-D fMRI data has been a fundamental but still challenging research topic for neuroimaging and medical image analysis fields. Currently, general linear model (GLM), independent component analysis (ICA), sparse dictionary learning, and recently deep learning models, are major methods for fMRI data analysis in either spatial or temporal domains, but there are few joint spatial-temporal methods proposed, as far as we know. As a result, the 4-D nature of fMRI data has not been effectively investigated due to this methodological gap. The recent success of deep learning applications for functional brain decoding and encoding greatly inspired us in this paper to propose a novel framework called spatio-temporal convolutional neural network (ST-CNN) to extract both spatial and temporal characteristics from targeted networks jointly and automatically identify of functional networks. The identification of default mode network (DMN) from fMRI data was used for evaluation of the proposed framework. Results show that only training the framework on one fMRI data set is sufficiently generalizable to identify the DMN from different data sets of different cognitive tasks and resting state. Further investigation of the results shows that the joint-learning scheme can capture the intrinsic relationship between the spatial and temporal characteristics of DMN and thus it ensures the accurate identification of DMN from independent data sets. The ST-CNN model brings new tools and insights for fMRI analysis in cognitive and clinical neuroscience studies.', 'Task fMRI data analysis based on supervised stochastic coordinate coding Task functional magnetic resonance imaging (fMRI) has been widely employed for brain activation detection and brain network analysis. Modeling rich information from spatially-organized collection of fMRI time series is challenging because of the intrinsic complexity. Hypothesis-driven methods, such as the general linear model (GLM), which regress exterior stimulus from voxel-wise functional brain activity, are limited due to overlooking the complexity of brain activities and the diversity of concurrent brain networks. Recently, sparse representation and dictionary learning methods have attracted increasing interests in task fMRI data analysis. The major advantage of this methodology is its promise in reconstructing concurrent brain networks systematically. However, this data-driven strategy is, to some extent, arbitrary and does not sufficiently utilize the prior information of task design and neuroscience knowledge. To bridge this gap, we here propose a novel supervised sparse representation and dictionary learning framework based on stochastic coordinate coding (SCC) algorithm for task fMRI data analysis, in which certain brain networks are learned with known information such as pre-defined temporal patterns and spatial network patterns, and at the same time other networks are learned automatically from data. Our proposed method has been applied to two independent task fMRI datasets, and qualitative and quantitative evaluations have shown that our method provides a new and effective framework for task fMRI data analysis. (C) 2017 Elsevier B.V. All rights reserved.']"
37,307,37_stroke_virtual_rehabilitation_exercises,"['stroke', 'virtual', 'rehabilitation', 'exercises', 'exercise', 'training', 'impairment', 'immersive', 'sessions', 'therapy']","['Increasing upper limb training intensity in chronic stroke using embodied virtual reality: a pilot study Background: Technology-mediated neurorehabilitation is suggested to enhance training intensity and therefore functional gains. Here, we used a novel virtual reality (VR) system for task-specific upper extremity training after stroke. The system offers interactive exercises integrating motor priming techniques and embodied visuomotor feedback. In this pilot study, we examined (i) rehabilitation dose and training intensity, (ii) functional improvements, and (iii) safety and tolerance when exposed to intensive VR rehabilitation. Conclusions: This pilot study showed how a dedicated VR system could deliver high rehabilitation doses and, importantly, intensive training in chronic stroke survivors. FMA-UE and AROM results suggest that task-specific VR training may be beneficial for further functional recovery both in the chronic stage of stroke. Longitudinal studies with higher doses and sample sizes are required to confirm the therapy effectiveness. Methods: Ten outpatient stroke survivors with chronic (&gt;6 months) upper extremity paresis participated in a tensession VR-based upper limb rehabilitation program (2 sessions/week). Results: All participants completed all sessions of the treatment. In total, they received a median of 403 min of upper limb therapy, with 290 min of effective training. Within that time, participants performed a median of 4713 goal-directed movements. Importantly, training intensity increased progressively across sessions from 13.2 to 17.3 movements per minute. Clinical measures show that despite being in the chronic phase, where recovery potential is thought to be limited, participants showed a median improvement rate of 5.3% in motor function (Fugl-Meyer Assessment for Upper Extremity; FMA-UE) post intervention compared to baseline, and of 15.4% at one-month follow-up. For three of them, this improvement was clinically significant. A significant improvement in shoulder active range of motion (AROM) was also observed at follow-up. Participants reported very low levels of pain, stress and fatigue following each session of training, indicating that the intensive VR intervention was well tolerated. No severe adverse events were reported. All participants expressed their interest in continuing the intervention at the hospital or even at home, suggesting high levels of adherence and motivation for the provided intervention.', 'Virtual reality training for upper extremity in subacute stroke (VIRTUES): study protocol for a randomized controlled multicenter trial Background: Novel virtual reality rehabilitation systems provide the potential to increase intensity and offer challenging and motivating tasks. The efficacy of virtual reality systems to improve arm motor function early after stroke has not been demonstrated yet in sufficiently powered studies. The objective of the study is to investigate whether VR training as an adjunct to conventional therapy is more effective in improving arm motor function in the subacute phase after stroke than dose-matched conventional training, to assess patient and therapist satisfaction when working with novel virtual reality training and to calculate cost-effectiveness in terms of resources required to regain some degree of dexterity. Discussion: Virtual reality systems are promising tools for rehabilitation of arm motor function after stroke. Their introduction in combination with traditional physical and occupational therapy may enhance recovery after stroke, and at the same time demand little personnel resources to increase training intensity. The VIRTUES trial will provide further evidence of VR-based treatment strategies to clinicians, patients and health economists. Methods/Design: Randomized controlled observer-blind trial. One hundred and twenty patients up to 12 weeks after stroke will be randomized to either a group receiving VR training or dose-matched and therapist attention-matched conventional arm training in addition to standard rehabilitation. During a period of four weeks the patients will be offered additional 4-5 training sessions a week of 45-60 minutes duration by a physiotherapist or an occupational therapist. Study outcomes: Arm motor function, dexterity and independence in daily life activities will be evaluated at baseline, post treatment and three months follow-up assessments with the Action Research Arm Test, Box and Blocks Test and the Functional Independence Measure, respectively. Patient and therapist satisfaction with the implementation of a VR rehabilitation system will also be assessed with questionnaires and interviews.', ""Virtual reality for upper extremity rehabilitation in early stroke: a pilot randomized controlled trial Conclusion: Although additional VR training was not superior to conventional therapy alone, this study demonstrates the feasibility of VR training in early stroke. Design: Pilot randomized controlled trial. Interventions: Participants were randomly assigned to VR group (n=11) or control group (n=12). VR group received nine 30 minutes upper extremity VR therapy in standing (five weekdays in two weeks) plus conventional therapy, which included physical and occupational therapy. Control group received only conventional therapy, which was comparable to total training time received by VR group (mean training hours (SD):VR = 17.07 (2.86); control = 15.50 (2.79)). Main outcome measures: The main outcome measure was the Fugl-Meyer Assessment (FMA). Secondary outcomes included Action Research Arm Test, Motor Activity Log and Functional Independence Measure. Results were taken at baseline, post intervention and 1-month post intervention. Participants' feedback and adverse effects were recorded. Objectives: To investigate the effect of virtual reality (VR) rehabilitation on upper extremity motor performance of patients with early stroke. Participants: Twenty three adults with stroke (mean age (SD) = 58.35 (13.45) years and mean time since stroke (SD) = 16.30 (7.44) days). Results: All participants improved in FMA scores (mean change (SD) = 11.65 (8.56), P<.001). These effects were sustained at one month after intervention (mean (SD) change from baseline = 18.67 (13.26), P<.001). All other outcome measures showed similar patterns. There were no significant differences in improvement between both groups. Majority of the participants found VR training useful and enjoyable, with no serious adverse effects reported. Setting: Rehabilitation wards.""]"
38,302,38_multiagent_consensus_heterogeneous_dynamics,"['multiagent', 'consensus', 'heterogeneous', 'dynamics', 'protocol', 'protocols', 'strategy', 'systems', 'control', 'theory']","['Iterative learning based consensus control for distributed parameter multi-agent systems with time-delay This paper concerns about the iterative learning consensus control scheme for a class of multi-agent systems (MAS) with delay distributed parameter models. First, based on the framework of network topologies and using the nearest neighbor knowledge, a second-order iterative learning consensus control protocol is proposed. Next, under the proposed controller, a discrete dynamic system with respect to the iteration number variable is established and the consensus control problem is then converted to a stability problem of a discrete dynamic system. Furthermore, a sufficient condition for the convergence of the consensus errors between any two agents is obtained. Finally, the simulation examples illustrate the validity of the proposed method. (C) 2019 Elsevier B.V. All rights reserved.', ""Second-order consensus in multi-agent systems with directed topologies and communication constraints The paper investigates second-order consensus problem for multi-agent systems with nonlinear dynamic and directed topologies, where each agent can only communicate with its neighbors on some disconnected time intervals. A novel intermittent consensus protocol is designed by its own and the neighbor's relative local information. Based on the Lyapunov stability theory and the intermittent control method, some novel and simple criteria are derived for consensus of multi-agent systems under a fixed strongly connected topology, it is proved that consensus can be reached if the general algebraic connectivity and the measure of communication are larger than the corresponding threshold values, respectively. Finally, two numerical examples are provided to demonstrate the effectiveness of the obtained theoretical results. (C) 2015 Elsevier B.V. All rights reserved."", 'Second-order consensus of discrete-time multi-agent systems in directed networks with nonlinear dynamics via impulsive protocols In this paper, we discuss the second-order consensus problem of discrete-time multi-agent systems with fixed and switching topology. Impulsive protocols are introduced for such multi-agent systems with non-linear dynamics. The consensus problem of multi-agent systems is analyzed by algebraic graph theory and matrix theory, where a connection of impulsive control methods and network topologies is established. Our main results indicate that the second-order consensus of multi-agent systems can be achieved if the graphs of the topology are balanced and strongly connected under suitable conditions. Numerical simulations are presented to support the theoretical results. (C) 2018 Elsevier B.V. All rights reserved.']"
39,300,39_trauma_traumatic_concussions_cerebral,"['trauma', 'traumatic', 'concussions', 'cerebral', 'concussion', 'injuries', 'brain', 'intracranial', 'injury', 'damage']","['Internet and Social Media Use After Traumatic Brain Injury: A Traumatic Brain Injury Model Systems Study Objectives: To characterize Internet and social media use among adults with moderate to severe traumatic brain injury (TBI) and to compare demographic and socioeconomic factors associated with Internet use between those with and without TBI. Setting: Ten Traumatic Brain Injury Model Systems centers. Participants: Persons with moderate to severe TBI (N = 337) enrolled in the TBI Model Systems National Database and eligible for follow-up from April 1, 2014, to March 31, 2015. Design: Prospective cross-sectional observational cohort study. Main Measures: Internet usage survey. Results: The proportion of Internet users with TBI was high (74%) but significantly lower than those in the general population (84%). Smartphones were the most prevalent means of Internet access for persons with TBI. The majority of Internet users with TBI had a profile account on a social networking site (79%), with more than half of the sample reporting multiplatform use of 2 or more social networking sites. Conclusion: Despite the prevalence of Internet use among persons with TBI, technological disparities remain in comparison with the general population. The extent of social media use among persons with TBI demonstrates the potential of these platforms for social engagement and other purposes. However, further research examining the quality of online activities and identifying potential risk factors of problematic use is recommended.', 'Applications of Resting State Functional MR Imaging to Traumatic Brain Injury Traumatic brain injury (TBI) is an important public health issue. TBI includes a broad spectrum of injury severities and abnormalities. Functional MR imaging (fMR imaging), both resting state (rs) and task, has been used often in research to study the effects of TBI. Although rs-fMR imaging is not currently applicable in clinical diagnosis of TBI, computer-aided tools are making this a possibility for the future. Specifically, graph theory is being used to study the change in networks after TBI. Machine learning methods allow researchers to build models capable of predicting injury severity and recovery trajectories.', 'Models used in the study of traumatic brain injury Traumatic brain injury (TBI) is a contemporary health problem and a leading cause of mortality and morbidity worldwide. Survivors of TBI frequently experience disabling long-term changes in cognition, sensorimotor function, and personality. A crucial step in understanding TBI and providing better treatment has been the use of models to mimic the event under controlled conditions. Here, we describe the known head injury models, which can be classified as whole animal (in vivo), in vitro, and mathematical models. We will also review the ways in which these models have advanced the knowledge of TBI.']"
40,295,40_imaging_mri_scans_scan,"['imaging', 'mri', 'scans', 'scan', 'reconstructions', 'reconstruction', 'sensing', 'reconstructed', 'data', 'resolution']","['Multi-Coil MRI Reconstruction Challenge-Assessing Brain MRI Reconstruction Models and Their Generalizability to Varying Coil Configurations Deep-learning-based brain magnetic resonance imaging (MRI) reconstruction methods have the potential to accelerate the MRI acquisition process. Nevertheless, the scientific community lacks appropriate benchmarks to assess the MRI reconstruction quality of high-resolution brain images, and evaluate how these proposed algorithms will behave in the presence of small, but expected data distribution shifts. The multi-coil MRI (MC-MRI) reconstruction challenge provides a benchmark that aims at addressing these issues, using a large dataset of high-resolution, three-dimensional, T1-weighted MRI scans. The challenge has two primary goals: (1) to compare different MRI reconstruction models on this dataset and (2) to assess the generalizability of these models to data acquired with a different number of receiver coils. In this paper, we describe the challenge experimental design and summarize the results of a set of baseline and state-of-the-art brain MRI reconstruction models. We provide relevant comparative information on the current MRI reconstruction state-of-the-art and highlight the challenges of obtaining generalizable models that are required prior to broader clinical adoption. The MC-MRI benchmark data, evaluation code, and current challenge leaderboard are publicly available. They provide an objective performance assessment for future developments in the field of brain MRI reconstruction.', 'Multi-Resolution Parallel Magnetic Resonance Image Reconstruction in Mobile Computing-Based IoT In the mobile computing-based Internet of Things, the computational complexity of applications is constrained by the capacity of the user equipment. In order to reduce the computational complexity of compressed sensing (CS)-based magnetic resonance image (MRI) reconstruction algorithms, we propose a novel multi-resolution-based parallel MRI reconstruction framework in this paper. We break down CS-based MRI reconstruction problem into four independent low-resolution image reconstruction sub-problems. Compared with the original problem, each sub-problem has a lower computational complexity. Assigned to four cores of the central processing unit (CPU), the sub-problems are solved simultaneously, and therefore the MRI reconstruction is accelerated. The combination of reconstructed low-resolution images achieves high-resolution image reconstruction. The proposed framework is applicable to the state-of-the-art CS-based MRI reconstruction algorithms to compute low-resolution images and involves multi-resolution processing. Compared with conventional serial computing, the proposed MRI reconstruction framework speeds at least four times up. Therefore, the parallel computation framework is especially suitable for widely used mobile devices with lower computational capability than workstations. To validate and evaluate the proposed scheme, when selecting the outstanding MRI reconstructing algorithm fast dictionary learning method on classified patches for numerical simulation, peak-signal-to-noise-ratio values of parallel reconstruction results are at least 0.929 dB higher than that of serial computation reconstruction results calculated by classical MRI reconstruction algorithm.', 'Reference-Driven Compressed Sensing MR Image Reconstruction Using Deep Convolutional Neural Networks without Pre-Training Deep learning has proven itself to be able to reduce the scanning time of Magnetic Resonance Imaging (MRI) and to improve the image reconstruction quality since it was introduced into Compressed Sensing MRI (CS-MRI). However, the requirement of using large, high-quality, and patient-based datasets for network training procedures is always a challenge in clinical applications. In this paper, we propose a novel deep learning based compressed sensing MR image reconstruction method that does not require any pre-training procedure or training dataset, thereby largely reducing clinician dependence on patient-based datasets. The proposed method is based on the Deep Image Prior (DIP) framework and uses a high-resolution reference MR image as the input of the convolutional neural network in order to induce the structural prior in the learning procedure. This reference-driven strategy improves the efficiency and effect of network learning. We then add the k-space data correction step to enforce the consistency of the k-space data with the measurements, which further improve the image reconstruction accuracy. Experiments on in vivo MR datasets showed that the proposed method can achieve more accurate reconstruction results from undersampled k-space data.']"
41,291,41_graphs_graph_datasets_topology,"['graphs', 'graph', 'datasets', 'topology', 'networks', 'clustering', 'classification', 'algorithm', 'structured', 'data']","['Adaptive graph convolutional clustering network with optimal probabilistic graph The graph convolutional network (GCN)-based clustering approaches have achieved the impressive performance due to strong ability of exploiting the topological structure. The adjacency graph seriously affects the clustering performance, especially for non-graph data. Existing approaches usually conduct two independent steps, i.e., constructing a fixed graph structure and then graph embedding representation learning by GCN. However, the constructed graph structure may be unreliable one due to noisy data, resulting in sub-optimal graph embedding representation. In this paper, we propose an adaptive graph convolutional clustering network (AGCCN) to alternatively learn the similarity graph structure and node embedding representation in a unified framework. Our AGCCN learns the weighted adjacency graph adaptively from the node representations by solving the optimization problem of graph learning, in which adaptive and optimal neighbors for each sample are assigned with probabilistic way according to local connectivity. Then, the attribute feature extracted by parallel Auto-Encoder (AE) module is fused into the input of adaptive graph convolution module layer-by-layer to learn the comprehensive node embedding representation and strengthen its representation ability. This also skillfully alleviates the over-smoothing problem of GCN. To further improve the discriminant ability of node representation, a dual self-supervised clustering mechanism is designed to guide model optimization with pseudo-labels information. Extensive experimental results on various real-world datasets consistently show the superiority and effectiveness of the proposed deep graph clustering method.(c) 2022 Elsevier Ltd. All rights reserved.', 'Graph classification based on graph set reconstruction and graph kernel feature reduction Graph, a kind of structured data, is widely used to model complex relationships among objects, and has been used in various of scientific and engineering fields, such as bioinformatics, network intrusion detection, social network, etc. Building an automatic and highly accurate classification method for graphs becomes quite necessary for predicting unknown graphs or understanding complex structures among different categories. The kernel method is regarded as a powerful solution to graph classification, which consists of two steps, namely, graph kernel mapping and classification. However, the feature selection process is ignored, and those sub-structures with low discriminative power result in classification accuracy decrease. In order to solve this problem, we propose an efficient graph classification algorithm based on graph set reconstruction and graph kernel feature reduction. First of all, the least discriminative frequent subgraphs and part of the infrequent subgraphs are removed to reconstruct the original graph set. Then we adopt the graph-kernel-based discriminant analysis method to perform feature reduction on the well-reconstructed graph set. At last, the whole framework of the graph classification method is introduced and any commonly used classifiers can be utilized. Extensive experimental results on a series of bioinformatics benchmarks show that our graph classification algorithm demonstrates a significant improvement of prediction comparing with other graph-kernel-based classification approaches. (C) 2018 Elsevier B.V. All rights reserved.', 'A Multi-Task Representation Learning Architecture for Enhanced Graph Classification Composed of nodes and edges, graph structured data are organized in the non-Euclidean geometric space and ubiquitous especially in chemical compounds, proteins, etc. They usually contain rich structure information, and how to effectively extract inherent features of them is of great significance on the determination of function or traits in medicine and biology. Recently, there is a growing interest in learning graph-level representations for graph classification. Existing graph classification strategies based on graph neural networks broadly follow a single-task learning framework and manage to learn graph-level representations through aggregating node-level representations. However, they lack the efficient utilization of labels of nodes in a graph. In this paper, we propose a novel multi-task representation learning architecture coupled with the task of supervised node classification for enhanced graph classification. Specifically, the node classification task enforces node-level representations to take full advantage of node labels available in the graph and the graph classification task allows for learning graph-level representations in an end-to-end manner. Experimental results on multiple benchmark datasets demonstrate that the proposed architecture performs significantly better than various single-task graph neural network methods for graph classification.']"
42,287,42_intrusion_detection_cyber_security,"['intrusion', 'detection', 'cyber', 'security', 'attacks', 'vulnerabilities', 'malware', 'intelligent', 'malicious', 'attack']","['Machine learning approach to realtime intrusion detection system Computer security has become a critical issue with the rapid development of business and other transaction systems over the internet. Recently applying artificial intelligence, machine learning and data mining techniques to intrusion detection system are increasing. But most of researches are focused on improving the classification performance of classifier. Selecting important features from input data lead to a simplification of the problem, faster and more accurate detection rates. Thus selecting important features is an important issue in intrusion detection. Another issue in intrusion detection is that most of the intrusion detection systems are performed by off-line and it is not proper method for realtime intrusion detection system. In this paper, we develop the realtime intrusion detection system which combining on-line feature extraction method with Least Squares Support Vector Machine classifier. Applying proposed system to KDD CUP 99 data, experimental results show that it have remarkable feature feature extraction and classification performance compared to existing off-line intrusion detection system.', 'A Standardized ICS Network Data Processing Flow With Generative Model in Anomaly Detection Industrial control systems (ICS) now usually connect to Wireless Sensor Networks and the Internet, exposing them to security threats resulting from cyber-attacks. However, detecting such attacks is non-trivial task. The high-dimensional network data pose significant challenges on security anomaly detection. In this work, we propose a network flow data processing method, which can make the complex network data more standardized and unified to assist security anomaly detection. Then, data generation method is applied to collect enough training data. We also propose a evaluation method for generated data. Finally, the bidirectional recurrent neural networks with attention mechanism is proposed to extract the latent feature, and give an explainable results in identifying the dominant attributes. Empirical results show our method outperforms the state-of-the-art models.', 'Improved hybrid intelligent intrusion detection system using AI technique Intrusion detection systems are increasingly a key part of systems defense. Various approaches to intrusion detection are currently being used, but they are relatively ineffective. Artificial Intelligence plays a driving role in security services. This paper proposes a dynamic model of intelligent intrusion detection system, based on a specific AI approach for intrusion detection. The techniques that are being investigated include fuzzy logic with network profiling, which uses simple data mining techniques to process the network data. The proposed hybrid system combines anomaly and misuse detection. Simple fuzzy rules allow us to construct if-then rules that reflect common ways of describing security attacks. We use DARPA dataset for training and benchmarking.']"
43,283,43_dimensionality_dimensional_reduction_dimension,"['dimensionality', 'dimensional', 'reduction', 'dimension', 'classification', 'discriminant', 'sparsity', 'tensor', 'algorithms', 'algorithm']","['Locally Minimizing Embedding and Globally Maximizing Variance: Unsupervised Linear Difference Projection for Dimensionality Reduction Recently, many dimensionality reduction algorithms, including local methods and global methods, have been presented. The representative local linear methods are locally linear embedding (LLE) and linear preserving projections (LPP), which seek to find an embedding space that preserves local information to explore the intrinsic characteristics of high dimensional data. However, both of them still fail to nicely deal with the sparsely sampled or noise contaminated datasets, where the local neighborhood structure is critically distorted. On the contrary, principal component analysis (PCA), the most frequently used global method, preserves the total variance by maximizing the trace of feature variance matrix. But PCA cannot preserve local information due to pursuing maximal variance. In order to integrate the locality and globality together and avoid the drawback in LLE and PCA, in this paper, inspired by the dimensionality reduction methods of LLE and PCA, we propose a new dimensionality reduction method for face recognition, namely, unsupervised linear difference projection (ULDP). This approach can be regarded as the integration of a local approach (LLE) and a global approach (PCA), so that it has better performance and robustness in applications. Experimental results on the ORL, YALE and AR face databases show the effectiveness of the proposed method on face recognition.', 'Manifold learning: Dimensionality reduction and high dimensional data reconstruction via dictionary learning Nonlinear dimensionality reduction (DR) algorithms can reveal the intrinsic characteristic of the high dimensional data in a succinct way. However, most of these methods suffer from two problems. First, the incremental dimensionality reduction problem, which means the algorithms cannot compute the embedding of new added data incrementally. Second, the high dimensional data reconstruction problem, which means the algorithms cannot recover the original high dimensional data from the embeddings. Both problems limit the application of the existing DR algorithms. In this paper, a dictionary-based algorithm for manifold learning is proposed to address the problems of incremental dimensionality reduction and high dimensional data reconstruction. In this algorithm, two dictionaries are trained. One is for the manifold in the high dimensional space and the other one is for the embeddings which can be computed by any existing DR method in the low dimensional space. When new data is added, dimensionality reduction and data reconstruction can just be conducted by coding this input data over one dictionary, and then use this code to recover the output data via the other dictionary. The proposed algorithm provides a general framework for manifold learning. It can be integrated into many existing DR algorithms to make them feasible to both incremental dimensionality reduction and high dimensional data reconstruction. The algorithm is efficient due to the closed-form solution for sparse coding and dictionary updating. Furthermore, the proposed algorithm is space-saving because it only needs to store two dictionaries instead of the whole training samples. Experiments conducted on synthetic datasets and real world datasets show that, no matter for incremental dimensionality reduction or high dimensional data reconstruction, the proposed algorithm is accurate and efficient. (C) 2016 Elsevier Ltd. All rights reserved.', 'Unsupervised 2D Dimensionality Reduction with Adaptive Structure Learning In recent years, unsupervised two-dimensional (2D) dimensionality reduction methods for unlabeled large-scale data have made progress. However, performance of these degrades when the learning of similarity matrix is at the beginning of the dimensionality reduction process. A similarity matrix is used to reveal the underlying geometry structure of data in unsupervised dimensionality reduction methods. Because of noise data, it is difficult to learn the optimal similarity matrix. In this letter, we propose a new dimensionality reduction model for 2D image matrices: unsupervised 2D dimensionality reduction with adaptive structure learning (DRASL). Instead of using a predetermined similarity matrix to characterize the underlying geometry structure of the original 2D image space, our proposed approach involves the learning of a similarity matrix in the procedure of dimensionality reduction. To realize a desirable neighbors assignment after dimensionality reduction, we add a constraint to our model such that there are exact c connected components in the final subspace. To accomplish these goals, we propose a unified objective function to integrate dimensionality reduction, the learning of the similarity matrix, and the adaptive learning of neighbors assignment into it. An iterative optimization algorithm is proposed to solve the objective function. We compare the proposed method with several 2D unsupervised dimensionality methods. K-means is used to evaluate the clustering performance. We conduct extensive experiments on Coil20, AT&T, FERET, USPS, and Yale data sets to verify the effectiveness of our proposed method.']"
44,276,44_dehazing_haze_images_algorithm,"['dehazing', 'haze', 'images', 'algorithm', 'pixel', 'blur', 'algorithms', 'filter', 'degraded', 'model']","['Prior guided conditional generative adversarial network for single image dehazing Single image dehazing is an important problem as the existence of haze degrades the quality of the image and hinders most high-level computer vision tasks. Previous methods solve this problem using various low-level statistics priors or learning on synthetic data sets with CNN. In practice, the low-level priors are not always held in various scenes. And many CNN based methods directly estimate the transmission maps and atmospheric lights from huge synthetic data. However, without the guidance or constraints of priors may lead to over-dehazed or under-dehazed results. To address these issues, we propose a prior guided conditional generative adversarial network, an end-to-end model that generates realistic clean images using hazy image input and dehazed image based on the traditional prior-based method. The proposed generator extracted the feature with a parameters-shared encoder, and the clear image is recovered by decoding multi-scale features, which are fused and enhanced by the proposed attention-based feature aggregation block. And two-scale discriminators are adopted to supervise the generator to recover more image details with a combination of perceptual loss and adversarial loss. Our algorithm can efficiently combine the prior-based and CNN based image dehazing method and remove the weakness of each other. Experimental results on synthetic datasets and real-world images demonstrate our model can generate more perceptually appealing dehazing results, and provide superior performance compared with the state-of-the-art methods. (c) 2020 Elsevier B.V. All rights reserved.', 'Single image dehazing based on fusion strategy In this paper, we propose a deep convolutional network for single image dehazing based on derived image fusion strategy. Instead of estimating the transmission map and atmospheric light as previously performed, we directly generate a haze-free image by the proposed end-to-end trainable neural network. We derive five maps from the original hazy image based on the characteristics of the hazy scene to improve the dehazing performance. First, the exposure map (EM) and saliency map (SM) complement each other to focus on details in far-away and near-region scenes. Second, the white balance map (BM) and gamma correction map (GM) are employed to recover the latent colour and intensity components of the scene. Finally, the haze veil map (VM) is introduced to enhance the global image contrast. To efficiently blend the five derived maps, we propose a U-shaped deep convolutional network consisting of encoder and decoder layers to generate a haze-free image. The convolutional layers transferred from the pretrained ResNet50 are used as encoder layers for hierarchical feature extraction. Two efficient blocks, named the cascaded residual block and the channel compression block, are proposed in the network for better dehazing performance. The final dehazed result is generated by combining the significant features of the different derived maps. Additionally, perceptual loss is introduced for better visual quality. The experimental results for both synthetic and natural hazy images demonstrate that our algorithm performs comparably or even better than state-of-the-art methods in terms of the peak signal-to-noise ratio (PSNR), structure similarity (SSIM) and visual quality. (C) 2019 Elsevier B.V. All rights reserved.', ""Model Based Edge-Preserving and Guided Filter for Real-World Hazy Scenes Visibility Restoration Transmission estimation is the most challenging part for single image haze removal and very sensitive to environment noise. However, most existing single image dehazing algorithms are far from satisfactory in terms of restoring an image's details and noise removal. To address this issue, an improved haze imaging model with transmission refinement based on dark channel prior is constructed to preserve the edge details and enhance visibility. Then, a fast single image dehazing algorithm called TSGA algorithm is proposed for complex real-world images. A refined transmission map obtained by TGVSH regularity scheme provides more edges and finer details and is less susceptible to noise. Guided filter and adaptive histogram equalization greatly enhance the visibility and color contrast of the scenes and significantly improve the drawback of halo artifacts. A large quantity of comparative experiment results demonstrate that the proposed algorithm simultaneously removes the serious effect of haze and noise, effectively makes the restored images look more natural, and has a lower time complexity. All these make it a good candidate for image segmentation, object recognition, and target tracking in complex real-world weather conditions.""]"
45,272,45_semantic_linguistic_vocabulary_semantics,"['semantic', 'linguistic', 'vocabulary', 'semantics', 'language', 'languages', 'comprehension', 'lexical', 'neural', 'phonological']","['Dealing with written language semantics by a connectionist model of cognitive reading Although machines perform much better than human beings in most of the tasks, it is not the case of natural language Processing. Computational linguistic systems usually rely on mathematical and statistical formalisms, which are efficient and useful but far from human procedures and therefore not so skilled. This paper proposes a computational model of natural language reading, called Cognitive Reading Indexing Model (CRIM), inspired by some aspects of human cognition, that tries to become as more psychologically plausible as possible. The model relies on a semantic neural network and it produces not vectors but nets of activated concepts as text representations. Based on these representations, measures of semantic similarity are also defined. Human comparison results show that the system is suitable to model human reading. Additional results also point out that the system could be used in real applications concerning natural language processing tasks. (C) 2008 Elsevier B.V. All rights reserved.', ""Architectures of neural networks applied for LVCSR language modeling The n-gram model and its derivatives are both widely applied solutions for Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, Slavonic languages require a language model that considers word order less strictly than English, i.e. the language that is the subject of most linguistic research. Such a language model is a necessary module in LVCSR systems, because it increases the probability of finding the right word sequences. The aim of the presented work is to create a language module for the Polish language with the application of neural networks. Here, the capabilities of Kohonen's Self-Organized Maps will be explored to find the associations between words in spoken utterances. To fulfill such a task, the application of neural networks to evaluate sequences of words will be presented. Then, the next step of language model development, the network architectures, will be discussed. The network proposed for the construction of the considered model is inspired by the Cocke-Young-Kasami parsing algorithm. (C) 2014 Elsevier B.V. All rights reserved."", 'The neural representation of abstract words may arise through grounding word meaning in language itself In order to describe how humans represent meaning in the brain, one must be able to account for not just concrete words but, critically, also abstract words, which lack a physical referent. Hebbian formalism and optimization are basic principles of brain function, and they provide an appealing approach for modeling word meanings based on word co-occurrences. We provide proof of concept that a statistical model of the semantic space can account for neural representations of both concrete and abstract words, using MEG. Here, we built a statistical model using word embeddings extracted from a text corpus. This statistical model was used to train a machine learning algorithm to successfully decode the MEG signals evoked by written words. In the model, word abstractness emerged from the statistical regularities of the language environment. Representational similarity analysis further showed that this salient property of the model co-varies, at 280-420 ms after visual word presentation, with activity in regions that have been previously linked with processing of abstract words, namely the left-hemisphere frontal, anterior temporal and superior parietal cortex. In light of these results, we propose that the neural encoding of word meanings can arise through statistical regularities, that is, through grounding in language itself.']"
46,271,46_brain_connectivity_cognitive_networks,"['brain', 'connectivity', 'cognitive', 'networks', 'connections', 'neuroimaging', 'cortical', 'connectomes', 'connectome', 'network']","['Fusing functional connectivity with network nodal information for sparse network pattern learning of functional brain networks Sparse learning methods have been powerful tools for learning compact representations of functional brain networks consisting of a set of brain network nodes and a connectivity matrix measuring functional coherence between the nodes. However, these tools typically focus on the functional connectivity measures alone, ignoring the brain network nodal information that is complementary to the functional connectivity measures for comprehensively characterizing the functional brain networks. In order to provide a comprehensive delineation of the functional brain networks, we develop a new data fusion method for heterogeneous data, aiming at learning sparse network patterns to characterize both the functional connectivity measures and their complementary network nodal information within a unified framework. Experimental results have demonstrated that our method outperforms the best alternative method under comparison in terms of accuracy on simulated data as well as both reproducibility and prediction performance of brain age on real resting state functional magnetic resonance imaging data.', ""Hyper-connectivity of functional networks for brain disease diagnosis Exploring structural and functional interactions among various brain regions enables better understanding of pathological underpinnings of neurological disorders. Brain connectivity network, as a simplified representation of those structural and functional interactions, has been widely used for diagnosis and classification of neurodegenerative diseases, especially for Alzheimer's disease (AD) and its early stage - mild cognitive impairment (MCI). However, the conventional functional connectivity network is usually constructed based on the pairwise correlation among different brain regions and thus ignores their higher-order relationships. Such loss of high-order information could be important for disease diagnosis, since neurologically a brain region predominantly interacts with more than one other brain regions. Accordingly, in this paper, we propose a novel framework for estimating the hyper-connectivity network of brain functions and then use this hyper-network for brain disease diagnosis. Here, the functional connectivity hyper-network denotes a network where each of its edges representing the interactions among multiple brain regions (i.e., an edge can connect with more than two brain regions), which can be naturally represented by a hyper-graph. Specifically, we first construct connectivity hyper-networks from the resting-state fMRI (R-fMRI) time series by using sparse representation. Then, we extract three sets of brain-region specific features from the connectivity hyper-networks, and further exploit a manifold regularized multi-task feature selection method to jointly select the most discriminative features. Finally, we use multi-kernel support vector machine (SVM) for classification. The experimental results on both MCI dataset and attention deficit hyperactivity disorder (ADHD) dataset demonstrate that, compared with the conventional connectivity network-based methods, the proposed method can not only improve the classification performance, but also help discover disease-related biomarkers important for disease diagnosis. (C) 2016 Elsevier B.V. All rights reserved."", ""Detecting Functional Connectivity in fMRI Using PCA and Regression Analysis A fMRI connectivity analysis approach combining principal component analysis (PCA) and regression analysis is proposed to detect functional connectivity between the brain regions. By first using PCA to identify clusters within the vectors of fMRI time series, more energy and information features in the signal can be maintained than using averaged values from brain regions of interest. Then, regression analysis can be applied to the extracted principal components in order to further investigate functional connectivity. Finally, t-test is applied and the patterns with t-values lager than a threshold are considered as functional connectivity mappings. The validity and reliability of the presented method were demonstrated with both simulated data and human fMRI data obtained during behavioral task and resting state. Compared to the conventional functional connectivity methods such as average signal based correlation analysis, independent component analysis (ICA) and PCA, the proposed method achieves competitive performance with greater accuracy and true positive rate (TPR). Furthermore, the 'default mode' and motor network results of resting-state fMRI data indicate that using PCA may improve upon application of existing regression analysis methods in study of human brain functional connectivity.""]"
47,268,47_electrocardiogram_cardiac_echocardiography_ventricle,"['electrocardiogram', 'cardiac', 'echocardiography', 'ventricle', 'ventricular', 'cardiomyopathy', 'myocardial', 'heart', 'cardiovascular', 'coronary']","['A review of segmentation methods in short axis cardiac MR images For the last 15 years, Magnetic Resonance Imaging (MRI) has become a reference examination for cardiac morphology, function and perfusion in humans. Yet, due to the characteristics of cardiac MR images and to the great variability of the images among patients, the problem of heart cavities segmentation in MRI is still open. This paper is a review of fully and semi-automated methods performing segmentation in short axis images using a cardiac cine MRI sequence. Medical background and specific segmentation difficulties associated to these images are presented. For this particularly complex segmentation task, prior knowledge is required. We thus propose an original categorization for cardiac segmentation methods, with a special emphasis on what level of external information is required (weak or strong) and how it is used to constrain segmentation. After reviewing method principles and analyzing segmentation results, we conclude with a discussion and future trends in this field regarding methodological and medical issues. (C) 2010 Elsevier B.V. All rights reserved.', 'Extracting cardiac dynamics within ECG signal for human identification and cardiovascular diseases classification Cardiac characteristics underlying the time/frequency domain features are limited and not comprehensive enough to reflect the temporal/dynamical nature of ECG patterns. This paper proposes a dynamical ECG recognition framework for human identification and cardiovascular diseases classification via a dynamical neural learning mechanism. The proposed method consists of two phases: a training phase and a test phase. In the training phase, cardiac dynamics within ECG signals is extracted (approximated) accurately by using radial basis function (RBF) neural networks through deterministic learning mechanism. The obtained cardiac system dynamics is represented and stored in constant RBF networks. An ECG signature is then derived from the extracted cardiac dynamics along the periodic ECG state trajectories. A bank of estimators is constructed using the extracted cardiac dynamics to represent the trained gait patterns. In the test phase, recognition errors are generated and taken as the similarity measure by comparing the cardiac dynamics of the trained ECG patterns and the dynamics of the test ECG pattern. Rapid recognition of a test ECG pattern begins with measuring the state of test pattern, and automatically proceeds with the evolution of the recognition error system. According to the smallest error principle, the test ECG pattern can be rapidly recognized. This kind of cardiac dynamics information represents the beat-to-beat temporal change of ECG modifications and the temporal/dynamical nature of ECG patterns. Therefore, the amount of discriminability provided by the cardiac dynamics is larger than the original signals. This paper further discusses the extension of the proposed method for cardiovascular diseases classification. The constructed recognition system can distinguish and assign dynamical ECG patterns to predefined classes according to the similarity of cardiac dynamics. Experiments are carried out on the FuWai and PTB ECG databases to demonstrate the effectiveness of the proposed method. (c) 2018 Elsevier Ltd. All rights reserved.', 'Artificial Intelligence in Cardiac Imaging With Statistical Atlases of Cardiac Anatomy In many cardiovascular pathologies, the shape and motion of the heart provide important clues to understanding the mechanisms of the disease and how it progresses over time. With the advent of large-scale cardiac data, statistical modeling of cardiac anatomy has become a powerful tool to provide automated, precise quantification of the status of patient-specific heart geometry with respect to reference populations. Powered by supervised or unsupervised machine learning algorithms, statistical cardiac shape analysis can be used to automatically identify and quantify the severity of heart diseases, to provide morphometric indices that are optimally associated with clinical factors, and to evaluate the likelihood of adverse outcomes. Recently, statistical cardiac atlases have been integrated with deep neural networks to enable anatomical consistency of cardiac segmentation, registration, and automated quality control. These combinations have already shown significant improvements in performance and avoid gross anatomical errors that could make the results unusable. This current trend is expected to grow in the near future. Here, we aim to provide a mini review highlighting recent advances in statistical atlasing of cardiac function in the context of artificial intelligence in cardiac imaging.']"
48,265,48_colorization_textures_segmentation_texture,"['colorization', 'textures', 'segmentation', 'texture', 'segmenting', 'contour', 'color', 'colour', 'classification', 'pixel']","['Efficient Color Texture Classification Using Color Monogenic Wavelet Transform Color textures are among the most important visual attributes in image analysis. From the practical point view of color texture image analysis, this paper proposes an effective multi-scale color texture classification algorithm that is rotation and scale invariant using non-marginal colormonogenic wavelet transform. The proposed algorithm exploits the color monogenic wavelet transform to obtain multi-scale representation of training samples for each texture class. The coefficients of colormonogenicwavelet transform represent a magnitude and three phases: two phases encode local color information while the third contains geometric information of color texture image. The multi-scale feature vector is composed of mean value, standard deviation, energy and entropy at different scales of each of the directional sub-bands. The experimental results of average correct classification rates are 98.67, 99.08 and 99.89% which are obtained from different color texture databases demonstrate its superior performance and robustness of the proposed classifier. The proposed color texture feature vector is also shown to be effective for color texture classification.', 'A pixel-based color image segmentation using support vector machine and fuzzy C-means Image segmentation is an important tool in image processing and can serve as an efficient front end to sophisticated algorithms and thereby simplify subsequent processing. In this paper, we present a pixel-based color image segmentation using Support Vector Machine (SVM) and Fuzzy C-Means (FCM). Firstly, the pixel-level color feature and texture feature of the image, which is used as input of the SVM model (classifier), are extracted via the local spatial similarity measure model and Steerable filter. Then, the SVM model (classifier) is trained by using FCM with the extracted pixel-level features. Finally, the color image is segmented with the trained SVM model (classifier). This image segmentation can not only take full advantage of the local information of the color image but also the ability of the SVM classifier. Experimental evidence shows that the proposed method has a very effective computational behavior and effectiveness, and decreases the time and increases the quality of color image segmentation in comparison with the state-of-the-art segmentation methods recently proposed in the literature. (C) 2012 Elsevier Ltd. All rights reserved.', 'Automatic color-texture image segmentation by using active contours In this paper, we propose a novel method for unsupervised color-texture segmentation. The approach aims at combining color and texture features and active contours to build a fully automatic segmentation algorithm. By fully automatic, we mean the steps of region initialization and calculation of the number of regions are performed automatically by the algorithm. Furthermore, the approach combines boundary and region information for accurate region boundary localization. We validate the approach by examples of synthetic and natural color-texture image segmentation.']"
49,265,49_recognition_recognizing_feature_interaction,"['recognition', 'recognizing', 'feature', 'interaction', 'features', 'detection', 'human', 'model', 'activity', 'attention']","['A study on attention-based LSTM for abnormal behavior recognition with variable pooling (c) 2021 Elsevier B.V. All rights reserved. Behavior recognition is a well-known computer vision mobile technology. It has been used in many applications such as video surveillance, motion detection on devices, human-computer interaction and sports video, etc. How-ever, most of the existing works ignored the depth and spatio-temporal information so that they resulted in over-fitting and inferior performance. Consequently, a novel framework for behavior recognition is proposed in this paper. In this framework, we propose a target depth estimation algorithm to calculate the 3D spatial position in-formation of the target, and take this information as the input of the behavior recognition model. Simultaneously, in order to obtain more Spatio-temporal information and better handle long-term video, combining with the idea of attention mechanism, we propose a skeleton behavior recognition model which is based on spatio-temporal convolution and attention-based LSTM (ST-CNN & ATT-LSTM). The deep spatial information is merged into each segment, and the model focuses on the key information extraction, which is essential for improving behav-ior recognition performance. Meanwhile, we use a feature compression method based on variable pooling to solve the problem of inconsistent input sizes caused by multi-person behavior recognition, so that the network can flexibly recognize multi-person skeleton sequences. Finally, the proposed framework is evaluated with real-world surveillance video data, and the results indicate that our framework is superior to existing methods.', 'A fast human action recognition network based on spatio-temporal features (c) 2020 Elsevier B.V. All rights reserved. Artificial intelligence models are widely used in the field of human activity recognition, and human action recognition is an important aspect of human activity recognition. The core of human action recognition is to understand the temporal relationship between video frames. Almost all state-of-the-art methods of human action recognition in videos use optical flow. However, traditional local optical flow estimation methods areexpensive and not trained end-to-end. In this paper, we propose a fast network for human action recognition. Our purpose is to improve the efficiency of optical flow feature extraction and explore the fusion method of spatio-temporal features. For spatio-temporal features, our method combines spatial features and temporal features into fusion features. In addition, we propose CNN with OFF instead of the VGG16 network, which is used to process optical flow features to obtain abundant features. Our model only needs RGB inputs to get the state-of-the-art accuracy of 91.5% on UCF-101, 67.9% on HMDB51, 83.3% on MSR Daily Activity3D, and 91.25% on Florence 3D action, respectively. Compared with most state-of-the-art video action recognition models, our proposed model can effectively improve the accuracy of human action recognition.', 'A novel local feature descriptor based on energy information for human activity recognition In this paper we propose a novel local feature descriptor based on energy information for human activity recognition. Instead of detecting spatio-temporal interest points, we combine the kinetic energy, gesture potential energy of 3D skeleton joints and others as a feature matrix. The semantic features are obtained by the Bag of Word (BOW) based on k-means clustering. These features conform to not only kinematics and biology of human action, but also the natural visual saliency for action recognition. During the activity recognition, we first present a temporal segmentation method based on kinetic features of human skeleton to cut the long videos into the sub-action segments. Then the sub-action units are iteratively incorporated in the meaningful groups by considering similarity of feature information. Finally, SVM based on kernel function is used to carry out human activity recognition. The experimental results show that our approach outperforms several state-of-the-art algorithms based on our proposed low dimensional features of energy information.']"
50,263,50_retinal_retinopathy_retina_imaging,"['retinal', 'retinopathy', 'retina', 'imaging', 'optic', 'vision', 'ophthalmologists', 'eye', 'glaucoma', 'macular']","['A Fundus Retinal Vessels Segmentation Scheme Based on the Improved Deep Learning U-Net Model Retinal vascular segmentation is very important for diagnosing fundus diseases. However, the existing methods of retinal vascular segmentation have some problems, such as low microvascular segmentation and wrong segmentation of pathological information. To solve these problems, we developed a fundus retinal vessels segmentation based on the improved deep learning U-Net model. First, enhance the retinal images. Second, add the residual module in the process of designing the network structure, which solved the problem of the traditional deep learning U-Net model is not deep enough. By using the improved deep learning U-Net model, it can connect the output of the convolutional layer with the output of the deconvolution layer to avoid low-level information sharing, and solved the problem of performance degradation of deep convolutional neural networks in residual networks under extreme depth conditions. By verifying on the DRIVE (digital retinal images for vessel extraction) dataset, the segmentation accuracy, sensitivity, and specificity of the proposed method are 96.50%, 93.1%, and 98.63% respectively.', 'A Deep Ensemble Learning-Based CNN Architecture for Multiclass Retinal Fluid Segmentation in OCT Images Retinal Fluids (fluid collections) develop because of the accumulation of fluid in the retina, which may be caused by several retinal disorders, and can lead to loss of vision. Optical coherence tomography (OCT) provides non-invasive cross-sectional images of the retina and enables the visualization of different retinal abnormalities. The identification and segmentation of retinal cysts from OCT scans is gaining immense attention since the manual analysis of OCT data is time consuming and requires an experienced ophthalmologist. Identification and categorization of the retinal cysts aids in establishing the pathophysiology of various retinal diseases, such as macular edema, diabetic macular edema, and age-related macular degeneration. Hence, an automatic algorithm for the segmentation and detection of retinal cysts would be of great value to the ophthalmologists. In this study, we have proposed a convolutional neural network-based deep ensemble architecture that can segment the three different types of retinal cysts from the retinal OCT images. The quantitative and qualitative performance of the model was evaluated using the publicly available RETOUCH challenge dataset. The proposed model outperformed the state-of-the-art methods, with an overall improvement of 1.8%.', 'Segmentation of retinal blood vessels from ophthalmologic Diabetic Retinopathy images The most prominent ophthalmic cause of blindness is Diabetic Retinopathy (DR). This retinal disease is characterized by variation in diameter of the retinal blood vessel and the new blood vessel growth inside the retina. A system to enhance the quality of the segmentation result over the pathological retinal images has been proposed. The proposed method uses Contrast Limited Adaptive Histogram Equalization (CLAHE) for preprocessing and Tandem Pulse Coupled Neural Network (TPCNN) model for automatic feature vectors generation then classification and extraction of the retinal blood vessels via Deep Learning Based Support Vector Machine (DLBSVM). The proposed approach is assessed over the standard public fundus image databases to evaluate the performance. The results render that these techniques improve the segmentation results with an average value of 74.45% sensitivity, 99.40% specificity, and 99.16% accuracy. The results evoke that the proposed method is a suitable alternative for supervised techniques. (C) 2018 Elsevier Ltd. All rights reserved.']"
51,261,51_clustering_mapping_topology_maps,"['clustering', 'mapping', 'topology', 'maps', 'map', 'multidimensional', 'cluster', 'topological', 'dimensional', 'algorithms']","['Constrained Self Organizing Maps for Data Clusters Visualization High dimensional data visualization is one of the main tasks in the field of data mining and pattern recognition. The self organizing maps (SOM) is one of the topology visualizing tool that contains a set of neurons that gradually adapt to input data space by competitive learning and form clusters. The topology preservation of the SOM strongly depends on the learning process. Due to this limitation one cannot guarantee the convergence of the SOM in data sets with clusters of arbitrary shape. In this paper, we introduce Constrained SOM (CSOM), the new version of the SOM by modifying the learning algorithm. The idea is to introduce an adaptive constraint parameter to the learning process to improve the topology preservation and mapping quality of the basic SOM. The computational complexity of the CSOM is less than those with the SOM. The proposed algorithm is compared with similar topology preservation algorithms and the numerical results on eight small to large real-world data sets demonstrate the efficiency of the proposed algorithm.', ""A combined measure for quantifying and qualifying the topology preservation of growing self-organizing maps The Self-Organizing Map (SOM) is a neural network model that performs an ordered projection of a high dimensional input space in a low-dimensional topological structure. The process in which such mapping is formed is defined by the SOM algorithm, which is a competitive, unsupervised and nonparametric method, since it does not make any assumption about the input data distribution. The feature maps provided by this algorithm have been successfully applied for vector quantization, clustering and high dimensional data visualization processes. However, the initialization of the network topology and the selection of the SOM training parameters are two difficult tasks caused by the unknown distribution of the input signals. A misconfiguration of these parameters can generate a feature map of low-quality, so it is necessary to have some measure of the degree of adaptation of the SOM network to the input data model. The topology preservation is the most common concept used to implement this measure. Several qualitative and quantitative methods have been proposed for measuring the degree of SUM topology preservation, particularly using Kohonen's model. In this work, two methods for measuring the topology preservation of the Growing Cell Structures (GCSs) model are proposed: the topographic function and the topology preserving map. (C) 2011 Elsevier B.V. All rights reserved."", 'SOM of SOMs This paper proposes an extension of the self-organizing map (SOM), in which the mapping objects themselves are self-organizing maps. Thus a """"SOM of SOMs"""" is presented, which we refer to as a SOM(2). A SOM(2) has a hierarchical structure consisting of a single parent SOM and a set of child SOMs. Each child SOM is trained to represent the distribution of a data class in a manifold, while the parent SOM generates a self-organizing map of the group of manifolds modeled by the child SOMs. Thus a SOM(2) is an architecture that organizes a product manifold represented as (child SOM) x (parent SOM). Such a product manifold is called a fiber bundle in terms of the topology. This extension of a SOM is easily generalized to any combination of SOM families, including cases of neural gas (NG) in which, for example, """"NG(2) (=NG x NG) as an NG of NGs"""" and """"NG x SOM as a SOM of NGs"""" are possible. Furthermore, a SOM(2) can be extended to a SOM(n), such as SOM(3) = SOM x SOM x SOM defined as a """"SOM of SOM(2)"""". In this paper, the algorithms for the SOM(2) and its variations are introduced, and some simulation results are reported. (C) 2009 Elsevier Ltd. All rights reserved.']"
52,259,52_classifiers_multiclass_classifier_classification,"['classifiers', 'multiclass', 'classifier', 'classification', 'ensembles', 'class', 'selection', 'classes', 'learning', 'generalization']","['Multi-train: A semi-supervised heterogeneous ensemble classifier Many real-world machine learning tasks have very limited labeled data but a large amount of unlabeled data. To take advantage of the unlabeled data for enhancing learning performance, several semi supervised learning techniques have been developed. In this paper, we propose a novel semi-supervised ensemble learning algorithm, termed Multi-Train, which generates a number of heterogeneous classifiers that use different classification models and/or different features. During the training process, each classifier is refined using unlabeled data, which are labeled by the majority prediction of the rest classifiers. We hypothesize that the use of different models and different input features can promote the diversity of the ensemble, thereby improving the performance compared to existing methods such as the co-training and tri-training algorithms. Experimental results on the UCI datasets clearly demonstrated the effectiveness of using heterogeneous ensembles in semi-supervised learning. (C) 2017 Elsevier B.V. All rights reserved.', 'A spectral clustering based ensemble pruning approach This paper introduces a novel bagging ensemble classifier pruning approach. Most investigated pruning approaches employ heuristic functions to rank classifiers in the ensemble, and select part of them from the ranked ensemble, so redundancy may exist in the selected classifiers. Based on the idea that the selected classifiers should be accurate and diverse, we define classifier similarity according to the predictive accuracy and the diversity, and introduce a Spectral Clustering based classifier selection approach (SC). SC groups the classifiers into two clusters based on the classifier similarity, and retains one cluster of classifiers in the ensemble. Experimental results show that SC is competitive in terms of classification accuracy. (C) 2014 Elsevier B.V. All rights reserved.', 'Classifier ensemble methods in feature selection Feature selection has become an indispensable preprocessing step in an expert system. Improving the feature selection performance could guide such a system to make better decisions. Classifier ensembles are known to improve performance when compared to the use of a single classifier. In this study, we aim to perform a formal comparison of different classifier ensemble methods on the feature selection domain. For this purpose, we compare the performances of six classifier ensemble methods: a greedy approach, two average-based approaches, two majority voting approaches, and a meta-classifier approach. In our study, the classifier ensemble involves five machine learning techniques: Logistic Regression, Support Vector Machines, Extreme Learning Machine, Naive Bayes, and Decision Tree. Experiments are carried on 12 well-known datasets, and results with statistical tests are provided. The results indicate that ensemble methods perform better than single classifiers, yet, they require a longer execution time. Moreover, they can minimize the number of features better than existing ensemble algorithms, namely Random Forest, AdaBoost, and Gradient Boosting, in a less amount of time. Among ensemble methods, the greedy based method performs well in terms of both classification accuracy and execution time. (c) 2020 Elsevier B.V. All rights reserved.']"
53,258,53_faults_fault_detection_classification,"['faults', 'fault', 'detection', 'classification', 'diagnostic', 'reliability', 'diagnosis', 'algorithm', 'accuracy', 'identification']","['Multi-fault diagnosis for rotating machinery based on orthogonal supervised linear local tangent space alignment and least square support vector machine In order to improve the accuracy of fault diagnosis, this article proposes a multi-fault diagnosis method for rotating machinery based on orthogonal supervised linear local tangent space alignment (OSLLTSA) and least square support vector machine (LS-SVM). First, the collected vibration signals are decomposed by empirical model decomposition (EMD), and a high-dimensional feature set is constructed by extracting statistical features, autoregressive (AR) coefficients and instantaneous amplitude Shannon entropy from those intrinsic model functions (IMFs) that contain most fault information. Then, the high-dimensional feature set is inputted into OSLLTSA for dimension reduction to yield more sensitive low-dimensional fault features, which not only achieves the combination of intrinsic structure information and class label information of dataset but also improves the discrimination of the low-dimensional fault features. Further, the low-dimensional fault features are inputted to LS-SVM to recognize machinery faults according to the LS-SVM parameters selected by enhanced particle swarm optimization (EPSO). Finally, the performance of the proposed method is verified by a fault diagnosis case in a rolling element bearing, and the results confirm the improved accuracy of fault diagnosis. (C) 2015 Elsevier B.V. All rights reserved.', 'A novel optimized SVM classification algorithm with multi-domain feature and its application to fault diagnosis of rolling bearing Sensitive feature extraction from the raw vibration signal is still a great challenge for intelligent fault diagnosis of rolling bearing. Current fault classification framework generally concentrates on the pattern of classifier with single-domain feature, which is easy to induce insufficient feature extraction and low recognition accuracy. Therefore, to address this issue and improve intelligent diagnostic accuracy of rolling bearing, this paper proposes a novel fault classification algorithm based on optimized SVM with multi-domain feature, which mainly consists of three stages (i.e. multi-domain feature extraction, feature selection and fault identification). In this first stage, three approaches (i.e. statistical analysis, FFT and VMD) are separately applied to extract the fault feature information from multi-domain aspect (e.g. time-domain, frequency-domain and time-frequency domain), which can excavate comprehensively the condition information and intrinsic property of the raw vibration signal. Secondly, Laplace score algorithm is introduced to select automatically the meaningful sensitive feature according to the importance of each feature, which is aimed at removing some redundant information and improving the calculation efficiency. Finally, particle swarm optimization-based support vector machine (PSO-SVM) classification model is employed to implement the identification of multiple fault condition of rolling bearing. Performance of the proposed method is evaluated on two experimental examples of rolling bearing fault diagnosis. Experimental results show that the proposed method achieves high diagnosis accuracy for different working conditions of rolling bearing and outperforms some traditional methods both mentioned in this paper and published in other literature. (C) 2018 Elsevier B.V. All rights reserved.', 'An intelligent fault diagnosis model based on deep neural network for few-shot fault diagnosis The most existing deep neural networks (DNN)-based methods for fault diagnosis only focus on prediction accuracy without considering the limitation of labeled sample size. In practical applications of DNNbased methods, it is time-consuming and costly to collect massive labeled samples. In this paper a task named few-shot fault diagnosis is defined as training model given small labeled samples in source domain and testing given small samples in target domain. We develop a novel intelligent fault diagnosis model for few-shot fault diagnosis which is using similarities of sample pairs to classify samples, rather than end-to-end classification. The proposed model contains modules of feature learning and metric learning. The module of feature learning has twin neural networks aiming to extract features from the sample pair. The module of metric learning is to predict similarity of the sample pair. The similarities of sample pairs combined the test sample with each labelled sample are utilized to complete the classification task. Label smoothing is utilized to further improve performance of classification. The performance of the proposed model is verified by two fault diagnosis cases which are bearing fault diagnosis cross different working conditions and cross bearing locations. The comparison studies with other models demonstrate the superiority of the proposed model. (c) 2021 Elsevier B.V. All rights reserved.']"
54,258,54_sclerosis_mri_ms_imaging,"['sclerosis', 'mri', 'ms', 'imaging', 'diseases', 'disease', 'diagnosis', 'scans', 'clinical', 'lesions']","['Automated detection of multiple sclerosis lesions in serial brain MRI This paper presents an up-to-date review of the approaches which deal with the time-series analysis of brain MRI for detecting active MS lesions and quantifying lesion load change. We provide a comprehensive reference source for researchers in which several approaches to change detection and quantification of MS lesions are investigated and classified. We also analyze the results provided by the approaches, discuss open problems, and point out possible future trends. Time-series analysis of images is widely used for MS diagnosis and patient follow-up. However, conventional manual methods are time-consuming, subjective, and error-prone. Thus, the development of automated techniques for the detection and quantification of MS lesions is a major challenge. Multiple sclerosis (MS) is a serious disease typically occurring in the brain whose diagnosis and efficacy of treatment monitoring are vital. Magnetic resonance imaging (MRI) is frequently used in serial brain imaging due to the rich and detailed information provided. Lesion detection approaches are required for the detection of static lesions and for diagnostic purposes, while either quantification of detected lesions or change detection algorithms are needed to follow up MS patients. However, there is not yet a single approach that can emerge as a standard for the clinical practice, automatically providing an accurate MS lesion evolution quantification. Future trends will focus on combining the lesion detection in single studies with the analysis of the change detection in serial MRI.', 'Machine Learning Approaches in Study of Multiple Sclerosis Disease Through Magnetic Resonance Images Multiple sclerosis (MS) is one of the most common autoimmune diseases which is commonly diagnosed and monitored using magnetic resonance imaging (MRI) with a combination of clinical manifestations. The purpose of this review is to highlight the main applications of Machine Learning (ML) models and their performance in the MS field using MRI. We reviewed the articles of the last decade and grouped them based on the applications of ML in MS using MRI data into four categories: 1) Automated diagnosis of MS, 2) Prediction of MS disease progression, 3) Differentiation of MS stages, 4) Differentiation of MS from similar disorders.', ""Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images: Techniques and Clinical Applications Multiple sclerosis (MS) is a chronic inflammatory and degenerative disease of the central nervous system, characterized by the appearance of focal lesions in the white and gray matter that topographically correlate with an individual patient's neurological symptoms and signs. Magnetic resonance imaging (MRI) provides detailed in-vivo structural information, permitting the quantification and categorization of MS lesions that critically inform disease management. Traditionally, MS lesions have been manually annotated on 2D MRI slices, a process that is inefficient and prone to inter-/intra-observer errors. Recently, automated statistical imaging analysis techniques have been proposed to detect and segment MS lesions based on MRI voxel intensity. However, their effectiveness is limited by the heterogeneity of both MRI data acquisition techniques and the appearance of MS lesions. By learning complex lesion representations directly from images, deep learning techniques have achieved remarkable breakthroughs in the MS lesion segmentation task. Here, we provide a comprehensive review of state-of-the-art automatic statistical and deep-learning MS segmentation methods and discuss current and future clinical applications. Further, we review technical strategies, such as domain adaptation, to enhance MS lesion segmentation in real-world clinical settings.""]"
55,246,55_memory_memories_memorized_recall,"['memory', 'memories', 'memorized', 'recall', 'neural', 'associative', 'recurrent', 'recalling', 'episodic', 'neuron']","['A Bidirectional Hetero-Associative Memory for True-Color Patterns Classical bidirectional associative memories (BAM) have poor memory storage capacity, are sensitive to noise, are subject to spurious steady states during recall, and can only recall bipolar patterns. In this paper, we introduce a new bidirectional hetero-associative memory model for true-color patterns that uses the associative model with dynamical synapses recently introduced in Vazquez and Sossa (Neural Process Lett, Submitted, 2008). Synapses of the associative memory could be adjusted even after the training phase as a response to an input stimulus. Propositions that guarantee perfect and robust recall of the fundamental set of associations are provided. In addition, we describe the behavior of the proposed associative model under noisy versions of the patterns. At last, we present some experiments aimed to show the accuracy of the proposed model with a benchmark of true-color patterns.', 'Hierarchical Associative Memories: The neural network for prediction in spatial maps Techniques for prediction in spatial maps can be based on associative neural network models. Unfortunately, the performance of standard associative memories depends on the number of training patterns stored in the memory; moreover it is very sensitive to mutual correlations of the stored patterns. In order to overcome limitations imposed by processing of a large number of mutually correlated spatial patterns, we have designed the Hierarchical Associative Memory model which consists of arbitrary number of associative memories hierarchically grouped into several layers. In order to further improve its recall abilities, we have proposed new modification of our model. In this paper, we also present experimental results focused on recall ability of designed model and their analysis by means of mathematical statistics.', 'Associative memory network and its hardware design In order to improve the performance of the conventional associative memory network, a novel associative memory network composed of input layer, computing layer, associative layer and output layer is proposed. An improved Hebb learning rule is designed for the associative network to perform the associative memory of strong correlation and multi-valued sample patterns. The associative memory can be performed by the associative network in only one forward calculation. The hardware circuit of the network can be designed by simple devices to ensure its parallel computation ability and meet the real-time requirement. Simulation results show that the network has better associative performance than conventional associative network in the binary patterns associative memory, it can store and associate strong correlation sample patterns, and it can retrieve the distortion multi-valued sample patterns with 40% noise correctly. (C) 2015 Elsevier B.V. All rights reserved.']"
56,245,56_tracking_tracker_trackers_tracked,"['tracking', 'tracker', 'trackers', 'tracked', 'visual', 'adaptive', 'detection', 'model', 'vision', 'robustness']","['Real-time object tracking via self-adaptive appearance modeling One of the main factors that limit the accuracy and robustness of visual tracking algorithms is the lack of suitable appearance models. The robustness and effectiveness of object appearance models is severely affected by the changing object appearances during the tracking process and the interference of other similar objects around the truth object. In this paper, a self-adaptive appearance model pool based on multi-sample is constructed to improve the robustness of the object appearance models. In order to deal with variable object states, the initial sample given in the first frame and the samples generated in the subsequent tracking process are combined into a sample set to represent various appearances of the object. In addition, a dynamic selection strategy is explored to update and maintain the sample components that are derived from varieties of sources. In order to distinguish the tracking object from other similar candidate objects, multi-feature response fusion strategy is proposed, which can effectively im prove the expression ability of the appearance model. Extensive experiments on the popular benchmark datasets demonstrate that the proposed tracking approach performs favorably against several other state-of-the-art tracking algorithms. (C) 2019 Elsevier B.V. All rights reserved.', 'Robust visual tracking by metric learning with weighted histogram representations Measuring the similarity between the target template and a target candidate is a critical issue in visual tracking. An appropriate similarity metric can improve the accuracy and robustness of visual tracking. This paper proposes a robust visual tracking algorithm that incorporates online distance metric learning into visual tracking based on a particle filter framework. The appearance variations of an object are effectively learned via an online metric learning mechanism. In addition, we use spatially weighted feature representations using both color and spatial information of objects, which can further improve the tracking performance. The proposed algorithm is compared with several state-of-the-art tracking algorithms, and experimental results on challenging video sequences demonstrate the effectiveness and robustness of the proposed tracking algorithm. (C) 2014 Elsevier B.V. All rights reserved.', 'Robust feature learning for online discriminative tracking without large-scale pre-training Owing to the inherent lack of training data in visual tracking, recent work in deep learning-based trackers has focused on learning a generic representation offline from large-scale training data and transferring the pre-trained feature representation to a tracking task. Offline pre-training is time-consuming, and the learned generic representation may be either less discriminative for tracking specific objects or overfitted to typical tracking datasets. In this paper, we propose an online discriminative tracking method based on robust feature learning without large-scale pre-training. Specifically, we first design a PCA filter bank-based convolutional neural network (CNN) architecture to learn robust features online with a few positive and negative samples in the high-dimensional feature space. Then, we use a simple soft-thresholding method to produce sparse features that are more robust to target appearance variations. Moreover, we increase the reliability of our tracker using edge information generated from edge box proposals during the process of visual tracking. Finally, effective visual tracking results are achieved by systematically combining the tracking information and edge box-based scores in a particle filtering framework. Extensive results on the widely used online tracking benchmark (OTB-50) with 50 videos validate the robustness and effectiveness of the proposed tracker without large-scale pre-training.']"
57,229,57_visualization_visual_perception_attentional,"['visualization', 'visual', 'perception', 'attentional', 'visually', 'vision', 'focus', 'stimulus', 'cognitive', 'modeling']","['A visual attention model based on hierarchical spiking neural networks Based on the information processing functionalities of spiking neurons, hierarchical spiking neural networks are proposed to simulate visual attention. Using spiking neural networks inspired by the visual system, an image can be decomposed into multiple visual image components. Based on specific visual image components and image features, a visual attention system is proposed to extract attention areas according to top-down volition-controlled signals. The hierarchical spiking neural networks are constructed with a conductance-based integrate-and-fire neuron model and a set of specific receptive fields in different levels. The simulation algorithm and properties of the networks are detailed in this paper. Simulation results show that the attention system is able to perform visual attention of objects based on specific image components or features, and a demonstration shows how the attention system can detect a house in a visual image. Using the proposed saliency index, attention areas of interest can be extracted from spike rate maps of multiple visual pathways, such as ON/OFF colour pathways. According to this visual attention principle, the visual image processing system can quickly focus on specific areas while ignoring other areas. (C) 2012 Elsevier B.V. All rights reserved.', 'MODELING VISUAL-ATTENTION VIA SELECTIVE TUNING A model for aspects of visual attention based on the concept of selective tuning is presented. It provides for a solution to the problems of selection in an image, information routing through the visual processing hierarchy and task-specific attentional bias. The central thesis is that attention acts to optimize the search procedure inherent in a solution to vision. It does so by selectively tuning the visual processing network which is accomplished by a top-down hierarchy of winner-take-all processes embedded within the visual processing pyramid. Comparisons to other major computational models of attention and to the relevant neurobiology are included in detail throughout the paper. The model has been implemented; several examples of its performance are shown. This model is a hypothesis for primate visual attention, but it also outperforms existing computational solutions for attention in machine vision and is highly appropriate to solving the problem in a robot vision system.', 'A computer vision system for rapid search inspired by surface-based attention mechanisms from human perception Humans are highly efficient at visual search tasks by focusing selective attention on a small but relevant region of a visual scene. Recent results from biological vision suggest that surfaces of distinct physical objects form the basic units of this attentional process. The aim of this paper is to demonstrate how such surface-based attention mechanisms can speed up a computer vision system for visual search. The system uses fast perceptual grouping of depth cues to represent the visual world at the level of surfaces. This representation is stored in short-term memory and updated over time. A top-down guided attention mechanism sequentially selects one of the surfaces for detailed inspection by a recognition module. We show that the proposed attention framework requires little computational overhead (about 11 ms), but enables the system to operate in real-time and leads to a substantial increase in search efficiency. (C) 2014 Elsevier Ltd. All rights reserved.']"
58,217,58_virtual_perception_reality_visual,"['virtual', 'perception', 'reality', 'visual', 'perceived', 'stimuli', 'sensory', 'immersive', 'experience', 'avatar']","['Navigating through a virtual city: Using virtual reality technology to study human action and perception The introduction of virtual reality technology in the field of human perception and behaviour research has spawned many new research initiatives. The paper outlines the motivations of researchers in this field to start using virtual environments for their studies by presenting two such studies conducted in our laboratory. First, we discuss how we are building a large virtual model of the city of Tubingen and how we are using it for sur research on human navigation behaviour. Second, we present data on the phenomenon that observers tend to underestimate the perceived speed of their movement through a virtual environment, and we discuss what implications these results have for the design of virtual environments. (C) 1998 Elsevier Science B.V.', ""The Effects of Visuomotor Calibration to the Perceived Space and Body, through Embodiment in Immersive Virtual Reality We easily adapt to changes in the environment that involve cross-sensory discrepancies (e.g., between vision and proprioception). Adaptation can lead to changes in motor commands so that the experienced sensory consequences are appropriate for the new environment (e.g., we program a movement differently while wearing prisms that shift our visual space). In addition to these motor changes, perceptual judgments of space can also be altered (e.g., how far can I reach with my arm?). However, in previous studies that assessed perceptual judgments of space after visuomotor adaptation, the manipulation was always a planar spatial shift, whereas changes in body perception could not directly be assessed. In this study, we investigated the effects of velocity dependent (spatiotemporal) and spatial scaling distortions of arm movements on space and body perception, taking advantage of immersive virtual reality. Exploiting the perceptual illusion of embodiment in an entire virtual body, we endowed subjects with new spatiotemporal or spatial 3D mappings between motor commands and their sensory consequences. The results imply that spatiotemporal manipulation of 2 and 4 times faster can significantly change participants' proprioceptive judgments of a virtual object's size without affecting the perceived body ownership, although it did affect the agency of the movements. Equivalent spatial manipulations of 11 and 22 degrees of angular offset also had a significant effect on the perceived virtual object's size; however, the mismatched information did not affect either the sense of body ownership or agency. We conclude that adaptation to spatial and spatiotemporal distortion can similarly change our perception of space, although spatiotemporal distortions can more easily be detected."", ""Virtual Embodiment Using 180 degrees Stereoscopic Video One of the most exciting possibilities of virtual reality is inducing in participants the illusion of owning a virtual body. This has become an established methodological paradigm allowing the study of the psychological and neural correlates of various scenarios that are impossible in the real world, such as gender or age switching. Thus far, full-body ownership illusions have been implemented by using real-time body tracking and avatars based on computer-generated imagery (CGI). We propose an alternative technique to induce perceived ownership over a (photorealistic) virtual body using 180 degrees stereoscopic video, synchronous touch, and narration. We describe the technical components of our novel technique and an example implementation as part of a science-art project that enables participants to experience virtual bodies of different ages, and present the results of an experimental evaluation study based on this experience. Consistent with previous virtual embodiment studies using CGI-based techniques, we found that participants accept a photorealistic virtual body as their own irrespective of its appearance as indicated by similar ratings of the strength of body ownership over a virtual body of a child versus an adult. We further show that our novel technique can alter participants' cognition in accordance with the characteristics of their virtual body. Specifically, young adult participants who were embodied in the virtual body of a child significantly overestimated the duration of the virtual reality experience compared to a control group who was embodied in a virtual body of their own age. This finding corresponds to chronological age differences in time estimations and extends previous research on virtual child embodiment. Overall, these findings provide initial evidence for the potential of our novel technique to create photorealistic embodiment experiences with comparable psychological effects as have been found using CGI-based techniques while reducing the costs and technical complexity in the production and application of virtual body ownership illusions.""]"
59,211,59_neuroinformatics_neuroscientists_neuroscience_neuroimaging,"['neuroinformatics', 'neuroscientists', 'neuroscience', 'neuroimaging', 'brain', 'neuropycon', 'researchers', 'data', 'informatics', 'research']","[""A Neuroimaging Web Services Interface as a Cyber Physical System for Medical Imaging and Data Management in Brain Research: Design Study Background: Structural and functional brain images are essential imaging modalities for medical experts to study brain anatomy. These images are typically visually inspected by experts. To analyze images without any bias, they must be first converted to numeric values. Many software packages are available to process the images, but they are complex and difficult to use. The software packages are also hardware intensive. The results obtained after processing vary depending on the native operating system used and its associated software libraries; data processed in one system cannot typically be combined with data on another system. Conclusions: To our knowledge, there is no validated Web-based system offering all the services that Neuroimaging Web Services Interface offers. The intent of Neuroimaging Web Services Interface is to create a tool for clinicians and researchers with keen interest on multimodal neuroimaging. More importantly, Neuroimaging Web Services Interface significantly augments the Alzheimer's Disease Neuroimaging Initiative data, especially since our data contain a large cohort of Hispanic normal controls and Alzheimer's Disease patients. The obtained results could be scrutinized visually or through the tabulated forms, informing researchers on subtle changes that characterize the different stages of the disease. Methods: Neuroimaging Web Services Interface accepts magnetic resonance imaging, positron emission tomography, diffusion tensor imaging, and functional magnetic resonance imaging. These images are processed using existing and custom software packages. The output is then stored as image files, tabulated files, and MySQL tables. The system, made up of a series of interconnected servers, is password-protected and is securely accessible through a Web interface and allows (1) visualization of results and (2) downloading of tabulated data. Objective: The aim of this study was to fulfill the neuroimaging community's need for a common platform to store, process, explore, and visualize their neuroimaging data and results using Neuroimaging Web Services Interface: a series of processing pipelines designed as a cyber physical system for neuroimaging and clinical data in brain research. Results: All results were obtained using our processing servers in order to maintain data validity and consistency. The design is responsive and scalable. The processing pipeline started from a FreeSurfer reconstruction of Structural magnetic resonance imaging images. The FreeSurfer and regional standardized uptake value ratio calculations were validated using Alzheimer's Disease Neuroimaging Initiative input images, and the results were posted at the Laboratory of Neuro Imaging data archive. Notable leading researchers in the field of Alzheimer's Disease and epilepsy have used the interface to access and process the data and visualize the results. Tabulated results with unique visualization mechanisms help guide more informed diagnosis and expert rating, providing a truly unique multimodal imaging platform that combines magnetic resonance imaging, positron emission tomography, diffusion tensor imaging, and resting state functional magnetic resonance imaging. A quality control component was reinforced through expert visual rating involving at least 2 experts."", 'Towards structured sharing of raw and derived neuroimaging data across existing resources Data sharing efforts increasingly contribute to the acceleration of scientific discovery. Neuroimaging data is accumulating in distributed domain-specific databases and there is currently no integrated access mechanism nor an accepted format for the critically important meta-data that is necessary for making use of the combined, available neuroimaging data. In this manuscript, we present work from the Derived Data Working Group, an open-access group sponsored by the Biomedical Informatics Research Network (BIRN) and the International Neuroimaging Coordinating Facility (INCF) focused on practical tools for distributed access to neuroimaging data. The working group develops models and tools facilitating the structured interchange of neuroimaging meta-data and is making progress towards a unified set of tools for such data and meta-data exchange. We report on the key components required for integrated access to raw and derived neuroimaging data as well as associated meta-data and provenance across neuroimaging resources. The components include (1) a structured terminology that provides semantic context to data, (2) a formal data model for neuroimaging with robust tracking of data provenance, (3) a web service-based application programming interface (API) that provides a consistent mechanism to access and query the data model, and (4) a provenance library that can be used for the extraction of provenance data by image analysts and imaging software developers. We believe that the framework and set of tools outlined in this manuscript have great potential for solving many of the issues the neuroimaging community faces when sharing raw and derived neuroimaging data across the various existing database systems for the purpose of accelerating scientific discovery. Published by Elsevier Inc.', 'Data sharing in neuroimaging research Significant resources around the world have been invested in neuroimaging studies of brain function and disease. Easier access to this large body of work should have profound impact on research in cognitive neuroscience and psychiatry, leading to advances in the diagnosis and treatment of psychiatric and neurological disease. A trend toward increased sharing of neuroimaging data has emerged in recent years. Nevertheless, a number of barriers continue to impede momentum. Many researchers and institutions remain uncertain about how to share data or lack the tools and expertise to participate in data sharing. The use of electronic data capture (EDC) methods for neuroimaging greatly simplifies the task of data collection and has the potential to help standardize many aspects of data sharing. We review here the motivations for sharing neuroimaging data, the current data sharing landscape, and the sociological or technical barriers that still need to be addressed. The INCF Task Force on Neuroimaging Datasharing, in conjunction with several collaborative groups around the world, has started work on several tools to ease and eventually automate the practice of data sharing. It is hoped that such tools will allow researchers to easily share raw, processed, and derived neuroirnaging data, with appropriate metadata and provenance records, and will improve the reproducibility of neuroimaging studies. By providing seamless integration of data sharing and analysis tools within a commodity research environment, the Task Force seeks to identify and minimize barriers to data sharing in the field of neuroimaging']"
60,208,60_fatigue_fatigued_drivers_sleepiness,"['fatigue', 'fatigued', 'drivers', 'sleepiness', 'driver', 'vehicles', 'drowsiness', 'traffic', 'accidents', 'driving']","[""A novel real-time driving fatigue detection system based on wireless dry EEG Development of techniques for detection of mental fatigue has varied applications in areas where sustaining attention is of critical importance like security and transportation. The objective of this study is to develop a novel real-time driving fatigue detection methodology based on dry Electroencephalographic (EEG) signals. The study has employed two methods in the online detection of mental fatigue: power spectrum density (PSD) and sample entropy (SE). The wavelet packets transform (WPT) method was utilized to obtain the (4-7 Hz), (8-12 Hz) and (13-30 Hz) bands frequency components for calculating corresponding PSD of the selected channels. In order to improve the fatigue detection performance, the system was individually calibrated for each subject in terms of fatigue-sensitive channels selection. Two fatigue-related indexes: ()/ and / were computed and then fused into an integrated metric to predict the degree of driving fatigue. In the case of SE extraction, the mean of SE averaged across two EEG channels ('O1h' and 'O2h') was used for fatigue detection. Ten healthy subjects participated in our study and each of them performed two sessions of simulated driving. In each session, subjects were required to drive simulated car for 90 min without any break. The results demonstrate that our proposed methods are effective for fatigue detection. The prediction of fatigue is consistent with the observation of reaction time that was recorded during simulated driving, which is considered as an objective behavioral measure."", ""Computational Intelligent Brain Computer Interaction and Its Applications on Driving Cognition Driving is one of the most common attention-demanding tasks in daily life. Driver's fatigue, drowsiness, inattention, and distraction are reported a major causal factor in many traffic accidents. Due to the drivers lost their attention, they had markedly reduced the perception, recognition and vehicle control abilities. In recent years, many computational intelligent technologies were developed for preventing traffic accidents caused by driver's inattention. Driver's drowsiness and distraction related studies had become a major interest research topic in automotive safety engineering. Many researches had investigated the driving cognition in cognitive neuro-engineering, but how to utilize the main findings of driving-related cognitive researches in traditional cognitive neuroscience and integrate with computational intelligence technologies for augmenting driving performance will become a big challenge in the interdisciplinary research area. For this reason, we attempt to integrate the driving cognition for real life application in this study. The implications of the driving cognition in cognitive neuroscience and computational intelligence for daily applications are also demonstrated through two common attention-related driving studies: (1) cognitive-state monitoring of the driver performing the realistic long-term driving tasks in a simulated realistic-driving environment; and (2) to extract the brain dynamic changes of driver's distraction effect during dual-task driving. Experimental results of these studies provide new insights into the understanding of complex brain functions of participants actively performing ordinary tasks in natural body positions and situations within real operational environments."", ""Analysis of Feature Fatigue EEG Signals Based on Wavelet Entropy Fatigue driving is bringing more and more serious harm, but there are various reasons for fatigue driving, it is still difficult to test the driver's fatigue. This paper defines a method to test driver's fatigue based on the EEG, and different from other researches into fatigue driving, this paper mainly takes the fatigue features of EEG signals in fatigue state and uses wavelet entropy as the feature extraction method to analyze the features of wavelet entropy and spectral entropy features as well as the classification accuracy under the same classifier. The SVM is used to show the classifier's results. The accuracy of the driver fatigue state monitoring using the wavelet entropy is 90.7%, which is higher than the use of spectral entropy as the characteristic accuracy rate of 81.3%. The results show that the frequency characteristics of EEG can be well applied to driving fatigue testing, but different frequency feature calculation methods will affect the classification accuracy.""]"
61,207,61_forecasting_forecast_prediction_predict,"['forecasting', 'forecast', 'prediction', 'predict', 'wind', 'power', 'electricity', 'renewable', 'optimization', 'models']","['Empirical Mode Decomposition based Multi-objective Deep Belief Network for short-term power load forecasting With the rapid development of power grid data, the data generated by the operation of the power system is increasingly complex, and the amount of data increases exponentially. In order to fully exploit and utilize the deep relationship between data to achieve accurate prediction of power load, this paper proposes an Empirical Mode Decomposition Based Multi-objective Deep Belief Network prediction method (EMD-MODBN). In the training process of DBN, a multi-objective optimization model is constructed aiming at accuracy and diversity, and MOEA/D is used to optimize the parameters of the model to enhance the generalization ability of the prediction model. Finally, the final load forecasting results are obtained by summing up the weighted outputs of each forecasting model with ensemble learning method. The experimental results show that compared with several current better load forecasting methods, this method has obvious advantages in prediction accuracy and generalization ability. (C) 2020 Elsevier B.V. All rights reserved.', 'A gated recurrent unit neural networks based wind speed error correction model for short-term wind power forecasting With the growing penetration of wind power, the wind power forecasting is fundamental in aiding the grid scheduling and electricity trading. In this paper, a numerical weather prediction wind speed error correction model based on gated recurrent unit neural networks is proposed for short-term wind power forecasting. Firstly, the standard deviation of numerical weather prediction wind speed error is extracted as weights, and these weights are rearranged according to the numerical weather prediction wind speed time series to get the weight time series. Then, the bidirectional gated recurrent unit neural networks based error correction model is proposed to correct error of numerical weather prediction wind speed with the inputs as numerical weather prediction wind speed, trend and detail terms of the weight time series. The wind power curve model is applied to forecast short-term wind power by using corrected numerical weather prediction wind speed. Finally, the effectiveness of the proposed method is compared with benchmark models by using actual data of wind farm, and the results show that the proposed model outperforms these benchmark models. (C) 2019 Elsevier B.V. All rights reserved.', ""Ultra-short-term wind power forecasting based on deep Bayesian model with uncertainty Wind energy is an important renewable clean energy resource. However, the stochastic and volatile nature of wind power brings significant challenges to the power system's reliable and secure operation. Accurate and reliable wind power prediction is critical for the integration of wind power into the grid. The existing wind power forecasting (WPF) methods lack an assessment of the reliability of the predicted results, which may result in a financial penalty for the wind energy producers. An accurate prediction with reliability measurement is urgently needed to encounter the intricate nature of the problem. In this paper, a Bayesian framework-based bidirectional gated logic unit (BiGRU) method was proposed for ultra-short-term wind power forecasting. First, an encoder-decoder (ED) architecture was combined with a BiGRU time series modeling and feature-temporal attention (FT-Attention) to improve the accuracy of wind power prediction. Then, two uncertainty losses were applied to improve the model's performance further. The proposed method obtains the uncertainty of forecast results, which effectively eliminates the untrusted results. Our proposed method demonstrated promising results for ultra-short-term wind power forecasting due to its competitive performance compared with traditional forecasting methods.""]"
62,207,62_selection_selecting_select_features,"['selection', 'selecting', 'select', 'features', 'classification', 'feature', 'selected', 'learning', 'datasets', 'regression']","['Feature Selection Method Based on Differential Correlation Information Entropy Feature selection is one of the major aspects of pattern classification systems. In previous studies, Ding and Peng recognized the importance of feature selection and proposed a minimum redundancy feature selection method to minimize redundant features for sequential selection in microarray gene expression data. However, since the minimum redundancy feature selection method is used mainly to measure the dependency between random variables of mutual information, the results cannot be optimal without consideration of global feature selection. Therefore, based on the framework of minimum redundancy-maximum correlation, this paper introduces entropy to measure global feature selection and proposes a new feature subset evaluation method, differential correlation information entropy. In our function, different bivariate correlation metrics are selected. Then, the feature selection is completed through sequence forward search. Two different classification models are used on eleven standard data sets of the UCI machine learning knowledge base to compare various comparison algorithms, such as mRMR, reliefF and feature selection method with joint maximal information entropy, with our method. The experimental results show that feature selection based on our proposed method is obviously superior to that of other models.', ""Unsupervised feature selection for visual classification via feature representation property Feature selection is designed to select a subset of features for avoiding the issue of 'curse of dimensionality'. In this paper, we propose a new feature-level self-representation framework for unsupervised feature selection. Specifically, the proposed method first uses a feature-level self-representation loss function to sparsely represent each feature by other features, and then employs an l(2,p)-norm regularization term to yield row-sparsity on the coefficient matrix for conducting feature selection. Experimental results on benchmark databases showed that the proposed method effectively selected the most relevant features than the state-of-the-art methods."", 'Global mutual information-based feature selection approach using single-objective and multi-objective optimization Feature selection is an important preprocessing step in data mining. Mutual information-based feature selection is a kind of popular and effective approaches. In general, most existing mutual information-based techniques are greedy methods, which are proven to be efficient but suboptimal. In this paper, mutual information-based feature selection is transformed into a global optimization problem, which provides a new idea for solving feature selection problems. First, a single-objective feature selection algorithm combining relevance and redundancy is presented, which has well global searching ability and high computational efficiency. Furthermore, to improve the performance of feature selection, we propose a multi-objective feature selection algorithm. The method can meet different requirements and achieve a tradeoff among multiple conflicting objectives. On this basis, a hybrid feature selection framework is adopted for obtaining a final solution. We compare the performance of our algorithm with related methods on both synthetic and real datasets. Simulation results show the effectiveness and practicality of the proposed method. (C) 2015 Elsevier B.V. All rights reserved.']"
63,203,63_stochastic_estimators_delays_nonlinearities,"['stochastic', 'estimators', 'delays', 'nonlinearities', 'estimator', 'delay', 'neural', 'estimation', 'probability', 'uncertainties']","['Stochastic Finite-Time H-infinity State Estimation for Discrete-Time Semi-Markovian Jump Neural Networks With Time-Varying Delays In this article, the finite-time H-infinity state estimation problem is addressed for a class of discrete-time neural networks with semi-Markovian jump parameters and time-varying delays. The focus is mainly on the design of a state estimator such that the constructed error system is stochastically finite-time bounded with a prescribed H-infinity performance level via finite-time Lyapunov stability theory. By constructing a delay-product-type Lyapunov functional, in which the information of time-varying delays and characteristics of activation functions are fully taken into account, and using the Jensen summation inequality, the free weighting matrix approach, and the extended reciprocally convex matrix inequality, some sufficient conditions are established in terms of linear matrix inequalities to ensure the existence of the state estimator. Finally, numerical examples with simulation results are provided to illustrate the effectiveness of our proposed results.', 'Finite-time resilient H-infinity state estimation for discrete-time delayed neural networks under dynamic event-triggered mechanism In this paper, the finite-time resilient H-infinity state estimation problem is investigated for a class of discrete-time delayed neural networks. For the sake of energy saving, a dynamic event-triggered mechanism is employed in the design of state estimator for the discrete-time delayed neural networks. In order to handle the possible fluctuation of the estimator gain parameters when the state estimator is implemented, a resilient state estimator is adopted. By constructing a Lyapunov-Krasovskii functional, a sufficient condition is established, which guarantees that the estimation error system is bounded and the H-infinity performance requirement is satisfied within the finite time. Then, the desired estimator gains are obtained via solving a set of linear matrix inequalities. Finally, a numerical example is employed to illustrate the usefulness of the proposed state estimation scheme. (C) 2019 Elsevier Ltd. All rights reserved.', 'H-infinity state estimation for discrete-time memristive recurrent neural networks with stochastic time-delays This paper deals with the robust H-infinity state estimation problem for a class of memristive recurrent neural networks with stochastic time-delays. The stochastic time-delays under consideration are governed by a Bernoulli-distributed stochastic sequence. The purpose of the addressed problem is to design the robust state estimator such that the dynamics of the estimation error is exponentially stable in the mean square, and the prescribed H-infinity performance constraint is met. By utilizing the difference inclusion theory and choosing a proper Lyapunov-Krasovskii functional, the existence condition of the desired estimator is derived. Based on it, the explicit expression of the estimator gain is given in terms of the solution to a linear matrix inequality. Finally, a numerical example is employed to demonstrate the effectiveness and applicability of the proposed estimation approach.']"
64,202,64_locomotion_controllers_cpg_cpgs,"['locomotion', 'controllers', 'cpg', 'cpgs', 'robot', 'controller', 'robots', 'motions', 'motion', 'movements']","['Multi-layered multi-pattern CPG for adaptive locomotion of humanoid robots In this paper, we present an extended mathematical model of the central pattern generator (CPG) in the spinal cord. The proposed CPG model is used as the underlying low-level controller of a humanoid robot to generate various walking patterns. Such biological mechanisms have been demonstrated to be robust in locomotion of animal. Our model is supported by two neurophysiological studies. The first study identified a neural circuitry consisting of a two-layered CPG, in which pattern formation and rhythm generation are produced at different levels. The second study focused on a specific neural model that can generate different patterns, including oscillation. This neural model was employed in the pattern generation layer of our CPG, which enables it to produce different motion patterns-rhythmic as well as non-rhythmic motions. Due to the pattern-formation layer, the CPG is able to produce behaviors related to the dominating rhythm (extension/flexion) and rhythm deletion without rhythm resetting. The proposed multi-layered multi-pattern CPG model (MLMP-CPG) has been deployed in a 3D humanoid robot (NAO) while it performs locomotion tasks. The effectiveness of our model is demonstrated in simulations and through experimental results.', ""Real-time Walking Pattern Generation for Biped Robot with Hybrid CPG-ZMP Algorithm Biped robots have better mobility than conventional wheeled robots. The bio-inspired method based on a central pattern generator (CPG) can be used to control biped robot walking in a manner like human beings. However, to achieve stable locomotion, it is difficult to modulate the parameters for the neural networks to coordinate every degree of freedom of the walking robot. The zero moment point (ZMP) method is very popular for the stability control of biped robot walking. However, the reference trajectories have low energy efficiency, lack naturalness and need significant offline calculation. This paper presents a new method for biped real-time walking generation using a hybrid CPG-ZMP control algorithm. The method can realize a stable walking pattern by combining the ZMP criterion with rhythmic motion control. The CPG component is designed to generate the desired motion for each robot joint, which is modulated by phase resetting according to foot contact information. By introducing the ZMP location, the activity of the CPG output signal is adjusted to coordinate the limbs' motion and allow the robot to maintain balance during the process of locomotion. The numerical simulation results show that, compared with the CPG method, the new hybrid CPG-ZMP algorithm can enhance the robustness of the CPG parameters and improve the stability of the robot. In addition, the proposed algorithm is more energy efficient than the ZMP method. The results also demonstrate that the control system can generate an adaptive walking pattern through interactions between the robot, the CPG and the environment."", ""CPGs With Continuous Adjustment of Phase Difference for Locomotion Control Regular Paper The central pattern generator (CPG) has been found to be a real, existing neuron controller for the locomotion control of animals and it has been used on bio-inspired robots widely in recent years. However, research on the adaptability of CPG-based locomotion control methods is still a challenge. In particular, the performance of the CPG method on quadruped robots is not good enough in some situations compared with the traditional force control methods. In this article, we adopt a CPG method in which phase difference between oscillators can be arbitrarily adjusted, and we try to improve the CPG's applications in quadruped robots in some aspects. One aspect is static walk gait locomotion, in which we try to add a transition state in the CPG network to enhance the static balance of the robot. Another aspect is gait transition. Compared with the traditional abrupt gait transition, we try to realize a continuous gait transition between walk gait and trot gait to decrease the fluctuations of the robot. The improved CPG method is tested on a quadruped model and it shows positive results with regard to the improvement of static walk gait and gait transitions.""]"
65,199,65_neuromodulation_stimulation_nerve_electrodes,"['neuromodulation', 'stimulation', 'nerve', 'electrodes', 'brain', 'electrode', 'cortex', 'tms', 'conductivity', 'electric']","['Validating computationally predicted TMS stimulation areas using direct electrical stimulation in patients with brain tumors near precentral regions The spatial extent of transcranial magnetic stimulation (TMS) is of paramount interest for all studies employing this method. It is generally assumed that the induced electric field is the crucial parameter to determine which cortical regions are excited. While it is difficult to directly measure the electric field, one usually relies on computational models to estimate the electric field distribution. Direct electrical stimulation (DES) is a local brain stimulation method generally considered the gold standard to map structure-function relationships in the brain. Its application is typically limited to patients undergoing brain surgery. In this study we compare the computationally predicted stimulation area in TMS with the DES area in six patients with tumors near precentral regions. We combine a motor evoked potential (MEP) mapping experiment for both TMS and DES with realistic individual finite element method (FEM) simulations of the electric field distribution during TMS and DES. On average, stimulation areas in TMS and DES show an overlap of up to 80%, thus validating our computational physiology approach to estimate TMS excitation volumes. Our results can help in understanding the spatial spread of TMS effects and in optimizing stimulation protocols to more specifically target certain cortical regions based on computational modeling. (C) 2014 The Authors. Published by Elsevier B.V. on behalf of Federation of European Biochemical Societies.', 'Where does transcranial magnetic stimulation (TMS) stimulate? Modelling of induced field maps for some common cortical and cerebellar targets Computational models have been be used to estimate the electric and magnetic fields induced by transcranial magnetic stimulation (TMS) and can provide valuable insights into the location and spatial distribution of TMS stimulation. However, there has been little translation of these findings into practical TMS research. This study uses the International 10-20 EEG electrode placement system to position a standard figure-of-eight TMS coil over 13 commonly adopted targets. Using a finite element method and an anatomically detailed and realistic head model, this study provides the first pictorial and numerical atlas of TMS-induced electric fields for a range of coil positions. The results highlight the importance of subject-specific gyral folding patterns and of local thickness of subarachnoid cerebrospinal fluid (CSF). Our modelling shows that high electric fields occur primarily on the peaks of those gyri which have only a thin layer of CSF above them. These findings have important implications for inter-individual generalizability of the TMS-induced electric field. We propose that, in order to determine with accuracy the site of stimulation for an individual subject, it is necessary to solve the electric field distribution using subject-specific anatomy obtained from a high-resolution imaging modality such as MRI.', 'The impact of large structural brain changes in chronic stroke patients on the electric field caused by transcranial brain stimulation Transcranial magnetic stimulation (TMS) and transcranial direct current stimulation (TDCS) are two types of non-invasive transcranial brain stimulation (TBS). They are useful tools for stroke research and may be potential adjunct therapies for functional recovery. However, stroke often causes large cerebral lesions, which are commonly accompanied by a secondary enlargement of the ventricles and atrophy. These structural alterations substantially change the conductivity distribution inside the head, which may have potentially important consequences for both brain stimulation methods. We therefore aimed to characterize the impact of these changes on the spatial distribution of the electric field generated by both TBS methods. In addition to confirming the safety of TBS in the presence of large stroke-related structural changes, our aim was to clarify whether targeted stimulation is still possible. Realistic head models containing large cortical and subcortical stroke lesions in the right parietal cortex were created using MR images of two patients. For TMS, the electric field of a double coil was simulated using the finite-element method. Systematic variations of the coil position relative to the lesion were tested. For TDCS, the finite-element method was used to simulate a standard approach with two electrode pads, and the position of one electrode was systematically varied. For both TMS and TDCS, the lesion caused electric field """" hot spots"""" in the cortex. However, these maxima were not substantially stronger than those seen in a healthy control. The electric field pattern induced by TMS was not substantially changed by the lesions. However, the average field strength generated by TDCS was substantially decreased. This effect occurred for both head models and even when both electrodes were distant to the lesion, caused by increased current shunting through the lesion and enlarged ventricles. Judging from the similar peak field strengths compared to the healthy control, both TBS methods are safe in patients with large brain lesions (in practice, however, additional factors such as potentially lowered thresholds for seizure-induction have to be considered). Focused stimulation by TMS seems to be possible, but standard tDCS protocols appear to be less efficient than they are in healthy subjects, strongly suggesting that tDCS studies in this population might benefit from individualized treatment planning based on realistic field calculations.']"
66,195,66_detection_saliency_features_feature,"['detection', 'saliency', 'features', 'feature', 'depth', 'datasets', 'salient', 'modality', 'localization', 'cues']","['Saliency detection integrating both background and foreground information In this paper, we propose a novel saliency detection algorithm. The saliency of an image element is defined not only as its contrast to the background but as its similarity to the foreground. First, we extract background seeds as well as their spatial layout information from image boundaries to compute the background-based saliency map. Second, we generate a compact foreground region from the first-stage saliency map to describe the appearance and location of the salient object and calculate the foreground based saliency map accordingly. We integrate these two saliency maps and further refine the unified one to obtain a more smooth and accurate saliency map. Each component of the presented algorithm is evaluated on the public available datasets and the experimental results also show that the presented algorithm achieves favorable performance compared to the state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.', 'Salient object detection via multi-scale attention CNN Fully convolutional network (FCN) based semantic segmentation models have largely inspired most recent works in the field of salient object detection. However, the lack of context information summarization can degrade the prediction accuracy of the final saliency map. Moreover, the information loss of downsampling operations of FCN-based models results in the loss of details of the final saliency map, such as edges of the saliency object. In this paper, we proposed a novel deep convolutional neural network (CNN) by introducing a spatial and channel-wise attention layer into a multi-scale encoder-decoder framework. The attention CNN layer can align the context information between the feature maps at different scales and the final prediction of the saliency map. In addition, a structure with multiple scale side-way outputs was designed to produce more accurate edge-preserving saliency maps by integrating saliency maps at different scales. Experimental results demonstrated the effectiveness of the proposed model on several benchmark datasets. Additional experimental results also validated the potential and feasibility of applying our trained saliency model to other object-driven vision tasks as an efficient preprocessing step. (C) 2018 Elsevier B.V. All rights reserved.', 'Salient object detection via color and texture cues In this paper, we present a new bottom-up salient object detection approach by constructing two graphs using color and texture features within the manifold ranking framework. First, we calculate the saliency of boundary patches and exclude the ones with high saliency which might be a part of saliency object. Second, we adopt a two-stage scheme for salient detection via affinity propagation clustering and graph-based manifold ranking. The background-based saliency detection aims to obtain the salient object regions as much as possible. In the foreground-based saliency detection, a similar computation is processed as that in the former step and yet slightly different. Instead of simultaneously using all the extracted boundary patches or foreground patches as queries, we compute saliency by using the patches in each cluster in turn and integrating them. At last, the final saliency map is generated by linearly combining two saliency maps respectively exploring color and texture cues. Both qualitative and quantitative evaluations on three publicly available datasets demonstrate the robustness and efficiency of our proposed approach against 21 state-of-the-art methods. (c) 2017 Elsevier B.V. All rights reserved.']"
67,190,67_spinal_spine_vertebrae_vertebral,"['spinal', 'spine', 'vertebrae', 'vertebral', 'vertebra', 'neurological', 'cervical', 'imaging', 'mri', 'surgical']","['Spinal Cord Segmentation in Ultrasound Medical Imagery In this paper, we study and evaluate the task of semantic segmentation of the spinal cord in ultrasound medical imagery. This task is useful for neurosurgeons to analyze the spinal cord movement during and after the laminectomy surgical operation. Laminectomy is performed on patients that suffer from an abnormal pressure made on the spinal cord. The surgeon operates by cutting the bones of the laminae and the intervening ligaments to relieve this pressure. During the surgery, ultrasound waves can pass through the laminectomy area to give real-time exploitable images of the spinal cord. The surgeon uses them to confirm spinal cord decompression or, occasionally, to assess a tumor adjacent to the spinal cord. The Freely pulsating spinal cord is a sign of adequate decompression. To evaluate the semantic segmentation approaches chosen in this study, we constructed two datasets using images collected from 10 different patients performing the laminectomy surgery. We found that the best solution for this task is Fully Convolutional DenseNets if the spinal cord is already in the train set. If the spinal cord does not exist in the train set, U-Net is the best. We also studied the effect of integrating inside both models some deep learning components like Atrous Spatial Pyramid Pooling (ASPP) and Depthwise Separable Convolution (DSC). We added a post-processing step and detailed the configurations to set for both models.', 'Automatic spinal cord localization, robust to MRI contrasts using global curve optimization The algorithm uses a global optimization scheme that attempts to strike a balance between a probabilistic localization map of the spinal cord center point and the overall spatial consistency of the spinal cord centerline (i.e. the rostro-caudal continuity of the spinal cord). Additionally, a new post-processing feature, which aims to automatically split brain and spine regions is introduced, to be able to detect a consistent spinal cord centerline, independently from the field of view. We present data on the validation of the proposed algorithm, known as """"OptiC"""", from a large dataset involving 20 centers, 4 contrasts (T-2-weighted n = 287, T-1-weighted n = 120, T-2*-weighted n = 307, diffusion-weighted n = 90), 501 subjects including 173 patients with a variety of neurologic diseases. Validation involved the gold-standard centerline coverage, the mean square error between the true and predicted centerlines and the ability to accurately separate brain and spine regions. Overall, OptiC was able to cover 98.77% of the gold-standard centerline, with a mean square error of 1.02 mm. OptiC achieved superior results compared to a state-of-the-art spinal cord localization technique based on the Hough transform, especially on pathological cases with an averaged mean square error of 1.08 mm vs. 13.16 mm (Wilcoxon signed-rank test p-value < .01). Images containing brain regions were identified with a 99% precision, on which brain and spine regions were separated with a distance error of 9.37 mm compared to ground-truth. During the last two decades, MRI has been increasingly used for providing valuable quantitative information about spinal cord morphometry, such as quantification of the spinal cord atrophy in various diseases. However, despite the significant improvement of MR sequences adapted to the spinal cord, automatic image processing tools for spinal cord MRI data are not yet as developed as for the brain. There is nonetheless great interest in fully automatic and fast processing methods to be able to propose quantitative analysis pipelines on large datasets without user bias. The first step of most of these analysis pipelines is to detect the spinal cord, which is challenging to achieve automatically across the broad range of MRI contrasts, field of view, resolutions and pathologies. In this paper, a fully automated, robust and fast method for detecting the spinal cord centerline on MRI volumes is introduced. Validation results on a challenging dataset suggest that OptiC could reliably be used for subsequent quantitative analyses tasks, opening the door to more robust analysis on pathological cases. (C) 2017 Elsevier B.V. All rights reserved.', 'Flexion Model Simulating Spinal Cord Injury Without Radiographic Abnormality in Patients With Ossification of the Longitudinal Ligament: The Influence of Flexion Speed on the Cervical Spine Background/Objective: It is suspected that the speed of the motion of the spinal cord under static compression may be the cause of spinal cord injury (SCI). However, little is known about the relationship between the speed of the motion of the spinal cord and its stress distributions. The objective was to carry out a biomechanical study of SCI in patients with ossification of the longitudinal ligament without radiologic evidence of injury. Conclusions: The stress distribution of the spinal cord under static compression increased with faster flexion speed of the spinal cord. High-speed motion of the spinal cord under static compression may be one of the causes of SCI in the absence of radiologic abnormality. Methods: A 3-dimensional finite element spinal cord model was established. After the application of static compression, the model underwent anterior flexion to simulate SCI in ossification of the longitudinal ligament patients without radiologic abnormality. Flexion of the spine was assumed to occur at I motor segment. Flexion angle was 5 degrees, and flexion speeds were 0.5 degrees/s, 5 degrees/s, and 50 degrees/s. Stress distributions inside of the spinal cord were evaluated. Results: Stresses on the spinal cord increased slightly after the application of 5 degrees of flexion at a speed of 0.5 degrees/s. Stresses became much higher at a speed of 5 degrees/s and increased further at 50 degrees s.']"
68,188,68_aging_brainage_ageing_aged,"['aging', 'brainage', 'ageing', 'aged', 'brain', 'lifespan', 'elderly', 'age', 'cognitive', 'ages']","['Predicting brain-age from multimodal imaging data captures cognitive impairment The disparity between the chronological age of an individual and their brain-age measured based on biological information has the potential to offer clinically relevant biomarkers of neurological syndromes that emerge late in the lifespan. While prior brain-age prediction studies have relied exclusively on either structural or functional brain data, here we investigate how multimodal brain-imaging data improves age prediction. Using cortical anatomy and whole-brain functional connectivity on a large adult lifespan sample (N=2354, age 19-82), we found that multimodal data improves brain-based age prediction, resulting in a mean absolute prediction error of 4.29 years. Furthermore, we found that the discrepancy between predicted age and chronological age captures cognitive impairment. Importantly, the brain-age measure was robust to confounding effects: head motion did not drive brain-based age prediction and our models generalized reasonably to an independent dataset acquired at a different site (N=475). Generalization performance was increased by training models on a larger and more heterogeneous dataset. The robustness of multimodal brain-age prediction to confounds, generalizability across sites, and sensitivity to clinically-relevant impairments, suggests promising future application to the early prediction of neurocognitive disorders.', 'Improved prediction of brain age using multimodal neuroimaging data Brain age prediction based on imaging data and machine learning (ML) methods has great potential to provide insights into the development of cognition and mental disorders. Though different ML models have been proposed, a systematic comparison of ML models in combination with imaging features derived from different modalities is still needed. In this study, we evaluate the prediction performance of 36 combinations of imaging features and ML models including deep learning. We utilize single and multimodal brain imaging data including MRI, DTI, and rs-fMRI from a large data set with 839 subjects. Our study is a follow-up to the initial work (Liang et al., 2019. Human Brain Mapping) to investigate different analytic strategies to combine data from MRI, DTI, and rs-fMRI with the goal to improve brain age prediction accuracy. Additionally, the traditional approach to predicting the brain age gap has been shown to have a systematic bias. The potential nonlinear relationship between the brain age gap and chronological age has not been thoroughly tested. Here we propose a new method to correct the systematic bias of brain age gap by taking gender, chronological age, and their interactions into consideration. As the true brain age is unknown and may deviate from chronological age, we further examine whether various levels of behavioral performance across subjects predict their brain age estimated from neuroimaging data. This is an important step to quantify the practical implication of brain age prediction. Our findings are helpful to advance the practice of optimizing different analytic methodologies in brain age prediction.', 'Predicting Brain Age at Slice Level: Convolutional Neural Networks and Consequences for Interpretability Conclusion: Compared to whole brain-based predictive models of neuroimaging-derived brain age, slice-based approach improves the interpretability and therefore the reliability of the prediction of brain age using MRI data. Methods: Using convolutional neural networks we trained multiple regressor models to predict brain age based on single slices of magnetic resonance imaging, which included gray matter- or white matter-segmented inputs. We evaluated the trained models in all brain image slices to generate a final prediction of brain age. Unlike whole-brain approaches to classification, the slice-level predictions allows for the identification of which brain slices and associated regions have the largest difference between chronological and neuroimaging-derived brain age. We also evaluated how model predictions were influenced by slice index and plane, participant age and sex, and MRI data collection site. Problem: Chronological aging in later life is associated with brain degeneration processes and increased risk for disease such as stroke and dementia. With a worldwide tendency of aging populations and increased longevity, mental health, and psychiatric research have paid increasing attention to understanding brain-related changes of aging. Recent findings suggest there is a brain age gap (a difference between chronological age and brain age predicted by brain imaging indices); the magnitude of the gap may indicate early onset of brain aging processes and disease. Artificial intelligence has allowed for a narrowing of the gap in chronological and predicted brain age. However, the factors that drive model predictions of brain age are still unknown, and there is not much about these factors that can be gleaned from the black-box nature of machine learning models. The goal of the present study was to test a brain age regression approach that is more amenable to interpretation by researchers and clinicians. Results: The results show, first, that the specific slice used for prediction affects prediction error (i.e., difference between chronological age and neuroimaging-derived brain age); second, the MRI site-stratified separation of training and test sets removed site effects and also minimized sex effects; third, the choice of MRI slice plane influences the overall error of the model.']"
69,187,69_metrics_metric_distance_distances,"['metrics', 'metric', 'distance', 'distances', 'learning', 'euclidean', 'clustering', 'nearest', 'dissimilarity', 'dimensional']","['Risk-based adaptive metric learning for nearest neighbour classification The performance of k-nearest neighbour classification highly depends on the appropriateness of distance metric designation. Optimal performance can be obtained when the distance metric is matched to the characteristics of data. Existing works on distance-metric learning typically learn a global linear transform from training samples, and the effectiveness is limited to data, which are well-separated by linear decision boundaries. To address this problem, we propose a locally adaptive weighted distance-metric learning method to deal with the non-linearity of the data. The metric are learned based on local leave-one-out cross-validation (LOOCV) risks in each dimension, so that the local variations in feature component discriminability are taken into account. Experiments on both public datasets and hyper-spectral imagery classification demonstrate that the classification accuracy of the proposed method shows about 2-10% improvements over other competitive methods. (C) 2015 Elsevier B.V. All rights reserved.', 'Global and local metric learning via eigenvectors Distance metric plays a significant role in machine learning methods(classification, clustering, etc.), especially in k-nearest neighbor classification(kNN), where the Euclidean distances are computed to decide the labels of unknown points. But Euclidean distance ignores the statistical structure which may help to measure the similarity of different inputs better. In this paper, we construct an unified framework, including two eigenvalue related methods, to learn data-dependent metric. Both methods aim to maximize the difference of intra-class distance and inter-class distance, but the optimization is considered in global view and local view respectively. Different from previous work in metric learning, our methods straight seek for equilibrium between inter-class distance and intra-class distance, and the linear transformation decomposed from the metric is to be optimized directly instead of the metric. Then we can effectively adjust the data distribution in transformed space and construct favorable regions for kNN classification. The problems can be solved simply by eigenvalue-decomposition, much faster than semi-definite programming. After selecting the top eigenvalues, the original data can be projected into low dimensional space, and then insignificant information will be mitigated or eliminated to make the classification more efficiently. This makes it possible that our novel methods make metric learning and dimension reduction simultaneously. The numerical experiments from different points of view verify that our methods can improve the accuracy of kNN classification and make dimension reduction with competitive performance. (C) 2016 Elsevier B.V. All rights reserved.', 'Kernel-based metric learning for semi-supervised clustering Distance metric plays an important role in many machine learning algorithms. Recently, there has been growing interest in distance metric learning for semi-supervised setting. In the last few years, many methods have been proposed for metric learning when pairwise similarity (must-link) and/or dissimilarity (cannot-link) constraints are available along with unlabeled data. Most of these methods learn a global Mahalanobis metric (or equivalently, a linear transformation). Although some recently introduced methods have devised nonlinear extensions of linear metric learning methods, they usually allow only limited forms of distance metrics and also can use only similarity constraints. In this paper, we propose a nonlinear metric learning method that learns a completely flexible distance metric via learning a nonparametric kernel matrix. The proposed method uses both similarity and dissimilarity constraints and also the topological structure of the data to learn an appropriate distance metric. Our method is formulated as a convex optimization problem for learning a kernel matrix. This convex problem allows us to give a local-optimum-free metric learning method. Experimental results on synthetic and real-world data sets show that the proposed method outperforms the recently introduced metric learning methods for semi-supervised clustering. (C) 2009 Elsevier B.V. All rights reserved.']"
70,184,70_neural_algorithms_adaptive_algorithm,"['neural', 'algorithms', 'adaptive', 'algorithm', 'artificial', 'networks', 'neuron', 'models', 'learning', 'modular']","['Efficient self-organizing multilayer neural network for nonlinear system modeling It has been shown extensively that the dynamic behaviors of a neural system are strongly influenced by the network architecture and learning process. To establish an artificial neural network (ANN) with self-organizing architecture and suitable learning algorithm for nonlinear system modeling, an automatic axon-neural network (AANN) is investigated in the following respects. First, the network architecture is constructed automatically to change both the number of hidden neurons and topologies of the neural network during the training process. The approach introduced in adaptive connecting-and-pruning algorithm (ACP) is a type of mixed mode operation, which is equivalent to pruning or adding the connecting of the neurons, as well as inserting some required neurons directly. Secondly, the weights are adjusted, using a feedforward computation (FC) to obtain the information for the gradient during learning computation. Unlike most of the previous studies, AANN is able to self-organize the architecture and weights, and to improve the network performances. Also, the proposed AANN has been tested on a number of benchmark problems, ranging from nonlinear function approximating to nonlinear systems modeling. The experimental results show that AANN can have better performances than that of some existing neural networks. Crown Copyright (c) 2013 Published by Elsevier Ltd. All rights reserved.', 'A self-generating modular neural network architecture for supervised learning In this paper, we present a self-generating modular neural network architecture for supervised learning. In the architecture, any kind of feedforward neural networks can be employed as component nets. For a given task, a tree-structured modular neural network is automatically generated with a growing algorithm by partitioning input space recursively to avoid the problem of pre-determined structure. Due to the principle of divide-and-conquer used in the proposed architecture, the modular neural network can yield both good performance and significantly faster training. The proposed architecture has been applied to several supervised learning tasks and has achieved satisfactory results.', 'Evolutionary Multi-task Learning for Modular Knowledge Representation in Neural Networks The brain can be viewed as a complex modular structure with features of information processing through knowledge storage and retrieval. Modularity ensures that the knowledge is stored in a manner where any complications in certain modules do not affect the overall functionality of the brain. Although artificial neural networks have been very promising in prediction and recognition tasks, they are limited in terms of learning algorithms that can provide modularity in knowledge representation that could be helpful in using knowledge modules when needed. Multi-task learning enables learning algorithms to feature knowledge in general representation from several related tasks. There has not been much work done that incorporates multi-task learning for modular knowledge representation in neural networks. In this paper, we present multi-task learning for modular knowledge representation in neural networks via modular network topologies. In the proposed method, each task is defined by the selected regions in a network topology (module). Modular knowledge representation would be effective even if some of the neurons and connections are disrupted or removed from selected modules in the network. We demonstrate the effectiveness of the method using single hidden layer feedforward networks to learn selected n-bit parity problems of varying levels of difficulty. Furthermore, we apply the method to benchmark pattern classification problems. The simulation and experimental results, in general, show that the proposed method retains performance quality although the knowledge is represented as modules.']"
71,181,71_algorithm_algorithms_nonlinear_optimization,"['algorithm', 'algorithms', 'nonlinear', 'optimization', 'radial', 'model', 'functions', 'orthogonal', 'method', 'gradient']","['AN ALGORITHM TO GENERATE RADIAL BASIS FUNCTION (RBF)-LIKE NETS FOR CLASSIFICATION PROBLEMS This paper presents a new algorithm for generating radial basis function (RBF)-like nets for classification problems. The method uses linear programming (LP) models to train the RBF-like net. Polynomial time complexity of the method is proven and computational results are provided for many, well-known problems. The method can also be implemented as an on-line adaptive algorithm.', 'Research on an online self-organizing radial basis function neural network A new growing and pruning algorithm is proposed for radial basis function (RBF) neural network structure design in this paper, which is named as self-organizing RBF (SORBF). The structure of the RBF neural network is introduced in this paper first, and then the growing and pruning algorithm is used to design the structure of the RBF neural network automatically. The growing and pruning approach is based on the radius of the receptive field of the RBF nodes. Meanwhile, the parameters adjusting algorithms are proposed for the whole RBF neural network. The performance of the proposed method is evaluated through functions approximation and dynamic system identification. Then, the method is used to capture the biochemical oxygen demand (BOD) concentration in a wastewater treatment system. Experimental results show that the proposed method is efficient for network structure optimization, and it achieves better performance than some of the existing algorithms.', 'RBF neural network based on q-Gaussian function in function approximation To enhance the generalization performance of radial basis function (RBF) neural networks, an RBF neural network based on a q-Gaussian function is proposed. A q-Gaussian function is chosen as the radial basis function of the RBF neural network, and a particle swarm optimization algorithm is employed to select the parameters of the network. The non-extensive entropic index q is encoded in the particle and adjusted adaptively in the evolutionary process of population. Simulation results of the function approximation indicate that an RBF neural network based on q-Gaussian function achieves the best generalization performance.']"
72,180,72_biomedical_clinical_dataset_patientslikeme,"['biomedical', 'clinical', 'dataset', 'patientslikeme', 'data', 'expert', 'medical', 'researchers', 'datasets', 'healthcare']","['Data science in neurodegenerative disease: its capabilities, limitations, and perspectives Purpose of review With the advancement of computational approaches and abundance of biomedical data, a broad range of neurodegenerative disease models have been developed. In this review, we argue that computational models can be both relevant and useful in neurodegenerative disease research and although the current established models have limitations in clinical practice, artificial intelligence has the potential to overcome deficiencies encountered by these models, which in turn can improve our understanding of disease. Recent findings In recent years, diverse computational approaches have been used to shed light on different aspects of neurodegenerative disease models. For example, linear and nonlinear mixed models, self-modeling regression, differential equation models, and event-based models have been applied to provide a better understanding of disease progression patterns and biomarker trajectories. Additionally, the Cox-regression technique, Bayesian network models, and deep-learning-based approaches have been used to predict the probability of future incidence of disease, whereas nonnegative matrix factorization, nonhierarchical cluster analysis, hierarchical agglomerative clustering, and deep-learning-based approaches have been employed to stratify patients based on their disease subtypes. Furthermore, the interpretation of neurodegenerative disease data is possible through knowledge-based models which use prior knowledge to complement data-driven analyses. These knowledge-based models can include pathway-centric approaches to establish pathways perturbed in a given condition, as well as disease-specific knowledge maps, which elucidate the mechanisms involved in a given disease. Collectively, these established models have revealed high granular details and insights into neurodegenerative disease models. In conjunction with increasingly advanced computational approaches, a wide spectrum of neurodegenerative disease models, which can be broadly categorized into data-driven and knowledge-driven, have been developed. We review the state of the art data and knowledge-driven models and discuss the necessary steps which are vital to bring them into clinical application.', ""An introduction and overview of machine learning in neurosurgical care A systematic literature search was performed in the PubMed and Embase databases to identify all potentially relevant studies up to January 1, 2017. All studies were included that evaluated ML models assisting neurosurgical treatment. ML has started to find applications aimed at improving neurosurgical care by increasing the efficiency and precision of perioperative decision-making. A thorough validation of specific ML models is essential before implementation in clinical neurosurgical care. To bridge the gap between research and clinical care, practical and ethical issues should be considered parallel to the development of these techniques. Machine learning (ML) is a branch of artificial intelligence that allows computers to learn from large complex datasets without being explicitly programmed. Although ML is already widely manifest in our daily lives in various forms, the considerable potential of ML has yet to find its way into mainstream medical research and day-to-day clinical care. The complex diagnostic and therapeutic modalities used in neurosurgery provide a vast amount of data that is ideally suited for ML models. This systematic review explores ML's potential to assist and improve neurosurgical care. Of the 6,402 citations identified, 221 studies were selected after subsequent title/abstract and full-text screening. In these studies, ML was used to assist surgical treatment of patients with epilepsy, brain tumors, spinal lesions, neurovascular pathology, Parkinson's disease, traumatic brain injury, and hydrocephalus. Across multiple paradigms, ML was found to be a valuable tool for presurgical planning, intraoperative guidance, neurophysiological monitoring, and neurosurgical outcome prediction."", ""Addressing the Challenges and Barriers to the Integration of Machine Learning into Clinical Practice: An Innovative Method to Hybrid Human-Machine Intelligence Machine learning (ML) models have proven their potential in acquiring and analyzing large amounts of data to help solve real-world, complex problems. Their use in healthcare is expected to help physicians make diagnoses, prognoses, treatment decisions, and disease outcome predictions. However, ML solutions are not currently deployed in most healthcare systems. One of the main reasons for this is the provenance, transparency, and clinical utility of the training data. Physicians reject ML solutions if they are not at least based on accurate data and do not clearly include the decision-making process used in clinical practice. In this paper, we present a hybrid human-machine intelligence method to create predictive models driven by clinical practice. We promote the use of quality-approved data and the inclusion of physician reasoning in the ML process. Instead of training the ML algorithms on the given data to create predictive models (conventional method), we propose to pre-categorize the data according to the expert physicians' knowledge and experience. Comparing the results of the conventional method of ML learning versus the hybrid physician-algorithm method showed that the models based on the latter can perform better. Physicians' engagement is the most promising condition for the safe and innovative use of ML in healthcare.""]"
73,177,73_deep_dnns_networks_neural,"['deep', 'dnns', 'networks', 'neural', 'learning', 'layers', 'network', 'dnn', 'dbn', 'dbns']","['Iterative Deep Neighborhood: A Deep Learning Model Which Involves Both Input Data Points and Their Neighbors Deep learning models, such as deep convolutional neural network and deep long-short term memory model, have achieved great successes in many pattern classification applications over shadow machine learning models with hand-crafted features. The main reason is the ability of deep learning models to automatically extract hierarchical features from massive data by multiple layers of neurons. However, in many other situations, existing deep learning models still cannot gain satisfying results due to the limitation of the inputs of models. The existing deep learning models only take the data instances of an input point but completely ignore the other data points in the dataset, which potentially provides critical insight for the classification of the given input. To overcome this gap, in this paper, we show that the neighboring data points besides the input data point itself can boost the deep learning model\'s performance significantly and design a novel deep learning model which takes both the data instances of an input point and its neighbors\' classification responses as inputs. In addition, we develop an iterative algorithm which updates the neighbors of data points according to the deep representations output by the deep learning model and the parameters of the deep learning model alternately. The proposed algorithm, named """"Iterative Deep Neighborhood (IDN),"""" shows its advantages over the state-of-the-art deep learning models over tasks of image classification, text sentiment analysis, property price trend prediction, etc.', 'Deep neural network compression through interpretability-based filter pruning This paper proposes a method to compress deep neural networks (DNNs) based on interpretability. For a trained DNN model, the activation maximization technique is first used to visualize every filter of the DNN model. Then, a single-layer filter pruning approach is introduced from what is learned by visualization. The entire DNN model is compressed layer by layer by using the single-layer filter pruning method in which the compression of the current layer is based on the compression of the preceding layers. Importantly, in addition to effective compression, the proposed method renders a better interpretation of the deep learning process. With a 60% compression rate of the VGG-16, our method achieves 0.8429 Top 1 accuracy under CIFAR-10, with a slight accuracy drop of only 0.0322, and the storage space of the model can be compressed to 9.42 Mb. For a modern DNN model such as ResNet50, our visualization-based filter pruning method is significantly better than other pruning strategies in different convolutional layers under different compression rates and the larger ImageNet dataset. After pruning, the computation cost and storage requirement of the DNN can be significantly reduced, which means that complex DNN models can be easily implemented in small mobile devices, thus enabling the efficient use of DNNs in the Internet of Things technologies. (c) 2021 Elsevier Ltd. All rights reserved.', 'Merging Similar Neurons for Deep Networks Compression Deep neural networks have achieved outstanding progress in many fields, such as computer vision, speech recognition and natural language processing. However, large deep neural networks often need huge storage space and long training time, making them difficult to apply to resource restricted devices. In this paper, we propose a method for compressing the structure of deep neural networks. Specifically, we apply clustering analysis to find similar neurons in each layer of the original network, and merge them and the corresponding connections. After the compression of the network, the number of parameters in the deep neural network is significantly reduced, and the required storage space and computational time is greatly reduced as well. We test our method on deep belief network (DBN) and two convolutional neural networks. The experimental results demonstrate that our proposed method can greatly reduce the number of parameters of the deep networks, while keeping their classification accuracy. Especially, on the CIFAR-10 dataset, we have compressed VGGNet with compression ratio 92.96%, and the final model after fine-tuning obtains even higher accuracy than the original model.']"
74,177,74_underwater_unmanned_ocean_adaptive,"['underwater', 'unmanned', 'ocean', 'adaptive', 'sonar', 'marine', 'simulation', 'learning', 'maritime', 'detection']","['A systematic review and analysis of deep learning-based underwater object detection Underwater object detection is one of the most challenging research topics in computer vision technology. The complex underwater environment makes underwater images suffer from high noise, low visibility, blurred edges, low contrast and color deviation, which brings significant challenges to underwater object detection tasks. In underwater object detection tasks, traditional object detection methods often perform poorly in terms of accuracy and generalization capabilities. Underwater object detection requires accurate, stable, generalizable, real-time and lightweight detection models, for which many researchers have proposed various underwater object detection techniques based on deep learning. Although many outstanding results have been achieved on underwater object detection over the years, the research status of underwater object detection techniques are still lack of unified induction, and some existing problems need to be further probed from the latest perspective. In addition, previous reviews lack analysis on the relationship between underwater image enhancement and object detection. Therefore, this paper provides a comprehensive review of the current research challenges, future development trends, and potential applications of underwater object detection techniques. More importantly, this paper has explored the internal relationship between underwater image enhancement and object detection, and analyzed the possible implementation manners of underwater image enhancement in the object detection task in order to further enhance its benefits. The experiments show the performances of current underwater image enhancement and state-of-the-art object detection algorithms, point out their limitations, and indicate that there is not a strict positive correlation between underwater image enhancement and the accuracy improvement of object detection. The domain shift caused by underwater image enhancement cannot be ignored. This paper can be regarded as a guide for future works on underwater object detection.', 'A DSC and MLP based robust adaptive NN tracking control for underwater vehicle In this paper, a novel adaptive neural network (NN) controller is proposed for trajectory tracking of autonomous underwater vehicle (AUV). By employing radial basic function neural network to account for modeling errors, then the adaptive NN tracking controller is constructed by combining the dynamic surface control (DSC) and the minimal learning parameter (MLP). The proposed controller guarantees that all the close-loop signals are uniform ultimate bounded (UUB) and that the tracking errors converge to a small neighborhood of the desired trajectory. Finally, simulation studies are given to illustrate the effectiveness of the proposed algorithm. (C) 2013 Elsevier B.V. All rights reserved.', 'Transferring deep knowledge for object recognition in Low-quality underwater videos In recent years, underwater video technologies allow us to explore the ocean in scientific and noninvasive ways, such as environmental monitoring, marine ecology studies, and fisheries management. However the low-light and high-noise scenarios pose great challenges for the underwater image and video analysis. We here propose a CNN knowledge transfer framework for underwater object recognition and tackle the problem of extracting discriminative features from relatively low contrast images. Even with the insufficient training set, the transfer framework can well learn a recognition model for the special underwater object recognition task together with the help of data augmentation. For better identifying objects from an underwater video, a weighted probabilities decision mechanism is introduced to identify the object from a series of frames. The proposed framework can be implemented for real-time underwater object recognition on autonomous underwater vehicles and video monitoring systems. To verify the effectiveness of our method, experiments on a public dataset are carried out. The results show that the proposed method achieves promising results for underwater object recognition on both test image datasets and underwater videos. (C) 2017 Elsevier B.V. All rights reserved.']"
75,175,75_ligands_receptors_ligand_receptor,"['ligands', 'receptors', 'ligand', 'receptor', 'dopaminergic', 'molecular', 'acetylcholine', 'binding', 'dopamine', 'affinity']","[""Molecular Docking Studies of Methamphetamine and Amphetamine- Related Derivatives as an Inhibitor against Dopamine Receptor Background: The catecholamines such as dopamine, norepinephrine, and epinephrine are neurotransmitters that regulate different physiological functions of the central nervous system. Some evidence suggests that the degeneration of dopamine neurons in the substantia nigra contributes to Parkinson's Disease (PD), which is a neurodegenerative disorder and it is responsible for the major symptoms of PD. It is suggested that replenishment of striatal dopamine through the oral administration of the dopamine precursor, levodopa, can compensate for the lack of endogenously produced dopamine. Some studies have shown competitive inhibition of dopamine receptor such as methamphetamine, and other amphetamine-related derivatives, which block dopamine receptor activity to uptake dopamine. Results: Our results indicated that all chemicals can interact with dopamine receptor molecule in the active site of dopamine and the minimum binding energies belong to Cocaine and Methylphenidate with -7.9 Kcal/mol and -7.2 Kcal/mol, respectively. Conclusion: It might be concluded that amphetamine, methamphetamine, cocaine, methylphenidate, cathinone, MDMA, and mephedrone could act as potential inhibitors of DA receptor for dopamine uptake, which could cause degenerative disorders. Methods: In this study, 3D structures of amphetamine, methamphetamine, cocaine, methylphenidate, cathinone, MDMA, and mephedrone were obtained from the PubChem database, which has reported some evidence about their inhibitory effect with dopamine receptor. Then, these structures were provided for molecular docking analysis by Autodock Vina software. Eventually, the binding energies between docked dopamine receptor and them were calculated and their interactions were prognosticated."", 'Prediction of the binding mode of biarylpropylsulfonamide allosteric AMPA receptor modulators based on docking, GRID molecular interaction fields and 3D-QSAR analysis A novel approach of combining flexible molecular docking, GRID molecular interaction fields, analysis of ligand-protein hydrogen bond interactions, conformational energy penalties and 3D-QSAR analysis was used to propose a binding mode in the dimer interface of the iGluR2 receptor for the biarylpropylsulfonamide class of positive allosteric AMPA modulators. Possible binding poses were generated by flexible molecular docking. GRID molecular interaction fields of the binding site, ligand-protein hydrogen bonding interactions and conformational energy penalties were used to select the most likely binding mode. The selected binding poses were subjected to a 3D-QSAR analysis using previously published activity data. The resulting model (2 LVs, R-2 = 0.89, q(2) = 0.61) predicted the activities of the compounds in the test set with a standard deviation on error of prediction of 0.17. The proposed binding mode was validated by interpretation of the PLS-coefficient regions from the 3D-QSAR analysis in terms of interactions between the receptor and the modulators. (c) 2007 Elsevier Inc. All rights reserved.', 'Molecular modeling of ligand-receptor interactions in GABA(C) receptor A new homology model of the GABA binding site of the GABA(C) receptor was built. Natural agonist GABA and antagonist TPMPA were docked into the receptor and molecular dynamics simulation of the complexes was performed to clarify binding poses of the ligands. It was shown that orientation of the ligand is defined by salt bridges between the ligand and the arginine (Arg104) and glutamate residues (Glu194 and Glu196) of the binding site. Different behavior and binding poses for agonist and antagonist was demonstrated by molecular dynamics simulation along with differential movement of the loop C during agonist and antagonist binding. Binding orientations of the ligands revealed that main binding forces in the GABA binding site should be electrostatic ones. (C) 2008 Elsevier Inc. All rights reserved.']"
76,175,76_virtual_rehabilitation_traumatic_impairments,"['virtual', 'rehabilitation', 'traumatic', 'impairments', 'experience', 'cognitive', 'cognition', 'immersion', 'neuropsychological', 'reality']","['Recommendations for the Design and Implementation of Virtual Reality for Acquired Brain Injury Rehabilitation: Systematic Review Background: Virtual reality (VR) is increasingly being used for the assessment and treatment of impairments arising from acquired brain injuries (ABIs) due to perceived benefits over traditional methods. However, no tailored options exist for the design and implementation of VR for ABI rehabilitation and, more specifically, traumatic brain injury (TBI) rehabilitation. In addition, the evidence base lacks systematic reviews of immersive VR use for TBI rehabilitation. Recommendations for this population are important because of the many complex and diverse impairments that individuals can experience. Conclusions: There is limited research on the use of immersive VR for TBI rehabilitation. Few studies have been conducted, and there is limited inclusion of recommendations for therapeutic VR design and implementation. Future research in ABI rehabilitation should consider a stepwise approach to VR development, from early co-design studies with end users to larger controlled trials. A list of recommendations is offered to provide guidance and a more consistent model to advance clinical research in this area. Methods: This review was guided by PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses). A comprehensive search of 11 databases and gray literature was conducted in August 2019 and repeated in June 2020. Studies were included if they met relevant search terms, were peer-reviewed, were written in English, and were published between 2009 and 2020. Studies were reviewed to determine the level of evidence and methodological quality. For the first part, qualitative data were synthesized and categorized via meta-synthesis. For the second part, findings were analyzed and synthesized descriptively owing to the heterogeneity of data extracted from the included studies. Objective: This study aims to conduct a two-part systematic review to identify and synthesize existing recommendations for designing and implementing therapeutic VR for ABI rehabilitation, including TBI, and to identify current evidence for using immersive VR for TBI assessment and treatment and to map the degree to which this literature includes recommendations for VR design and implementation. Results: In the first part, a total of 14 papers met the inclusion criteria. Recommendations for VR design and implementation were not specific to TBI but rather to stroke or ABI rehabilitation more broadly. The synthesis and analysis of data resulted in three key phases and nine categories of recommendations for designing and implementing VR for ABI rehabilitation. In the second part, 5 studies met the inclusion criteria. A total of 2 studies reported on VR for assessment and three for treatment. Studies were varied in terms of therapeutic targets, VR tasks, and outcome measures. VR was used to assess or treat impairments in cognition, balance, and anxiety, with positive outcomes. However, the levels of evidence, methodological quality, and inclusion of recommendations for VR design and implementation were poor.', 'Immersive virtual reality in traumatic brain injury rehabilitation: A literature review BACKGROUND: Traumatic brain injury (TBI) is a common cause of morbidity and mortality in the United States with its sequelae often affecting individuals long after the initial injury. Innovations in virtual reality (VR) technology may offer potential therapy options in the recovery from such injuries. However, there is currently no consensus regarding the efficacy of VR in the setting of TBI rehabilitation. CONCLUSIONS: While the current literature generally offers support for the use of VR in TBI recovery, there is a paucity of strong evidence to support its widespread use. The increasing availability of immersive VR technology offers the potential for engaging therapy in TBI rehabilitation, but its utility remains uncertain given the limited studies available at this time. METHODS: A comprehensive literature search was conducted utilizing PubMed, Google Scholar, and the Cochrane Review using the search terms """"virtual reality,"""" """"traumatic brain injury,"""" """"brain injury,"""" and """" immersive. """" OBJECTIVE: The aim of this review is to evaluate and summarize the current literature regarding immersive VR in the rehabilitation of those with TBI. RESULTS: A total of 11 studies were evaluated. These were primarily of low-level evidence, with the exception of two randomized, controlled trials. 10 of 11 studies demonstrated improvement with VR therapy. VR was most frequently used to address gait or cognitive deficits.', 'The Use of the Term Virtual Reality in Post-Stroke Rehabilitation: A Scoping Review and Commentary Virtual reality (VR) offers many opportunities for post-stroke rehabilitation. However, """"VR"""" can refer to several types of computer-based rehabilitation systems. Since these systems may impact the feasibility and the efficacy of VR interventions, consistent terminology is important. In this study, we aimed to optimize the terminology for VR-based post-stroke rehabilitation by assessing whether and how review papers on this topic defined VR and what types of mixed reality systems were discussed. In addition, this review can inspire the use of consistent terminology for other researchers working with VR. We assessed the use of the term VR in review papers on post-stroke rehabilitation extracted from Scopus, Web of Science and PubMed. We also developed a taxonomy distinguishing 16 mixed reality systems based on three factors: immersive versus semi-immersive displays, the way in which real and virtual information is mixed, and the main input device. 64% of the included review papers (N = 121) explicitly defined VR and 33% of them described different subtypes of VR, with immersive and non-immersive VR as the most common distinction. The most frequently discussed input devices were motion-capture cameras and handheld devices, while regular 2D monitors were the most frequently mentioned output devices. Our analysis revealed that reviews on post-stroke VR rehabilitation did not or only broadly defined """"VR"""" and did not focus on a specific system. Since the efficacy and feasibility of rehabilitation may depend on the specific system, we propose a new data-driven taxonomy to distinguish different systems, which is expected to facilitate communication amongst researchers and clinicians working with virtual reality.']"
77,173,77_neurons_neural_neuronal_neuron,"['neurons', 'neural', 'neuronal', 'neuron', 'oscillations', 'synchronization', 'oscillation', 'synaptic', 'stimulus', 'oscillatory']","['Spike-timing-dependent plasticity in small-world networks Biologically plausible excitatory neural networks develop a persistent synchronized pattern of activity depending on spontaneous activity and synaptic refractoriness (short term depression). By fixed synaptic weights synchronous bursts of oscillatory activity are stable and involve the whole network. In our modeling study we investigate the effect of a dynamic Hebbian-like learning mechanism, spike-timing-dependent plasticity (STDP), on the changes of synaptic weights depending on synchronous activity and network connection strategies (small-world topology). We show that STDP modifies the weights of synaptic connections in such a way that synchronization of neuronal activity is considerably weakened. Networks with a higher proportion of long connections can sustain a higher level of synchronization in spite of STDP influence. The resulting distribution of the synaptic weights in single neurons depends both on the global statistics of firing dynamics and on the number of incoming and outgoing connections. (c) 2007 Elsevier B.V. All rights reserved.', ""Feedback effects in simulated Stein's coupled neurons A network consisting of two Stein-type neuronal units is analyzed under the assumption of a complete interaction between the neurons. The firing of each neuron causes a jump of constant amplitude of the membrane potential of the other neuron. The jump is positive or negative according to whether the firing neuron is excitatory or inhibitory. Making use of a simulation procedure designed by ourselves, we study the interspike intervals of the two neurons by means of their histograms, of some descriptive statistics and of empirical distribution functions. Furthermore, via the crosscorrelation function, we investigate the synchronization between the neurons firing activity in the special case when one neuron is excitatory and the other is inhibitory."", 'Synchronous firing frequency dependence in unidirectional coupled neuronal networks with chemical synapses Rhythmic brain waves caused by the synchronous firing activity of neurons are believed to be relevant for higher brain functions such as the attention and sleep-wake state switching. In the brain, cortical neurons, including interneurons, are anatomically and functionally diverse and can fire at different frequencies. However, it still remains unclear how such cortical networks that comprise a variety of neurons create synchronous activity. The present study examined entrainments of firing activity in cortical networks. To explore how cortical networks causes synchronous firing and to elucidate the mechanism for synchronous activity, we performed numerical simulations of synchronous firing behaviors observed in a unidirectional coupled neuron model, mimicking one of the minimum motifs in cortical networks. Furthermore, we observed bifurcations of periodic oscillations, which cause various phase locking states, in the coupled neuron model. We analyzed these bifurcations to investigate the effects of differences in membrane excitability, synaptic properties, and model structural complexity on the synchronous firing frequency. We found that the post-synaptic neuron could more readily attain a phase locking state at higher or lower frequencies than the intrinsic firing frequency of the pre-synaptic neuron for excitatory and inhibitory synaptic inputs, respectively. This finding suggests that synaptic coupling properties might determine the entrainable frequency range (phase-locked range) of the synchronous firing behavior. Thus, the specific rhythmic waves evoked by brain activity may be attributable to the synaptic coupling properties constituting local circuits. (C) 2019 Elsevier B.V. All rights reserved.']"
78,172,78_forecasting_forecasters_predictive_forecasts,"['forecasting', 'forecasters', 'predictive', 'forecasts', 'forecast', 'prediction', 'predictions', 'models', 'modeling', 'model']","['A novel time series forecasting model with deep learning Time series forecasting is emerging as one of the most important branches of big data analysis. However, traditional time series forecasting models can not effectively extract good enough sequence data features and often result in poor forecasting accuracy. In this paper, a novel time series forecasting model, named SeriesNet, which can fully learn features of time series data in different interval lengths. The SeriesNet consists of two networks. The LSTM network aims to learn holistic features and to reduce dimensionality of multi-conditional data, and the dilated causal convolution network aims to learn different time interval. This model can learn multi-range and multi-level features from time series data, and has higher predictive accuracy compared those models using fixed time intervals. Moreover, this model adopts residual learning and batch normalization to improve generalization. Experimental results show our model has higher forecasting accuracy and has greater stableness on several typical time series datasets. (C) 2019 Elsevier B.V. All rights reserved.', 'A perturbative approach for enhancing the performance of time series forecasting This paper proposes a method to perform time series prediction based on perturbation theory. The approach is based on continuously adjusting an initial forecasting model to asymptotically approximate a desired time series model. First, a predictive model generates an initial forecasting for a time series. Second, a residual time series is calculated as the difference between the original time series and the initial forecasting. If that residual series is not white noise, then it can be used to improve the accuracy of the initial model and a new predictive model is adjusted using residual series. The whole process is repeated until convergence or the residual series becomes white noise. The output of the method is then given by summing up the outputs of all trained predictive models in a perturbative sense. To test the method, an experimental investigation was conducted on six real world time series. A comparison was made with six other methods experimented and ten other results found in the literature. Results show that not only the performance of the initial model is significantly improved but also the proposed method outperforms the other results previously published. (C) 2017 Elsevier Ltd. All rights reserved.', 'A Time Series Forecasting Model Selection Framework using CNN and Data Augmentation for Small Sample Data The key to the accuracy of time series forecasting is to find the most appropriate forecasting method. Therefore, the forecasting model selection of time series has become a new research hotspot in the data analysis field. However, most of the existing meta learning forecasting model selection methods rely on manual selection of features, which leads to low efficiency and lack of objectivity. Therefore, this paper proposes an improved meta learning framework for deep learning time series forecasting model selection. Inspired by computer vision, we transform one -dimensional time series into two-dimensional images, and use convolution neural network to train and classify time series images (model selection). Moreover, in order to deal with the over fitting problem caused by small sample datasets, the sliding window data augmentation method is used to improve the accuracy of small datasets model selection. The large-scale empirical study on M3 data sets shows that the framework has better model selection accuracy and smaller forecasting error than the recurrent neural network (RNN), back propagation neural network and traditional time series image algorithms. In addition, compared with the traditional time series image method, RNN and BP, the classification rate (model selection accuracy) of this algorithm is improved by 6.5%, 4.4% and 3.2%, respectively.']"
79,170,79_approximations_approximation_approximating_approximated,"['approximations', 'approximation', 'approximating', 'approximated', 'computational', 'neural', 'complexity', 'polynomial', 'polynomials', 'arbitrary']","['The essential approximation order for neural networks with trigonometric hidden layer units There have been various studies on approximation ability of feedforward neural networks. The existing studies are, however, only concerned with the density or upper bound estimation on how a multivariate function can be approximated by the networks, and consequently, the essential approximation ability of networks cannot be revealed. In this paper, by establishing both upper and lower bound estimations on approximation order, the essential approximation ability of a class of feedforward neural networks with trigonometric hidden layer units is clarified in terms of the second order modulus of smoothness of approximated function.', 'The essential order of approximation for neural networks There have been various studies on approximation ability of feedforward neural networks (FNNs). Most of the existing studies are, however, only concerned with density or upper bound estimation on how a multivariate function can be approximated by an FNN, and consequently, the essential approximation ability of an FNN cannot be revealed. In this paper, by establishing both upper and lower bound estimations on approximation order, the essential approximation ability (namely, the essential approximation order) of a class of FNNs is clarified in terms of the modulus of smoothness of functions to be approximated. The involved FNNs can not only approximate any continuous or integrable functions defined on a compact set arbitrarily well, but also provide an explicit lower bound on the number of hidden units required. By making use of multivariate approximation tools, it is shown that when the functions to be approximated are Lipschitzian with order up to 2, the approximation speed of the FNNs is uniquely determined by modulus of smoothness of the functions.', 'Approximation bounds by neural networks in L-w(P) We consider approximation of multidimensional functions by feedforward neural networks with one hidden layer of Sigmoidal units and a linear output. Under the Orthogonal polynomials basis and certain assumptions of activation functions in the neural network, the upper bounds on the degree of approximation are obtained in the class of functions considered in this paper. The order of approximation O(n(-r/d)), d being dimension, n the number of hidden neurons, and r the natural number.']"
80,170,80_kernel_kernels_algorithms_polynomial,"['kernel', 'kernels', 'algorithms', 'polynomial', 'matrix', 'algorithm', 'computational', 'classification', 'optimization', 'generalization']","['Multiple Spectral Kernel Learning and a Gaussian Complexity Computation Multiple kernel learning (MKL) partially solves the kernel selection problem in support vector machines and similar classifiers by minimizing the empirical risk over a subset of the linear combination of given kernel matrices. For large sample sets, the size of the kernel matrices becomes a numerical issue. In many cases, the kernel matrix is of low-efficient rank. However, the low-rank property is not efficiently utilized in MKL algorithms. Here, we suggest multiple spectral kernel learning that efficiently uses the low-rank property by finding a kernel matrix from a set of Gram matrices of a few eigenvectors from all given kernel matrices, called a spectral kernel set. We provide a new bound for the gaussian complexity of the proposed kernel set, which depends on both the geometry of the kernel set and the number of Gram matrices. This characterization of the complexity implies that in an MKL setting, adding more kernels may not monotonically increase the complexity, while previous bounds show otherwise.', 'Kernel self-optimization learning for kernel-based feature extraction and recognition Kernel learning is becoming an important research topic in the area of machine learning, and it has wide applications in pattern recognition, computer vision, image and signal processing. Kernel learning provides a promising solution to nonlinear problems, including nonlinear feature extraction, classification and clustering. However, in kernel-based systems, the problem of the kernel function and its parameters remains to be solved. Methods of choosing parameters from a discrete set of values have been presented in previous studies, but these methods do not change the data distribution structure in the kernel-based mapping space. Accordingly, performance is not improved because the current kernel optimization does not change the data distribution. Based on this problem, this paper presents a uniform framework for kernel self-optimization with the ability to adjust the data structure. The data-dependent kernel is extended and applied to kernel learning, and optimization equations with two criteria for measuring data discrimination are used to solve the optimal parameter values. Some experiments are performed to evaluate the performance in popular kernel learning methods, including kernel principal components analysis (KPCA), kernel discriminant analysis (KDA) and kernel locality-preserving projection (KLPP). These evaluations show that the framework of kernel self-optimization is feasible for enhancing kernel-based learning methods. (C) 2013 Elsevier Inc. All rights reserved.', 'Theoretical properties and implementation of the one-sided mean kernel for time series In this paper we introduce a new kernel for sequences of structured data, investigate its properties and propose a fast implementation. We demonstrate using the theory of infinitely divisible kernels that this kernel is positive definite, that it is a radial basis kernel and that it reduces to a product kernel when comparing two sequences of the same length. We present an implementation of this kernel using dynamic programming techniques that leads to an algorithm of lower complexity than competing kernels. We illustrate that this kernel presents a consistent behavior in the context of sub-sampling of continuous time series. Finally we compare this kernel with the global alignment kernel in two classification tasks with real world data using support vector machines. (C) 2015 Elsevier B.V. All rights reserved.']"
81,169,81_factorization_clustering_matrix_nmf,"['factorization', 'clustering', 'matrix', 'nmf', 'matrices', 'minimization', 'nonnegativity', 'nonnegative', 'datasets', 'dimensional']","['Semi-supervised convex nonnegative matrix factorizations with graph regularized for image representation Non-negative matrix factorization (NMF) is a very effective method for high dimensional data analysis, which has been widely used in computer vision. It can capture the underlying structure of image in the low dimensional space using its parts-based representations. However, nonnegative entries are usually required for the data matrix in NMF, which limits its application. Besides, it is actually an unsupervised method without making use of prior information of data. In this paper, we propose a novel method called Pairwise constrained Graph Regularized Convex Nonnegative Matrix Factorization (PGCNMF), which not only allows the processing of mixed-sign data matrix but also incorporates pairwise constraints generated among all labeled data into Convex NMF framework. We expect that images which have the same class label will have very similar representations in the low dimensional space as much as possible, while images with different class labels will have dissimilar representations as much as possible. Clustering experiments on nonnegative and mixed-sign real-world image datasets are conducted to demonstrate the effectiveness of the proposed method. (C) 2016 Elsevier B.V. All rights reserved.', 'Convex nonnegative matrix factorization with manifold regularization Nonnegative Matrix Factorization (NMF) has been extensively applied in many areas, including computer vision, pattern recognition, text mining, and signal processing. However, nonnegative entries are usually required for the data matrix in NMF, which limits its application. Besides, while the basis and encoding vectors obtained by NMF can represent the original data in low dimension, the representations do not always reflect the intrinsic geometric structure embedded in the data. Motivated by manifold learning and Convex NMF (CNMF), we propose a novel matrix factorization method called Graph Regularized and Convex Nonnegative Matrix Factorization (GCNMF) by introducing a graph regularized term into CNMF. The proposed matrix factorization technique not only inherits the intrinsic low-dimensional manifold structure, but also allows the processing of mixed-sign data matrix. Clustering experiments on nonnegative and mixed-sign real-world data sets are conducted to demonstrate the effectiveness of the proposed method. (C) 2014 Elsevier Ltd. All rights reserved.', 'Subspace clustering guided convex nonnegative matrix factorization As one of the most important information of the data, the geometry structure information is usually modeled by a similarity graph to enforce the effectiveness of nonnegative matrix factorization (NMF). However, pairwise distance based graph is sensitive to noise and can not capture the subspace structure of the data. Reconstruction coefficients based graph can capture the subspace structure of the data, but the procedure of building the representation based graph is usually independent to the framework of NMF. To address this issue, a novel subspace clustering guided convex nonnegative matrix factorization (SC-CNMF) is proposed. In this NMF framework, the nonnegative subspace clustering is incorporated to learning the representation based graph, and meanwhile, a convex nonnegative matrix factorization is also updated simultaneously. To tackle the noise influence of the dataset, only k largest entries of each representation are kept in the subspace clustering. To capture the complicated geometry structure of the data, multiple centroids are also introduced to describe each cluster. Additionally, a row constraint is used to remove the relevance among the rows of the encoding matrix, which can help to improve the clustering performance of the proposed model. For the proposed NMF framework, two different objective functions with different optimizing schemes are designed. Image clustering experiments are conducted to demonstrate the effectiveness of the proposed methods on several datasets and compared with some related works based on NMF together with k-means clustering method and PCA as baseline. (c) 2018 Elsevier B.V. All rights reserved.']"
82,168,82_neurodevelopmental_infants_infant_brain,"['neurodevelopmental', 'infants', 'infant', 'brain', 'neonates', 'brains', 'developmental', 'neonatal', 'newborn', 'fetal']","[""Neonatal Brain Tissue Classification with Morphological Adaptation and Unified Segmentation Measuring the distribution of brain tissue types (tissue classification) in neonates is necessary for studying typical and atypical brain development, such as that associated with preterm birth, and may provide biomarkers for neurodevelopmental outcomes. Compared with magnetic resonance images of adults, neonatal images present specific challenges that require the development of specialized, population-specific methods. This paper introduces MANTiS (Morphologically Adaptive Neonatal Tissue Segmentation), which extends the unified segmentation approach to tissue classification implemented in Statistical Parametric Mapping (SPM) software to neonates. MANTiS utilizes a combination of unified segmentation, template adaptation via morphological segmentation tools and topological filtering, to segment the neonatal brain into eight tissue classes: cortical gray matter, white matter, deep nuclear gray matter, cerebellum, brainstem, cerebrospinal fluid (CSF), hippocampus and amygdala. We evaluated the performance of MANTiS using two independent datasets. The first dataset, provided by the NeoBrainSl2 challenge, consisted of coronal T2 weightedimages of preterm infants (born <30 weeks' gestation) acquired at 30 weeks' corrected gestational age (n = 5), coronal T2-weighted images of preterm infants acquired at 40 weeks' corrected gestational age (n = 5) and axial T2-weighted images of preterm infants acquired at 40 weeks' corrected gestational age (n = 5). The second dataset, provided by the Washington University NeuroDevelopmental Research (WUNDeR) group, consisted of T2-weighted images of preterm infants (born <30 weeks' gestation) acquired shortly after birth (n = 12), preterm infants acquired at term-equivalent age (n = 12), and healthy term born infants (born >38 weeks' gestation) acquired within the first 9 days of life (n = 12). For the NeoBrainS12 dataset, mean Dice scores comparing MANTiS with manual segmentations were all above 0.7, except for the cortical gray matter for coronal images acquired at 30 weeks. This demonstrates that MANTiS' performance is competitive with existing techniques. For the WUNDeR dataset, mean Dice scores comparing MANTiS with manually edited segmentations demonstrated good agreement, where all scores were above 0.75, except for the hippocampus and amygdala. The results show that MANTiS is able to segment neonatal brain tissues well, even in images that have brain abnormalities common in preterm infants. MANTiS is available for download as an SPM toolbox from http://developmentalimagingmcri.github.io/mantis."", 'LINKS: Learning-based multi-source IntegratioN frameworK for Segmentation of infant brain images Segmentation of infant brain MR images is challenging due to insufficient image quality, severe partial volume effect, and ongoing maturation and myelination processes. In the first year of life, the image contrast between white and gray matters of the infant brain undergoes dramatic changes. In particular, the image contrast is inverted around 6-8 months of age, and the white and gray matter tissues are isointense in both T1- and T2-weighted MR images and thus exhibit the extremely low tissue contrast, which poses significant challenges for automated segmentation. Most previous studies used multi-atlas label fusion strategy, which has the limitation of equally treating the different available image modalities and is often computationally expensive. To cope with these limitations, in this paper, we propose a novel learning-based multi-source integration framework for segmentation of infant brain images. Specifically, we employ the random forest technique to effectively integrate features from multi-source images together for tissue segmentation. Here, the multi-source images include initially only the multi-modality (T1, T2 and FA) images and later also the iteratively estimated and refined tissue probability maps of gray matter, white matter, and cerebrospinal fluid. Experimental results on 119 infants show that the proposed method achieves better performance than other state-of-the-art automated segmentation methods. Further validation was performed on the MICCAI grand challenge and the proposed method was ranked top among all competing methods. Moreover, to alleviate the possible anatomical errors, our method can also be combined with an anatomically-constrained multi-atlas labeling approach for further improving the segmentation accuracy. (C) 2014 Elsevier Inc. All rights reserved.', ""Morphology-driven automatic segmentation of MR images of the neonatal brain The segmentation of MR images of the neonatal brain is an essential step in the study and evaluation of infant brain development. State-of-the-art methods for adult brain MRI segmentation are not applicable to the neonatal brain, due to large differences in structure and tissue properties between newborn and adult brains. Existing newborn brain MRI segmentation methods either rely on manual interaction or require the use of atlases or templates, which unavoidably introduces a bias of the results towards the population that was used to derive the atlases. We propose a different approach for the segmentation of neonatal brain MRI, based on the infusion of high-level brain morphology knowledge, regarding relative tissue location, connectivity and structure. Our method does not require manual interaction, or the use of an atlas, and the generality of its priors makes it applicable to different neonatal populations, while avoiding atlas-related bias. The proposed algorithm segments the brain both globally (intracranial cavity, cerebellum, brainstem and the two hemispheres) and at tissue level (cortical and subcortical gray matter, myelinated and unmyelinated white matter, and cerebrospinal fluid). We validate our algorithm through visual inspection by medical experts, as well as by quantitative comparisons that demonstrate good agreement with expert manual segmentations. The algorithm's robustness is verified by testing on variable quality images acquired on different machines, and on subjects with variable anatomy (enlarged ventricles, preterm- vs. term-born). (C) 2012 Elsevier B.V. All rights reserved.""]"
83,167,83_registrations_mapping_registration_images,"['registrations', 'mapping', 'registration', 'images', 'groupwise', 'imaging', 'statistical', 'algorithm', 'atlas', 'graph']","['CycleMorph: Cycle consistent unsupervised deformable image registration (c) 2021 Elsevier B.V. All rights reserved. Image registration is a fundamental task in medical image analysis. Recently, many deep learning based image registration methods have been extensively investigated due to their comparable performance with the state-of-the-art classical approaches despite the ultra-fast computational time. However, the existing deep learning methods still have limitations in the preservation of original topology during the deformation with registration vector fields. To address this issues, here we present a cycle-consistent de formable image registration, dubbed CycleMorph. The cycle consistency enhances image registration performance by providing an implicit regularization to preserve topology during the deformation. The proposed method is so flexible that it can be applied for both 2D and 3D registration problems for various applications, and can be easily extended to multi-scale implementation to deal with the memory issues in large volume registration. Experimental results on various datasets from medical and non-medical applications demonstrate that the proposed method provides effective and accurate registration on diverse image pairs within a few seconds. Qualitative and quantitative evaluations on deformation fields also verify the effectiveness of the cycle consistency of the proposed method.', 'Hierarchical unbiased graph shrinkage (HUGS): A novel groupwise registration for large data set Normalizing all images in a large data set into a common space is a key step in many clinical and research studies, e.g., for brain development, maturation, and aging. Recently, groupwise registration has been developed for simultaneous alignment of all images without selecting a particular image as template, thus potentially avoiding bias in the registration. However, most conventional groupwise registration methods do not explore the data distribution during the image registration. Thus, their performance could be affected by large inter-subject variations in the data set under registration. To solve this potential issue, we propose to use a graph to model the distribution of all image data sitting on the image manifold, with each node representing an image and each edge representing the geodesic pathway between two nodes (or images). Then, the procedure of warping all images to their population center turns to the dynamic shrinking of the graph nodes along their graph edges until all graph nodes become close to each other. Thus, the topology of image distribution on the image manifold is always preserved during the groupwise registration. More importantly, by modeling the distribution of all images via a graph, we can potentially reduce registration error since every time each image is warped only according to its nearby images with similar structures in the graph. We have evaluated our proposed groupwise registration method on both infant and adult data sets, by also comparing with the conventional group-mean based registration and the ABSORB methods. All experimental results show that our proposed method can achieve better performance in terms of registration accuracy and robustness. (C) 2013 Elsevier Inc. All rights reserved.', 'Cascade connection-based channel attention network for bidirectional medical image registration Medical image registration is an essential task in researching and applying medical images. Doctors can observe and extract relevant pathological features to quickly analyze the disease by registered images to diagnose the infection. After more than ten years of research and development, medical image registration has achieved good research results in traditional and deep learning methods. However, most existing methods only focus on unidirectional medical image registration research and rarely consider bidirectional medical image registration research. This paper proposes a new, unsupervised bidirectional medical image registration method based on this aspect. This method guarantees the registration effect in the forward and reverses directions and adds a cascade connection-based channel attention network to the registration model to enable better automatic learning of the registration model, optimizes feature weights, and extracts essential information from images to improve registration performance. We verified the effectiveness of our method by conducting experiments on large-scale 3D brain MRI images and achieved a comparable registration speed and effect with most existing medical image registration methods.']"
84,165,84_chaotic_chaos_dynamics_dynamical,"['chaotic', 'chaos', 'dynamics', 'dynamical', 'neural', 'noisy', 'dynamic', 'phenomena', 'neuron', 'noise']","['Dynamic characteristic of a multiple chaotic neural network and its application Based on chaotic neural network, a multiple chaotic neural network algorithm combining two different chaotic dynamics sources in each neuron is proposed. With the effect of self-feedback connection and non-linear delay connection weight, the new algorithm can contain more powerful chaotic dynamics to search the solution domain globally in the beginning searching period. By analyzing the dynamic characteristic and the influence of cooling schedule in simulated annealing, a flexible parameter tuning strategy being able to promote chaotic dynamics convergence quickly is introduced into our algorithm. We show the effectiveness of the new algorithm in two difficult combinatorial optimization problems, i.e., a traveling salesman problem and a maximum clique problem.', 'Visual object tracking with online weighted chaotic multiple instance learning In this paper, a chaotic multiple instance learning tracker based on chaos theory for a robust and efficient online tracking is introduced. In this method, chaotic characteristics can be utilized for representing the target as well as the updating appearance model, which has not been used for the tracking task. The computational architecture of the method is organized as follows. (1) Chaotic representation: a chaotic model can capture the complex dynamics of the target region to train the weak classifiers. Our representation can balance the global and local features to handle fast motion, partial occlusion, and illumination changes. (2) Importance of instance: fractal dimension of the dynamic model can be adjusted as instance weight for efficient online learning. (3) Chaotic approximation: A robust chaotic approximation to update the appearance model is introduced, which is crucial to select the discriminative and robust features. Chaotic online learning quickly explores the feature space to update the appearance model of the target by means of a chaotic map. The experimental results reveal that the proposed method is more effective and robust than the state-of-the-art trackers on various challenging sequences. Indeed, the efficiency of the proposed method is attributed to its strong online updating of chaotic policy as well as desirable target representation of chaotic model. (C) 2017 Elsevier B.V. All rights reserved.', 'Chaotic neural networks and chaotic annealing A simple model of single neuron with chaotic dynamics is proposed. Neural networks coupled by such neurons have the property of temporal retrieval of stored patterns in a chaotic way. The network is also studied from the viewpoint of optimization. A chaotic annealing technique is developed to search for the global minima of the energy with transient chaos. (C) 2000 Elsevier Science B.V. All rights reserved.']"
85,165,85_aneurysms_aneurysm_aneurysmal_artery,"['aneurysms', 'aneurysm', 'aneurysmal', 'artery', 'arteries', 'intracranial', 'arterial', 'vascular', 'angiography', 'aortic']","[""Computational haemodynamics in two idealised cerebral wide-necked aneurysms after stent placement Endovascular stents are being commonly used to treat cerebral wide-necked aneurysms recently. The effect of a stent placed in the parent artery is not only to protect the parent artery from occlusion, due to extension of coils and thrombosis, but also to act as flow diverter to vary the haemodynamics in the aneurysm. In this article, two idealised cerebral wide-necked aneurysms were created, one was sidewall aneurysm with curved parent vessel and the other was terminal aneurysm with the bifurcated parent vessel. The plexiglass models of the two aneurysms were 'treated' with commercial porous intravascular stents. The stented physical models were scanned by Micro-CT and the numerical models of the two idealised cerebral wide-necked aneurysms after stent placement were constructed from the scanned image files. The pulsatile flow of non-Newtonian fluid inside the models was simulated by using computational fluid dynamics package. From the simulated flow dynamics, various haemodynamic characteristics such as velocity contours, wall shear stress and oscillatory shear index (OSI) were computed. The velocity of the jet entering the sacs reduced after stent was deployed across the necks of both sidewall and terminal aneurysms; the wall shear stress on the distal neck of sidewall aneurysm reduced, the wall shear stress on the dome of the terminal aneurysm increased and the OSI on the dome of the terminal aneurysm reduced. Therefore, stent placement not only promotes thrombus formation in both aneurysm models but also reduces the regrowth risk of the sidewall aneurysm and the rupture risk of the terminal aneurysm."", 'An approach to quantitative assessment of hemodynamic differences between unruptured and ruptured ophthalmic artery aneurysms Background and purpose: Hemodynamic parameters are important in the pathogenesis, evolution and rupture of intracranial aneurysm. Energy loss (EL) has been applied for the rupture risk prediction of artery aneurysms recently. We proposed a new EL and further investigate its effects on the rupture of aneurysms. Materials and methods: Sixty-four patient-specific ophthalmic aneurysm datasets were divided into ruptured and unruptured groups based on their clinical history. Based on patient-specific 3D-DSA data, realistic models were retrospectively reconstructed and then analyzed by using computational fluid dynamic method. Results: The flow field feature EL in ruptured cases was significantly higher than that in unruptured cases. The average wall shear stress (WSS) and the maximum WSS in ruptured cases were higher than those in unruptured cases. Modified pressure loss coefficient (PLCM) in ruptured cases was slight higher than that in unruptured cases but the difference has no statistical significance. Multivariate logistic regression analysis demonstrated flow field feature EL (p<0.05) and the maximum WSS (p<0.05) were the only independently significant variables to predict rupture of ophthalmic aneurysm. There were no differences in PLCM, the maximum oscillatory shear index (OSI), the average OSI and AR between the two groups. Conclusion: Flow field feature EL may be a reliable factor to predict the rupture risk of aneurysms.', 'Risk of rupture of the cerebral aneurysm in relation to traumatic brain injury using a patient-specific fluid-structure interaction model Conclusions: Although the injury to the aneurysm wall after TBI is lower than that of the aneurysm wall mechanical strength, it still can alter the stress pattern in the wall and disrupt the hemodynamics of the blood. These results have implications in understanding the rupture risk of the cerebral aneurysm due to TBI, which may contribute in establishing preventive and/or treatment methods. (C) 2019 Elsevier B.V. All rights reserved. Method: A patient-specific FSI model of the human skull, brain, and cerebral aneurysm, was established using human computed tomography (CT)/magnetic resonance imaging (MRI) data and subjected to a frontal TBI. Background and objective: Cerebral aneurysm, which is defined as one of the weakened area in the wall of an artery in the brain, ruptures when wall tension exceeds its mechanical strength. Traumatic brain injury (TBI) by exerting a sudden impact load to the brain can lead to mechanical failure of the cerebral blood vessels followed by an alteration in not only the structure but also the function of the cerebrovascular. TBI also alters the hemodynamics of the blood flow in the cerebrovascular, while it has been shown that hemodynamics has a key asset in the progression and rupture of the cerebral aneurysms. So far, there is a lack of knowledge on the risk of rupture of the cerebral aneurysm in relation to TBI. Therefore, this study aimed to calculate the mechanical stresses and deformations in the arterial wall as well as the pressure and velocity of the blood using a fluid-structure interaction (FSI) model of the cerebral aneurysm located in the anterior circulation region of the circle of Willis. Results: The results revealed considerable increasing of similar to 8 kPa (60 mmHg) and 0.40 m/s in the pressure and velocity of the blood in the intraluminal of the cerebral artery after TBI. The von Mises stress, shear stress, and deformation of the cerebral aneurysm wall also showed the increasing of 56.03 kPa, 15.66 Pa, and 0.072 mm after TBI, respectively.']"
86,163,86_navigational_robot_robots_navigation,"['navigational', 'robot', 'robots', 'navigation', 'mapping', 'autonomous', 'cognition', 'direction', 'neural', 'map']","[""Robotic Navigation Based on Experiences and Predictive Map Inspired by Spatial Cognition Humans and animals have environmental cognition and navigation abilities. These abilities are closely related to the spatial cognitive mechanism of brain. Based on this mechanism, we propose a novel robotic navigation framework based on experiences and predictive map inspired by spatial cognition to accurately construct environment experience and quickly plan path. The grid cell and the place cell are modeled to rapidly integrate self-motion cues. The multidimensional grid coding and one-shot learning rule are utilized for activating the place representation of robot pose. Visual cues provide information for relocation. These information are integrated through experiences which express the topology of the environment, enabling the robot to accurately achieve spatial cognition of complex environment. In order to realize the sequential decision making of hippocampus, the predictive map is introduced to quickly plan the experience sequence to target in dynamic environment. The successor representation model of robot's state is constructed through reinforcement learning. Combined with the goal-based reward function, the shortest path can be replanned to adapt to environment changes. The proposed method is tested in simulated maze, Kitti dataset and corridor environment. Compared with other bionic navigation methods, it has a faster computing speed and higher precision with bionic characteristics. Compared with visual navigation methods, the navigation tasks can robustly be accomplished without complex system design."", ""A Bionic Robot Navigation Algorithm Based on Cognitive Mechanism of Hippocampus The firing of space cell in hippocampus is considered to be able to form an intrinsic map for the environment which is called cognitive map. Previous bionic navigation algorithms (such as rat simultaneous localization and mapping) and traditional SLAM algorithms lack sufficient physiological basis and cannot reflect the cognitive mechanism of hippocampal formation. Based on the cognitive mechanism of hippocampal space cells, this paper proposes a navigation algorithm for constructing accurate environmental cognitive map. This algorithm is characterized by the construction of a unified spatial cell attractor model for self-motion trajectory path integration. The expressions of grid cells and place cells are driven by stripe cells. The algorithm performs closed-loop detection by collecting depth image, red green blue+depthmap information and corrects the error of spatial cells' path integral. Eventually, we get a precise cognitive map of the environment and bionic robot navigation is achieved by global navigation and local navigation algorithm based on the map. The cognitive map is a topological metric map that contains the topological relations of the environment feature point coordinates, visual cues, and specific sites. In this paper, the method is verified by the simulation experiment and the physical experiment on the robot platform. The research results laid the foundation for the research of the robot navigation method based on the hippocampus cognitive mechanism. Note to Practitioners Environmental cognition and navigation ability are the main function of intelligent mobile robots. People and animals have strong adaptability and cognitive ability in unfamiliar environment, and they can independently recognize and navigate in unfamiliar environment. Now, the environmental cognition and navigation ability of intelligent robots are far from the level of human and animal. This paper suggests a bionic robot navigation algorithm based on the cognitive mechanism of rat hippocampus. The bionic robot navigation algorithm makes mobile robots more intelligent by learning and imitating human and animal's environmental cognition and navigation ability. This navigation algorithm conforms to the physiological characteristics and is pretty accurate and intelligent. The experimental results demonstrate the effectiveness of this algorithm in building environment map and navigation."", 'A biologically inspired model based on a multi-scale spatial representation for goal-directed navigation Inspired by the multi-scale nature of hippocampal place cells, a biologically inspired model based on a multi-scale spatial representation for goal-directed navigation is proposed in order to achieve robotic spatial cognition and autonomous navigation. First, a map of the place cells is constructed in different scales, which is used for encoding the spatial environment. Then, the firing rate of the place cells in each layer is calculated by the Gaussian function as the input of the Q-learning process. The robot decides on its next direction for movement through several candidate actions according to the rules of action selection. After several training trials, the robot can accumulate experiential knowledge and thus learn an appropriate navigation policy to find its goal. The results in simulation show that, in contrast to the other two methods(G-Q, S-Q), the multi-scale model presented in this paper is not only in line with the multi-scale nature of place cells, but also has a faster learning potential to find the optimized path to the goal. Additionally, this method also has a good ability to complete the goal-directed navigation task in large space and in the environments with obstacles.']"
87,163,87_preferences_feedbacks_recommender_preference,"['preferences', 'feedbacks', 'recommender', 'preference', 'recommendation', 'feedback', 'ratings', 'recommendations', 'rating', 'recommenders']","[""Generating Knowledge-Based Attentive User Representations for Sparse Interaction Recommendation Deep neural networks (DNNs) have been widely imported into collaborative-filtering (CF) based recommender systems and yielded remarkable superiority over traditional recommendation models. However, most deep CF-based models perform weakly when observed user-item interactions are sparse since user preferences and item characteristics are inferred mainly based on observed (historical) interactions. To address this problem, we propose a deep knowledge-enhanced recommendation model in this paper. Specifically, to augment user/item representations in the scenario of sparse historical user-item interactions, we first incorporate the knowledge from open knowledge graphs and personal information of users as side information, from which sufficient features of users and items are extracted. Second, to well capture shifted user preferences, we leverage a memory component constituted by recently interacted items rather than all historical ones. Third, attentive user representations are generated by attention mechanism to capture the diversity of user preferences. Furthermore, we build a convolutional neural network to pool the latent features in user representations for better user modeling, which enhances recommendation performance further. Our extensive experiments conducted against two real-world datasets, i.e., Douban movie and NetEase music, demonstrate our model's remarkable superiority over the state-of-the-art deep recommendation models."", 'Joint representation learning with ratings and reviews for recommendation Recommender system is an important technique to find the information that the users may be interested by their feedbacks. However, it is still a challenge to model the preference of users due to the sparsity of user feedbacks. To alleviate this problem, many methods are developed by extracting information from various kinds of auxiliary information that are related to the users. In the auxiliary information, review is the popular one, since it can reflect both user preferences and item characteristics. Moreover, the review can generate plausible recommendation explanations in the recommendation results. In this paper, we propose a hybrid deep collaborative filtering model that jointly learns rating embedding and textural feature from ratings and reviews respectively. Specifically, two embedding layers are employed to learn rating embedding for users and items based on the interactions, and two attention-based GRU networks attempt to learn context-aware representation as textural feature for users and items from reviews. To leverage the contribution between rating embedding and textual feature and obtain the fused features for users and items, a proposed gating mechanism is used. Then an interaction-learning layer is adopted to learn the user and item interaction information based on the fused user and item features. The prediction score is obtained with the factorization machine. Experimental results on six real-world datasets demonstrate the superior performance of the proposed method over several state-of-the-art methods. (c) 2020 Elsevier B.V. All rights reserved.', 'Cognitive Knowledge-aware Social Recommendation via Group-enhanced Ranking Model Cognitive inspired recommendation systems have attracted increasing attention in recent years, aiming at fitting user ratings on certain items. However, the performance of recommendation approaches has been limited due to the sparsity and ambiguity of cognitive knowledge user-item ratings. Top-k recommendation has therefore been addressed and has become one of the most popular research areas. The goal of top-k recommendation is to capture the relative preferences of users and fit the optimal ranking list of items. Meanwhile, the development of social networks provides a new way to model user preferences to improve the accuracy and interpretation ability of cognition-aware recommendation models. To integrate user social information into top-k recommendation, we propose a group-enhanced ranking method based on matrix factorization. In our method, we first compute trust values between users based on user trust relationships. Then, we incorporate a trust matrix into the loss function with a social-based penalty term that reduces the distances between preference vectors of trusted users. Experimental results on two real datasets from Epinions and BaiduMovies show that the proposed method outperforms several state-of-the-art methods in terms of the normalized discounted cumulative gain (NDCG) value. Our model effectively improves the accuracy of social recommendations. We propose a novel cognitive knowledge-aware group-enhanced social recommendation method for item recommendation. The model modifies the loss function by considering the user trust relationship and group-enhanced ranking and significantly improves the performance of social recommendations.']"
88,161,88_snns_snn_neural_neuron,"['snns', 'snn', 'neural', 'neuron', 'neurons', 'learning', 'networks', 'neuromorphic', 'network', 'training']","['Automated Adaptive Threshold-Based Feature Extraction and Learning for Spiking Neural Networks Over the past years Spiking Neural Networks (SNNs) models became attractive as a possible bridge to enable low-power event-driven neuromorphic hardware. SNNs have a high computational power due to the implicit employment of the biologically inspired input times. SNNs employ various parameters such as neuron threshold, synaptic delays, and weights in their structures. However, SNNs applications are still limited and elementary compared with other neural network architectures such as the Convolution Neural Networks (CNNs). In this research, a new SNN-based model named Adaptive Threshold Module (ATM) and its algorithm are proposed. The proposed ATM and algorithm depend on the adaptation of the internal spiking neuron threshold level. Adapting the threshold of the neurons is employed to control the spiking neuron firing rate to uniquely extract the main features of the input pattern that is in the shape of spike trains. It is shown that this technique works as an automated feature extraction method of input patterns in an efficient and faster way than other methods. The proposed method can preserve all information of the input spike trains. Simulations of the proposed model and the algorithm, using the challenging speech TIDIGITS dataset, sound RWCP dataset, and Poisson distribution spike trains, show encouraging results. The ATM can make SNN provide an accuracy surpassing that of the current state-of-the-art SNN algorithms and conventional non-spiking learning models.', 'An ensemble unsupervised spiking neural network for objective recognition It is now known that the spiking neuron is a basic unit of spiking neural networks (SNNs). Spiking neu-rons modulate the nervous cells via receiving external incentives, generation of action potential and firing spikes. The SNNs usually used for pattern recognition tasks or complex computation depending on the brain-like characteristic. Although the SNNs have no advantages comparing with the deep neural networks in terms of classification accuracy, the SNNs have more characteristics of biological neurons. In this paper, a hierarchical SNN, comprising convolutional and pooling layers, is designed. The proposed SNN consists of excitatory and inhibitory neurons based on the mechanism of the primate brain. A temporal coding (rank order) manner is used to encode the input patterns. It depends on the rank of the spike arrival on post synapses to establish the priority of input spikes for a particular pattern. The spike-timing dependent plasticity (STDP) learning rule is used in convolutional layers to extract visual features in an unsupervised learning manner. During the classification stage, a lateral inhibition mechanism is used to prevent the non-firing neurons and produce distinguishable results. In order to improve the performance of our SNN, an ensemble SNN architecture using the voting method is proposed, and transfer learning is used to avoid re-training the SNN when solving the different tasks. The hand-written digits classification task on MNIST, CIFAR-10, and BreaKHis databases are used to verify the performance of the proposed SNN. Experimental results show that by using the ensemble architecture and transfer learning, the classification accuracy of 99.27% for the MNIST database, overall accuracy is 93% for the CIFAR-10 database, and overall accuracy is 96.97% for BreaKHis database. In the meantime, this work achieves a better performance than the benchmarking approaches. Taken together, the results of our work suggest that the ensemble SNN architecture with transfer learning is key to improving the performance of the SNN. (c) 2020 Elsevier B.V. All rights reserved.', 'Enabling Spike-Based Backpropagation for Training Deep Neural Network Architectures Spiking Neural Networks (SNNs) have recently emerged as a prominent neural computing paradigm. However, the typical shallow SNN architectures have limited capacity for expressing complex representations while training deep SNNs using input spikes has not been successful so far. Diverse methods have been proposed to get around this issue such as converting off-the-shelf trained deep Artificial Neural Networks (ANNs) to SNNs. However, the ANN-SNN conversion scheme fails to capture the temporal dynamics of a spiking system. On the other hand, it is still a difficult problem to directly train deep SNNs using input spike events due to the discontinuous, non-differentiable nature of the spike generation function. To overcome this problem, we propose an approximate derivative method that accounts for the leaky behavior of LIF neurons. This method enables training deep convolutional SNNs directly (with input spike events) using spike-based backpropagation. Our experiments show the effectiveness of the proposed spike-based learning on deep networks (VGG and Residual architectures) by achieving the best classification accuracies in MNIST, SVHN, and CIFAR-10 datasets compared to other SNNs trained with a spike-based learning. Moreover, we analyze sparse event-based computations to demonstrate the efficacy of the proposed SNN training method for inference operation in the spiking domain.']"
89,160,89_dementia_caregivers_caregiver_alzheimer,"['dementia', 'caregivers', 'caregiver', 'alzheimer', 'elderly', 'carers', 'elders', 'aging', 'caring', 'adults']","['Co-design of an mHealth application for family caregivers of people with dementia to address functional disability care needs The co-design of a mobile health (mHealth) application for family caregivers of people with dementia to address functional disability care needs is presented. Participants included family caregivers of people with dementia, aged care nurses, physicians, occupational therapists, and information technology (IT) experts. The co-design process involved two phases: (1) needs assessment phase (an online survey and in-depth interviews with family caregivers and expert consultation); and (2) development of an mHealth application (content and prototype development). Data triangulation from phase one informed the content of the application. Data triangulation resulted in three content modules: """"an overview of dementia and care,"""" """"management of daily living activities,"""" and """"caregivers\' health and well-being."""" The content was based on contemporary literature, and care guidelines with input from family caregivers and dementia care experts. IT engineers developed the mHealth application. In this study, an Android-based mHealth application was designed to address the functional care needs of family caregivers and the co-design process ensured the incorporation of end-users\' real-world experiences and the opinions and expertise of key stakeholders in the development of the application prototype.It is to be noted that before releasing the application into the app store, testing its feasibility and effectiveness is essential.', 'Seeing the First-Person Perspective in Dementia: A Qualitative Personal Evaluation Game to Evaluate Assistive Technology for People Affected by Dementia in the Home Context The number of people with dementia is increasing rapidly. As a result, care has to be extended towards the home context. This increases the burden on both informal caregivers and persons affected by dementia. To support these people more effectively, technology could play an important role. However, it proves to be challenging to involve them in user-centred research with this purpose. Therefore, there is a need for more research approaches that gather first-hand experiences with technology from people with dementia directly. This research presents a personal evaluation game method, used in the home context to study assistive technology as experienced by its users. In parallel, a questionnaire was applied to explore the difference in data and experiences between both methods. In the study, 12 households participated, each with a person diagnosed with dementia and a partner still living with them as their informal caregiver. During a period of 3 weeks, participants experienced a dynamic lighting armature designed to improve the sleep-wake cycle and evaluated it through one of these methods. The results show that the newly developed method manages to capture the first-person perspective, and is a more appropriate research tool for people with dementia. The information gathered with the tool allowed the researchers to capture the daily lives of the participants in detail, mainly due to the diverse types of input. The personal evaluation game shows a first step towards an ecologically valid tool that includes people with dementia directly. As such the method proved to be qualitative and explorative, and able to provide insights into both the technology and the daily lives of people living with dementia.', 'Internet-Based Interventions Aimed at Supporting Family Caregivers of People With Dementia: Systematic Review Background: Caring for someone with dementia is one of the most challenging caring roles. The need for support for family caregivers has been recognized for some time but is often still lacking. With an aging population, demand on health and social care services is growing, and the population is increasingly looking to the internet for information and support. Conclusions: Although mixed, the results indicate a positive response for the use of internet-based interventions by caregivers. More high-quality studies are required to identify the effectiveness of internet interventions aimed at supporting family caregivers, with particular focus on meeting the needs of caregivers during the different stages of dementia. Methods: We conducted a systematic search of online databases in April 2018. We searched reference lists and tracked citations. All study designs were included. We adopted a narrative synthesis approach with thematic analysis and tabulation as tools. Objective: In this review, we aimed to (1) identify the key components of existing internet-based interventions designed to support family caregivers of people with dementia, (2) develop an understanding of which components are most valued by caregivers, and (3) consider the evidence of effectiveness of internet-based interventions designed to support family caregivers of people with dementia. Results: We identified 2325 studies, of which we included 40. The interventions varied in the number and types of components, duration and dose, and outcomes used to measure effectiveness. The interventions focused on (1) contact with health or social care providers, (2) peer interaction, (3) provision of information, (4) decision support, and (5) psychological support. The overall quality of the studies was low, making interpretation and generalizability of the effectiveness findings difficult. However, most studies suggested that interventions may be beneficial to family caregiver well-being, including positive impacts on depression, anxiety, and burden. Particular benefit came from psychological support provided online, where several small randomized controlled trials suggested improvements in caregiver mental health. Provision of information online was most beneficial when tailored specifically for the individual and used as part of a multicomponent intervention. Peer support provided in online groups was appreciated by most participants and showed positive effects on stress. Finally, online contact with a professional was appreciated by caregivers, who valued easy access to personalized practical advice and emotional support, leading to a reduction in burden and strain.']"
90,158,90_learning_training_learner_adaptive,"['learning', 'training', 'learner', 'adaptive', 'active', 'sampling', 'classification', 'selection', 'estimator', 'datasets']","['AL-ELM: One uncertainty-based active learning algorithm using extreme learning machine It is well known that in supervised learning, active learning could effectively decrease the complexity of training instances without obvious loss of the classification performance. Generally, active learning is applied in the scenario that lots of instances are easy to be acquired, but labeling them is expensive and/or time-consuming. In this study, we try to implement active learning by using extreme learning machine (ELM) classifier based on three reasons as follows: (1) ELM has light computational costs, (2) ELM has strong generalization ability which is even comparable with support vector machine (SVM) and (3) ELM could be directly applied on both binary-class and multiclass problems. Specifically, an active learning algorithm based on ELM classifier named AL-ELM is proposed in this paper. During active learning, AL-ELM estimates the uncertainty of each unlabeled instance by creating a mapping relation between the actual outputs of the instance in ELM and the approximated membership probability of the same instance. In other words, ELM is converted as the equivalent Bayes classifier. On each iteration, those most uncertain instances are extracted and labeled to promote the quality of classification model. The learning procedure stops until it satisfies a pre-designed criterion. Experimental results on 20 benchmark data sets show that AL-ELM is better than or at least comparable to several state-of-the-art uncertainty-based active learning algorithms. Also, in contrast with several other algorithms, AL-ELM could effectively decrease the running time of learning procedure. (C) 2015 Elsevier B.V. All rights reserved.', 'Empirical investigation of active learning strategies Many predictive tasks require labeled data to induce classification models. The data labeling process may have a high cost. Several strategies have been proposed to optimize the selection of the most relevant examples, a process referred to as active learning. However, a lack of empirical studies comparing different active learning approaches across multiple datasets makes it difficult identifying the most promising strategies, or even assessing the relative gain of active learning over the trivial random selection of instances. In this study, a comprehensive comparison of active learning strategies is presented, with various instance selection criteria, different classification algorithms and a large number of datasets. The experimental results confirm the effectiveness of active learning and provide insights about the relationship between classification algorithms and active learning strategies. Additionally, ranking curves with bands are introduced as a means to summarize in a single chart the performance of each active learning strategy for different classification algorithms and datasets. (C) 2017 Elsevier B.V. All rights reserved.', 'Particle Swarm Optimization Based Swarm Intelligence for Active Learning Improvement: Application on Medical Data Classification Semi-supervised learning targets the common situation where labeled data are scarce but unlabeled data are abundant. It uses unlabeled data to help supervised learning tasks. In practice, it may make sense to utilize active learning in conjunction with semi-supervised learning. That is, we might allow the learning algorithm to pick a set of unlabeled instances to be labeled by a domain expert, which will then be used as the labeled data set. However, existing approaches are computationally expensive and require searching through an entire unlabeled dataset, which may contain redundant instances that provide no instructive information to the classifier and can decrease the performance. To address this optimization problem, a hybrid system that combines active learning (AL) and particle swarm optimization (PSO) algorithms is proposed to reduce the cost of labeling while building a more efficient classifier. The novelty of this work resides in the integration of a bio-inspired optimization algorithm in the machine learning strategy. Furthermore, a novel uncertainty measure was integrated into the particle swarm optimization algorithm as an objective function to select from massive amounts of medical instances those that are deemed mostinformative.To evaluate the effectiveness of the proposed approach, eighteen (18) benchmark datasets were used and compared against three best-known classifiers with different learning paradigms:AL-NBan active learning algorithm using Naive Base classifier and Margin Sampling strategy,SVM(Support Vector Machine),ELM(Extreme Learning Machine) with supervised learning, andTSVM(Transductive Support Vector Machine) with the semi-supervised learning. Experiments showed that the proposed approach is effective in reducing the efforts required by experts for medical data annotation to produce an accurate classifier. The active learning approach has been utilized to optimize the expensive task of labeling. Based on a novel uncertainty measure, the nature-inspired algorithm PSO attempts to select from massive amounts of unlabeled medical instances those consideredinformative, at the same time improving the classifier performance. The experiments carried out confirm that the proposed strategy significantly enhances the performance of the AL algorithm compared with the commonly used uncertainty strategies. It achieves a performance similar to that of fully supervised and semi-supervised algorithms while requiring much less labeling. As a future extension of this work, it would be interesting to integrate other evolutionary optimization algorithms and compare them with our approach. In addition, it is beneficial to test the impact of using other variants of PSO algorithm in our approach. Also, it is aimed to test more classification algorithms in the experimentation process.']"
91,158,91_mammography_mammograms_mammographic_breast,"['mammography', 'mammograms', 'mammographic', 'breast', 'cancer', 'cancers', 'biopsy', 'imaging', 'mri', 'diagnostic']","['Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2 & x0025;, Sensitivity 98.3 & x0025;, and Specificity 96.5 & x0025; has been compared to other existing systems.', 'Radiomics and Machine Learning with Multiparametric Breast MRI for Improved Diagnostic Accuracy in Breast Cancer Diagnosis The purpose of this multicenter retrospective study was to evaluate radiomics analysis coupled with machine learning (ML) of dynamic contrast-enhanced (DCE) and diffusion-weighted imaging (DWI) radiomics models separately and combined as multiparametric MRI for improved breast cancer detection. Consecutive patients (Memorial Sloan Kettering Cancer Center, January 2018-March 2020; Medical University Vienna, from January 2011-August 2014) with a suspicious enhancing breast tumor on breast MRI categorized as BI-RADS 4 and who subsequently underwent image-guided biopsy were included. In 93 patients (mean age: 49 years +/- 12 years; 100% women), there were 104 lesions (mean size: 22.8 mm; range: 7-99 mm), 46 malignant and 58 benign. Radiomics features were calculated. Subsequently, the five most significant features were fitted into multivariable modeling to produce a robust ML model for discriminating between benign and malignant lesions. A medium Gaussian support vector machine (SVM) model with five-fold cross validation was developed for each modality. A model based on DWI-extracted features achieved an AUC of 0.79 (95% CI: 0.70-0.88), whereas a model based on DCE-extracted features yielded an AUC of 0.83 (95% CI: 0.75-0.91). A multiparametric radiomics model combining DCE- and DWI-extracted features showed the best AUC (0.85; 95% CI: 0.77-0.92) and diagnostic accuracy (81.7%; 95% CI: 73.0-88.6). In conclusion, radiomics analysis coupled with ML of multiparametric MRI allows an improved evaluation of suspicious enhancing breast tumors recommended for biopsy on clinical breast MRI, facilitating accurate breast cancer diagnosis while reducing unnecessary benign breast biopsies.', ""Breast Lesion Classification with Multiparametric Breast MRI Using Radiomics and Machine Learning: A Comparison with Radiologists' Performance Simple Summary Currently, breast contrast-enhanced MRI is the most sensitive imaging technique for breast cancer detection; however, its specificity is low given the common characteristics shared by benign breast lesions and some cancers. This leads to a high number of false-positive cases and, therefore, unnecessary biopsies. Multiparametric MRI including diffusion-weighted imaging assists in this task by increasing the specificity for breast lesion discrimination. Nevertheless, interpretation of breast MRI is still highly dependent on the reader's level of experience. Our work combines radiomic features extracted from multiparametric MRI to generate predictive models for breast cancer differentiation. Additionally, decision support models were compared with the performance of two breast dedicated radiologists for lesion differentiation. Our work proves the potential of multiparametric radiomics coupled with machine learning to be implemented in clinical practice for lesion differentiation on breast MRI. AI algorithms show value to assist less experienced readers, improving the accuracy for breast lesion discrimination. This multicenter retrospective study compared the performance of radiomics analysis coupled with machine learning (ML) with that of radiologists for the classification of breast tumors. A total of 93 consecutive women (mean age: 49 +/- 12 years) with 104 histopathologically verified enhancing lesions (mean size: 22.8 +/- 15.1 mm), classified as suspicious on multiparametric breast MRIs were included. Two experienced breast radiologists assessed all of the lesions, assigning a Breast Imaging Reporting and Database System (BI-RADS) suspicion category, providing a diffusion-weighted imaging (DWI) score based on lesion signal intensity, and determining the apparent diffusion coefficient (ADC). Ten predictive models for breast lesion discrimination were generated using radiomic features extracted from the multiparametric MRI. The area under the receiver operating curve (AUC) and the accuracy were compared using McNemar's test. Multiparametric radiomics with DWI score and BI-RADS (accuracy = 88.5%; AUC = 0.93) and multiparametric radiomics with ADC values and BI-RADS (accuracy= 88.5%; AUC = 0.96) models showed significant improvements in diagnostic accuracy compared to the multiparametric radiomics (DWI + DCE data) model (p = 0.01 and p = 0.02, respectively), but performed similarly compared to the multiparametric assessment by radiologists (accuracy = 85.6%; AUC = 0.03; p = 0.39). In conclusion, radiomics analysis coupled with the ML of multiparametric MRI could assist in breast lesion discrimination, especially for less experienced readers of breast MRIs.""]"
92,155,92_variational_bayesian_stochastic_likelihood,"['variational', 'bayesian', 'stochastic', 'likelihood', 'probability', 'random', 'probabilities', 'statistical', 'complexities', 'divergence']","['Stochastic complexity for mixture of exponential families in variational Bayes In this paper, we discuss the Variational Bayesian learning of the mixture of exponential families and derive the asymptotic form of the stochastic complexities. We show that the stochastic complexities become smaller than those of regular statistical models, which implies the advantage of the Bayesian learning still remains in the Variational Bayesian learning. Stochastic complexity, which is called the marginal likelihood or the free energy, not only becomes important in addressing the model selection problem but also enables us to discuss the accuracy of the Variational Bayesian approach as an approximation of the true Bayesian learning. The Variational Bayesian learning, proposed as an approximation of the Bayesian learning, has provided computational tractability and good generalization performance in many applications. However, little has been done to investigate its theoretical properties.', 'Stochastic complexity for mixture of exponential families in generalized variational Bayes In this paper, we discuss the Variational Bayesian learning of the mixture of exponential families and derive the asymptotic form of the stochastic complexities in a generalized setting of the prior distribution. We show that the stochastic complexities become smaller than those of regular statistical models, which implies that the advantage of the Bayesian learning still remains in the Variational Bayesian learning. Stochastic complexity, which is called the marginal likelihood or the free energy, not only becomes important in addressing the model selection problem but also enables us to discuss the accuracy of the Variational Bayesian approach as an approximation of the true Bayesian learning. The main result also shows the effects of the prior distribution under the generalized setting. (C) 2007 Elsevier B.V. All rights reserved. The Variational Bayesian learning, proposed as an approximation of the Bayesian learning, has provided computational tractability and good generalization performance in many applications. However, little has been done to investigate its theoretical properties.', 'Stochastic complexities of general mixture models in variational Bayesian learning The asymptotic form was obtained for the stochastic complexity, or the free energy in the variational Bayesian learning of a mixture of exponential-family distributions, which is the main contribution this paper makes. We reveal that the stochastic complexities become smaller than those of regular statistical models, which implies that the advantages of Bayesian learning are still retained in variational Bayesian learning. Moreover, the derived bounds indicate what influence the hyperparameters have on the learning process, and the accuracy of the variational Bayesian approach as an approximation of true Bayesian learning. (c) 2006 Elsevier Ltd. All rights reserved. In this paper, we focus on variational Bayesian learning of general mixture models. Variational Bayesian learning was proposed as an approximation of Bayesian learning. While it has provided computational tractability and good generalization in many applications, little has been done to investigate its theoretical properties.']"
93,155,93_segmentation_biomedical_medical_imaging,"['segmentation', 'biomedical', 'medical', 'imaging', 'mri', 'clinical', 'learning', 'classification', 'research', 'diagnosis']","['Recent advances and clinical applications of deep learning in medical image analysis Deep learning has received extensive research interest in developing new medical image processing algorithms, and deep learning based models have been remarkably successful in a variety of medical imaging tasks to support disease detection and diagnosis. Despite the success, the further improvement of deep learning models in medical image analysis is majorly bottlenecked by the lack of large-sized and well annotated datasets. In the past five years, many studies have focused on addressing this challenge. In this paper, we reviewed and summarized these recent studies to provide a comprehensive overview of applying deep learning methods in various medical image analysis tasks. Especially, we emphasize the latest progress and contributions of state-of-the-art unsupervised and semi-supervised deep learning in medical image analysis, which are summarized based on different application scenarios, including classification, segmentation, detection, and image registration. We also discuss major technical challenges and suggest possible solutions in the future research effort s.(c) 2022 Elsevier B.V. All rights reserved.', 'A medical image segmentation method based on multi-dimensional statistical features Medical image segmentation has important auxiliary significance for clinical diagnosis and treatment. Most of existing medical image segmentation solutions adopt convolutional neural networks (CNNs). Althought these existing solutions can achieve good image segmentation performance, CNNs focus on local information and ignore global image information. Since Transformer can encode the whole image, it has good global modeling ability and is effective for the extraction of global information. Therefore, this paper proposes a hybrid feature extraction network, into which CNNs and Transformer are integrated to utilize their advantages in feature extraction. To enhance low-dimensional texture features, this paper also proposes a multi-dimensional statistical feature extraction module to fully fuse the features extracted by CNNs and Transformer and enhance the segmentation performance of medical images. The experimental results confirm that the proposed method achieves better results in brain tumor segmentation and ventricle segmentation than state-of-the-art solutions.', 'Domain- and task-specific transfer learning for medical segmentation tasks Background and objectives: Transfer learning is a valuable approach to perform medical image segmentation in settings with limited cases available for training convolutional neural networks (CNN). Both the source task and the source domain influence transfer learning performance on a given target medical image segmentation task. This study aims to assess transfer learning-based medical segmentation task performance for various source task and domain combinations. Methods: CNNs were pre-trained on classification, segmentation, and self-supervised tasks on two domains: natural images and T1 brain MRI. Next, these CNNs were fine-tuned on three target T1 brain MRI segmentation tasks: stroke lesion, MS lesions, and brain anatomy segmentation. In all experiments, the CNN architecture and transfer learning strategy were the same. The segmentation accuracy on all target tasks was evaluated using the mIOU or Dice coefficients. The detection accuracy was evaluated for the stroke and MS lesion target tasks only. Results: CNNs pre-trained on a segmentation task on the same domain as the target tasks resulted in higher or similar segmentation accuracy compared to other source task and domain combinations. Pre-training a CNN on ImageNet resulted in a comparable, but not consistently higher lesion detection rate, despite the amount of training data used being 10 times larger. Conclusions: This study suggests that optimal transfer learning for medical segmentation is achieved with a similar task and domain for pre-training. As a result, CNNs can be effectively pre-trained on smaller datasets by selecting a source domain and task similar to the target domain and task. (C) 2021 Elsevier B.V.']"
94,155,94_stability_synchronization_periodicity_delays,"['stability', 'synchronization', 'periodicity', 'delays', 'neural', 'periodic', 'intermittent', 'delay', 'theoretical', 'stabilization']","['Stability Analysis of Neutral-Type Cohen-Grossberg Neural Networks With Multiple Time-Varying Delays This paper deals with the problem for stability of neutral-type Cohen-Grossberg neural networks involving delay parameters. In the neutral-type neural networks, the states of the neurons involve multiple time-varying delays and time derivative of states of neurons include discrete time delays. We note that the neutral-type neural network cannot be expressed in the vector-matrix form due to multiple time-varying delays and discrete neutral delays, which leads to linear matrix inequality approach can not be employed to obtain stability conditions of this type of Cohen-Grossberg neural networks. Therefore, it is difficult for stability analysis of this type of Cohen-Grossberg neural networks to find suitable Lyapunov-Krasovskii functional and effective method. This paper constructs an appropriate Lyapunov-Krasovskii functional and employs M-matrix property to derive new sufficient conditions ensuring the global asymptotic stability of the equilibrium point of the neutral-type Cohen-Grossberg neural networks with multiple time-varying delays in the states and discrete delays in the time derivative of the states. The obtained stability conditions are easy to validate by testing basic matrix property. A constructive example is presented to indicate applicability of the obtained stability criteria. Compared with the existed references, the networks we studied are more general and the derived results develop and generalize the known results.', 'Global asymptotical stability of Cohen-Grossberg neural networks with time-varying and distributed delays In this paper, we discuss delayed Cohen-Grossberg neural networks with time-varying and distributed delays and investigate their global asymptotical stability of the equilibrium point. The model proposed in this paper is universal. A set of sufficient conditions ensuring global convergence and globally exponential convergence for the Cohen-Grossberg neural networks with time-varying and distributed delays are given. Most of the existing models and global stability results for Cohen-Grossberg neural networks, Hopfield neural networks and cellular neural networks can be obtained from the theorems given in this paper.', 'Stability Analysis of Cohen-Grossberg Neural Networks With Multiple Time-Varying Delays By improving a previously introduced Lyapunov functional,this paper addressed the stability issue about neutral-type Cohen-Grossberg neural networks with multiple time-varying delays in the states of neurons and the time derivative of states of neurons, a sufficient condition for global asymptotic stability is obtained. Since the Cohen-Grossberg neural networks considered in this paper is more general than those in the former literature, the obtained result developed stability condition of Cohen-Grossberg neural networks. At the end of the paper, two examples are employed to demonstrate the validity and superiority of the conclusion.']"
95,154,95_virtual_pain_analgesia_analgesic,"['virtual', 'pain', 'analgesia', 'analgesic', 'therapy', 'venipuncture', 'sessions', 'interventions', 'experience', 'treatment']","[""Virtual Reality as a Clinical Tool for Pain Management Current management techniques for acute and chronic pain, such as opioids and physical therapy, are often incomplete or ineffective. VR trials demonstrate a potential to redefine the approach to treating acute and chronic pain in the clinical setting. Patient immersion in interactive virtual reality provides distraction from painful stimuli and can decrease an individual's perception of the pain. In this review, we discuss the use of VR to provide patient distraction from acute pain induced from electrical, thermal, and pressure conditions. We also discuss the application of VR technologies to treat various chronic pain conditions in both outpatient and inpatient settings. Recent articles support the hypothesis that VR therapies can effectively distract patients who suffer from chronic pain and from acute pain stimulated in trials. Clinical studies yield promising results in the application of VR therapies to a variety of acute and chronic pain conditions, including fibromyalgia, phantom limb pain, and regional specific pain from past injuries and illnesses. To evaluate the use of virtual reality (VR) therapies as a clinical tool for the management of acute and chronic pain."", ""Effectiveness of Virtual Reality-Based Interventions for Managing Chronic Pain on Pain Reduction, Anxiety, Depression and Mood: A Systematic Review (1) Background: Patients diagnosed with chronic pain suffer from long-term pain, which negatively affects their daily lives and mental health. Virtual reality (VR) technologies are considered a therapeutic tool to manage pain perception and mental health conditions. This systematic review aimed to appraise the efficacy of VR in improving pain intensity, anxiety, depression and mood among patients with chronic pain; (2) Methods: Five electronic databases were systematically searched using the terms representing VR and chronic pain. Quality assessment was conducted using Cochrane Collaboration's tool and Newcastle-Ottawa scale; (3) Results: Seventeen peer-reviewed articles were included in this review. It was found that VR was able to reduce pain intensity in patients with phantom limb pain, chronic headache, chronic neck pain and chronic low-back pain. The effects of VR on the improvement of anxiety, depression and mood were not determined due to the inadequate amount of clinical evidence; (4) Conclusions: VR, especially immersive VR, improves pain outcomes and its effects may vary depending on the approach and study design. More research is still needed to investigate the clinical use of VR in patients with chronic pain."", 'Using Virtual Reality Exposure Therapy in Pain Management: A Systematic Review and Meta-Analysis of Randomized Controlled Trials Objectives: This study aimed to assess the effectiveness of virtual reality (VR) in managing different types of pain in different age groups and to provide evidence for the clinical application of new alternative strategy for pain management. Methods: Electronic databases, including the Cochrane Library, PubMed, EMBASE, and the Web of Science, were searched for studies published up to October 2020. Randomized controlled trials that reported on VR for pain management were included. Results: A total of 31 randomized controlled trials were included. As for the pain intensity, the increase of visual analog scale score in the VR group was 1.62 scores less than that in the control group. In juvenile patients, the VR group had 1.79 scores lower than that in control group. For adult patients, the VR group had 1.34 scores lower than that in control group. As for other pain-related indicators, the VR group had lower levels of anxiety, lower pain unpleasantness, lower pulse rate, and shorter duration of dressing change and spent less time thinking about pain. Nevertheless, there was no statistical difference in pain tolerance. VR can effectively alleviate acute pain. In terms of chronic low back pain and cancer-related pain, there was no statistical difference between VR therapy and standard therapy. Conclusions: VR is a feasible alternative therapy for both juveniles and adults in pain management, and it has a greater potential for juveniles. VR can effectively alleviate acute pain. Nevertheless, VR showed little effectiveness in increasing pain tolerance, which may explain in part the ineffectiveness of VR therapy in pain management for chronic pain.']"
96,154,96_dementia_alzheimer_elderly_aging,"['dementia', 'alzheimer', 'elderly', 'aging', 'cognitive', 'predictive', 'neuropsychological', 'biomarkers', 'disease', 'prevalence']","[""Gender-Based Analysis of Risk Factors for Dementia Using Senior Cohort Globally, one of the biggest problems with the increase in the elderly population is dementia. However, dementia still has no fundamental cure. Therefore, it is important to predict and prevent dementia early. For early prediction of dementia, it is crucial to find dementia risk factors that increase a person's risk of developing dementia. In this paper, the subject of dementia risk factor analysis and discovery studies were limited to gender, because it is assumed that the difference in the prevalence of dementia in men and women will lead to differences in the risk factors for dementia among men and women. This study analyzed the Korean National Health Information System-Senior Cohort using machine-learning techniques. By using the machine-learning technique, it was possible to reveal a very small causal relationship between data that are ignored using existing statistical techniques. By using the senior cohort, it was possible to analyze 6000 data that matched the experimental conditions out of 558,147 sample subjects over 14 years. In order to analyze the difference in dementia risk factors between men and women, three machine-learning-based dementia risk factor analysis models were constructed and compared. As a result of the experiment, it was found that the risk factors for dementia in men and women are different. In addition, not only did the results include most of the known dementia risk factors, previously unknown candidates for dementia risk factors were also identified. We hope that our research will be helpful in finding new dementia risk factors."", 'Use of Patient-Reported Symptoms from an Online Symptom Tracking Tool for Dementia Severity Staging: Development and Validation of a Machine Learning Approach Background: SymptomGuide Dementia (DGI Clinical Inc) is a publicly available online symptom tracking tool to support caregivers of persons living with dementia. The value of such data are enhanced when the specific dementia stage is identified. Conclusions: A supervised machine learning algorithm exhibited excellent performance in identifying dementia stages based on dementia symptoms reported in an online environment. This novel dementia staging algorithm can be used to describe dementia stage based on user-reported symptoms. This type of symptom recording offers real-world data that reflect important symptoms in people with dementia. Methods: We employed clinical data from 717 people from 3 sources: (1) a memory clinic; (2) long-term care; and (3) an open-label trial of donepezil in vascular and mixed dementia (VASPECT). Symptoms were captured with SymptomGuide Dementia. A clinician classified participants into 4 groups using either the Functional Assessment Staging Test or the Global Deterioration Scale as mild cognitive impairment, mild dementia, moderate dementia, or severe dementia. Individualized symptom profiles from the pooled data were used to train machine learning models to predict dementia severity. Models trained with 6 different machine learning algorithms were compared using nested cross-validation to identify the best performing model. Model performance was assessed using measures of balanced accuracy, precision, recall, Cohen kappa, area under the receiver operating characteristic curve (AUROC), and area under the precision-recall curve (AUPRC). The best performing algorithm was used to train a model optimized for balanced accuracy. Objective: We aimed to develop a supervised machine learning algorithm to classify dementia stages based on tracked symptoms. Results: The study population was mostly female (424/717, 59.1%), older adults (mean 77.3 years, SD 10.6, range 40-100) with mild to moderate dementia (332/717, 46.3%). Age, duration of symptoms, 37 unique dementia symptoms, and 10 symptom-derived variables were used to distinguish dementia stages. A model trained with a support vector machine learning algorithm using a one-versus-rest approach showed the best performance. The correct dementia stage was identified with 83% balanced accuracy (Cohen kappa=0.81, AUPRC 0.91, AUROC 0.96). The best performance was seen when classifying severe dementia (AUROC 0.99).', ""Early Diagnosis of Dementia from Clinical Data by Machine Learning Techniques Dementia is the most prevalent degenerative disease in seniors in which progression can be prevented or delayed by early diagnosis. In this study, we proposed a two-layer model inspired by the method used in dementia support centers for the early diagnosis of dementia and using machine learning techniques. Data were collected from patients who received dementia screening from 2008 to 2013 at the Gangbuk-Gu center for dementia in the Republic of Korea. The data consisted of the patient's gender, age, education, the Mini-Mental State Examination in the Korean version of the CERAD Assessment Packet (MMSE-KC) for dementia screening test, and the Korean version of the Consortium to Establish a Registry for Alzheimer's Disease (CERAD-K) for the dementia precise test. In the proposed model, MMSE-KC data are initially classified into normal and abnormal. In the second stage, CERAD-K data are used to classify dementia and mild cognitive impairment. The performance of each algorithm is compared with that of Naive Bayes, Bayes Network, Begging, Logistic Regression, Random Forest, Support Vector Machine (SVM) and Multilayer Perceptron (MLP) using Precision, Recall and F-measure. Comparing the F-measure values of normal, mild cognitive impairment (MCI), and dementia, the MLP was the highest in the F-measure values of normal with 0.97, while the SVM appear to be the highest in MCI and dementia with 0.739. Using the proposed early diagnosis model for dementia reduces the time and economic burden and can help simplify the diagnosis method for dementia.""]"
97,152,97_addictions_addiction_addictive_adolescents,"['addictions', 'addiction', 'addictive', 'adolescents', 'adolescent', 'youth', 'internet', 'users', 'abuse', 'students']","[""Prevalence of Internet Addiction and associated risk factors in Jordanian school students Internet Addiction has become a public health issue that cannot be neglected. In Jordan, there is a need to investigate this issue among school students. This descriptive correlational study aimed to assess the prevalence of Internet Addition and associated risk factors in Jordanian school students. The participants (N = 716) aged 12-18 years were selected randomly from ten public schools in Amman Governorate in Jordan. Socio-demographical data, patterns of Internet usage, the Young's Internet Addiction Tool (YIAT), the Symptom Checklist-anxiety scale (SCL-anxiety), and the Center for Epidemiological Studies Depression Scale for Children (CES-DC) were used. The findings showed that the prevalence of severe Internet Addiction was 6.3%. The highest prevalence of Internet Addiction was among students with family monthly income &gt;1400$/, their fathers completed elementary education and mothers completed university and higher education, and their academic performance was poor. The friend's home was the favorite place among Internet addicted students. Chatting was the highest reason for Internet Addiction. The students were experiencing anxiety and depression symptoms had the highest prevalence of Internet Addiction (10.3%, 8.2%, respectively). There was a statistically significant relationship between the age, school grade, family income, academic performance, average hours of Internet daily usage during school days and holidays, anxiety, depression, and Internet Addiction. These findings emphasize the importance of developing and implementing interventions such as preventive measures and early diagnosis of Internet Addiction among school students. Furthermore, counseling programs are recommended to increase the awareness of families regarding Internet Addiction and their responsibilities in providing guidance and support for their children. (C) 2017 Elsevier Ltd. All rights reserved."", 'Internet addiction and psychiatric symptoms among Korean adolescents BACKGROUND: The aims of this study were to identify the independent factors associated with intermittent addiction and addiction to the Internet and to examine the psychiatric symptoms in Korean adolescents when the demographic and Internet-related factors were controlled. CONCLUSIONS: Staff working in junior or senior high schools should pay closer attention to those students who have the risk factors for intermittent addiction and addiction to the Internet. Early preventive intervention programs are needed that consider the individual severity level of Internet addiction. METHODS: Male and female students (N = 912) in the 7th-12th grades were recruited from 2 junior high schools and 2 academic senior high schools located in Seoul, South Korea. Data were collected from November to December 2004 using the Internet-Related Addiction Scale and the Symptom Checklist-90-Revision. A total of 851 subjects were analyzed after excluding the subjects who provided incomplete data. RESULTS: Approximately 30% (n = 258) and 4.3% (n = 37) of subjects showed intermittent Internet addiction and Internet addiction, respectively. Multivariate logistic regression analysis showed that junior high school students and students having a longer period of Internet use were significantly associated with intermittent addiction. In addition, male gender, chatting, and longer Internet use per day were significantly associated with Internet addiction. When the demographic and Internet-related factors were controlled, obsessive-compulsive and depressive symptoms were found to be independently associated factors for intermittent addiction and addiction to the Internet, respectively.', 'AN ANALYSIS OF INTERNET ADDICTION LEVELS OF INDIVIDUALS ACCORDING TO VARIOUS VARIABLES The concept of internet addiction refers to the excessive use of internet which in turn causes various problems in individual, social and professional aspects. The aim of this study was to determine internet addiction levels of internet users from all age groups. The study used survey model. Study group of the study consisted of a total of 596 people from all age groups. """"Personal Information Form"""" and """"Internet Addiction Scale"""" were used for data collection. Arithmetic mean, standard deviation, independent sampling and t test, ANOVA and LSD tests were performed on collected data. The findings of the study revealed that the individuals had low levels of internet addiction both in sub-scales and in the general of the scale according to age groups. It was found that there was a significant difference between internet addiction scores of the individuals who belonged to the age group of 19 and below and 30 and below. There was a significant difference between the internet addiction scores of students and other professional groups. It was found that internet addiction levels of males were higher than those of females. The results of the study were discussed together with the results of different studies and suggestions were made.']"
98,151,98_mixture_mixing_mixtures_estimators,"['mixture', 'mixing', 'mixtures', 'estimators', 'probabilities', 'algorithm', 'convergence', 'likelihood', 'probabilistic', 'approximation']","['EM algorithm with split and merge operations for mixture models The maximum likelihood estimate of a mixture model is usually found by using the EM algorithm. However, the EM algorithm suffers from a local optima problem and therefore we cannot obtain the potential performance of mixture models in practice. In the case of mixture models, local maxima often have too many components of a mixture model in one part of the space and too few in another, widely separated part of the space. To escape from such configurations we proposed a new variant of the Ehl algorithm in which simultaneous split and merge operations are repeatedly performed by using a new criterion for efficiently selecting the split and merge candidates. We apply the proposed algorithm to the training of Gaussian mixtures and the dimensionality reduction based on a mixture of factor analyzers using synthetic and real data and show that the proposed algorithm can markedly improve the ML estimates.', 'On EM Estimation for Mixture of Multivariate t-Distributions This paper formulates a novel expectation maximization (EM) algorithm for the mixture of multivariate t-distributions. By introducing a new kind of """"missing"""" data, we show that the empirically improved iterative algorithm, in literature, for the mixture of multivariate t-distributions is in fact a type of EM algorithm; thus a theoretical analysis is established, which guarantees the empirical algorithm converges to the maximization likelihood estimates of the mixture parameters. Simulated experiment and real experiments on classification and image segmentation confirm the effectiveness of the improved EM algorithm.', 'A greedy EM algorithm for Gaussian mixture learning Learning a Gaussian mixture with a local algorithm like EM can be difficult because (i) the true number of mixing components is usually unknown, (ii) there is no generally accepted method for parameter initialization, and (iii) the algorithm can get trapped in one of the many local maxima of the likelihood function. In this paper we propose a greedy algorithm for learning a Gaussian mixture which tries to overcome these limitations. In particular, starting with a single component and adding components sequentially until a maximum number k, the algorithm is capable of achieving solutions superior to EM with k components in terms of the likelihood of a test set. The algorithm is based on recent theoretical results on incremental mixture density estimation, and uses a combination of global and local search each time a new component is added to the mixture.']"
99,150,99_robotic_controllers_manipulator_controller,"['robotic', 'controllers', 'manipulator', 'controller', 'manipulators', 'adaptive', 'robot', 'robots', 'autonomous', 'control']","['Indirect adaptive tracking control of a nonholonomic mobile robot via neural networks This paper presents the design and implementation of a novel adaptive trajectory tracking controller for a nonholonomic wheeled mobile robot (WMR) with unknown parameters and uncertain dynamics. The learning ability of neural networks is used to design a robust adaptive backstepping controller that does not require the knowledge of the robot dynamics. The kinematic controller gains are tuned on-line to minimize the velocity error and improve the trajectory tracking characteristics. The performance of the proposed control algorithm is verified and compared with the classical backstepping controller through simulation and experiments on a commercial mobile robot platform. (C) 2012 Elsevier B.V. All rights reserved.', 'Adaptive neural control for mobile manipulator systems based on adaptive state observer This study processes the adaptive robust control problem in a task space for a mobile manipulator with uncertain dynamics and external disturbances based on radial basis function neural networks(RBFNN) and a nonlinear state observer. Owing to the high nonlinearity, strong coupling, and unknown uncertainty characteristics of the mobile manipulators, their control poses a considerable challenge. An adaptive robust control strategy for nonlinear mobile robot systems with unknown uncertainties and disturbances based on the RBFNN and state observer is proposed in the operating space. First, a feedforward-feedback virtual speed generator is developed based on the feedforward control and backstepping method to implement virtual speed tracking control in the operation space to make the positional error asymptotically stable. Then, a model-independent RBFNN based adaptive robust controller (ARBFNNC) with the state observer is proposed, which converts the virtual speed input into the control torque of the actual mobile manipulator to achieve precise position tracking in the task space, and theoretical analysis performed through Lyapunov stability theory shows the global asymptotic stability of a system under the control of the proposed method. Finally, simulation results confirm the effectiveness of the proposed control method in position regulation and tracking control of the nonlinear mobile manipulator.', 'Design of an intelligent optimal neural network-based tracking controller for nonholonomic mobile robot systems This paper addresses the trajectory-tracking control problem of mobile robot systems with nonholonomic constraints, in the presence of time-varying parametric uncertainties and external disturbances. This necessitates an accurate controller to meet as much control objectives, as possible. Therefore, this paper deals with an artificial intelligence control technique to design a robust controller to meet the control objectives. The design of the intelligent controller is based on the optimal control theory, the adaptive neural network system, and the robust control technique. The trajectory-tracking problem is solved using the optimal control methodology. Since the nonholonomic wheeled mobile robot is strongly nonlinear, the neural network system is applied to approximate the nonlinear function in the optimal control law. The robust controller, for his part, is then applied to adaptively estimate an unknown upper bound of the time-varying parametric uncertainties, external disturbances and approximation error of the neural network system. The stability of the closed-loop robot system is proven using the optimal control theory and Lyapunov stability analysis. The results of the simulation studies on three typical nonholonomic mobile robots are provided to demonstrate the effectiveness of the proposed controller. In addition, a comparative study with a recent robust adaptive controller shows that our proposed intelligent controller gives better results, in the sense that the output trajectory converges to the steady state faster with smaller tracking error.']"
100,149,100_categorization_classification_categories_clustering,"['categorization', 'classification', 'categories', 'clustering', 'semantic', 'datasets', 'collection', 'dataset', 'context', 'hierarchical']","['A joint extraction model of entities and relations based on relation decomposition Extracting entities and relations from unstructured text is an essential task in the field of information extraction. Existing work mainly pipeline extraction and joint decoding methods. However, these methods are unable to extract overlapping entities and relations, and ignore the task correlation between entity and relation extraction. In this paper, we first introduce the BERT pre-training model to model the text more finely. Then, we decompose the extraction into relation extraction and entity recognition. Relation extraction is transformed into a relation classification task. Entity recognition is transformed into a sequence labeling task. The recognition entity includes a head entity and a tail entity. We evaluate the model on the New York Times (NYT) and WebNLG datasets. Compared with most existing models, excellent results have been obtained. Experimental results show that our model can fully capture the semantic interdependence between the two tasks of entity and relation extraction, reduce the interference of unrelated entity pairs, and effectively solve the problem of entity overlap.', 'Corpus-based topic diffusion for short text clustering In this paper, we propose a novel corpus-based enrichment approach for short text clustering. Since sparseness brings about the problem of insufficient word co-occurrence and lack of context information, previous researches use external sources such as Wikipedia or WordNet to enrich the representation of short text documents, which requires extra resources and might lead to possible inconsistency. On the other hand, corpus-based approaches use no external information in mining short text data. By introducing a set of conjugate definitions to characterize the structures of topics and words, and by proposing a virtual generative procedure for short texts, we perform expansion on short text data. Specifically, new words which may not appear in a short text document were added with a virtual term frequency, and this virtual frequency is obtained from the posterior probabilities of new words given all the words in that document. The complete procedure can be regarded as mapping data points (documents) from the original feature space to a hidden semantic space (topic space). After performing semantic smoothing, data points are then mapped back to the original space. We conduct experiments on two short text datasets, and the results show that the proposed method can effectively address the sparseness problem. For these datasets, our method, using only a basic clustering algorithm, attains a comparable performance with methods based on enrichment with external information sources. (C) 2017 Elsevier B.V. All rights reserved.', 'HSAN-capsule: A novel text classification model Most text classification methods fail to fully consider the important role of the hierarchical structure of the text in determining the text category, and cannot well extract enough text sequence information. To address this problem, a novel model based on hierarchical self-attention mechanism capsule network was proposed for text classification, which was composed of two components, i.e., the hierarchical self-attention network and capsule network. First input the text data processed by word embedding into the hierarchical self-attention network for feature extraction, model the text from the two levels of words and sentences to extract the hierarchical features of the text; then the results are passed into the capsule network in order to refine the relationship between the part of the text and the whole, and further extract richer text semantic information. The experimental results on 5 text classification datasets show that compared with other baseline models, the model in this paper has achieved better classification results.(c) 2022 Elsevier B.V. All rights reserved.']"
101,147,101_virtual_mindfulness_psychosis_psychiatric,"['virtual', 'mindfulness', 'psychosis', 'psychiatric', 'mental', 'psychological', 'anxiety', 'schizophrenia', 'depression', 'phobias']","['Using Virtual Reality Exposure Therapy to Enhance Treatment of Anxiety Disorders: Identifying Areas of Clinical Adoption and Potential Obstacles Despite strong evidence of effectiveness, exposure therapy is an underutilized treatment for anxiety disorders at a time when effective treatment for anxiety is greatly needed. The significant worldwide prevalence and negative impact of anxiety are documented and highlight the importance of increasing therapist and patient use of effective treatment. Obstacles to the use of exposure therapy are explored and steps to lessen these obstacles are proposed. In particular, virtual reality (VR) technology is discussed as a way to increase the availability of exposure therapy. Incorporating VR in therapy can increase the ease, acceptability, and effectiveness of treatment for anxiety. VR exposure therapy (VRET) permits individualized, gradual, controlled, immersive exposure that is easy for therapists to implement and often more acceptable to patients than in vivo or imaginal exposure. VR is presented as a scalable tool that can augment access to and effectiveness of exposure therapy thus improving treatment of anxiety disorders. VR also has the potential to help with assessment and with therapist training standardization. The authors advocate for providing continuing education in VRET to practicing clinicians and including training in exposure therapy and VRET in training programs. Ongoing development of VR applications for clinical use is encouraged, especially when developed in collaboration with software developers, clinical users, therapists who are experienced in VRET, and researchers.', 'Virtual Reality for Anxiety Reduction Demonstrated by Quantitative EEG: A Pilot Study While previous research has established that virtual reality (VR) can be successfully used in the treatment of anxiety disorders, including phobias and PTSD, no research has examined changes in brain patterns associated with the use of VR for generalized anxiety management. In the current study, we compared a brief nature-based mindfulness VR experience to a resting control condition on anxious participants. Self-reported anxiety symptoms and resting-state EEG were recorded across intervals containing quiet rest or the VR intervention. EEG activity was analyzed as a function of global power shifts in Alpha and Beta activity, and with sLORETA current source density estimates of cingulate cortex regions of interest. Results demonstrated that both a quiet rest control condition and the VR meditation significantly reduced subjective reports of anxiety and increased Alpha power. However, the VR intervention uniquely resulted in shifting proportional power from higher Beta frequencies into lower Beta frequencies, and significantly reduced broadband Beta activity in the anterior cingulate cortex. These effects are consistent with a physiological reduction of anxiety. This pilot study provides preliminary evidence supporting the therapeutic potential of VR for anxiety management and stress reduction programs.', 'A Literature Overview of Virtual Reality (VR) in Treatment of Psychiatric Disorders: Recent Advances and Limitations In this paper, we conduct a literature survey on various virtual reality (VR) treatments in psychiatry. We collected 36 studies that used VR to provide clinical trials or therapies for patients with psychiatric disorders. In order to gain a better understanding of the management of pain and stress, we first investigate VR applications for patients to alleviate pain and stress during immersive activities in a virtual environment. VR exposure therapies are particularly effective for anxiety, provoking realistic reactions to feared stimuli. On top of that, exposure therapies with simulated images are beneficial for patients with psychiatric disorders such as phobia and posttraumatic stress disorder (PTSD). Moreover, VR environments have shown the possibility of changing depression, cognition, even social functions. We review empirical evidence from VR-based treatments on psychiatric illnesses such as dementia, mild cognitive impairment (MCI), schizophrenia and autism. Through cognitive training and social skill training, rehabilitation through VR therapies helps patients to improve their quality of life. Recent advances in VR technology also demonstrate potential abilities to address cognitive and functional impairments in dementia. In terms of the different types of VR systems, we discuss the feasibility of the technology within different stages of dementia as well as the methodological limitations. Although there is room for improvement, its widespread adoption in psychiatry is yet to occur due to technical drawbacks such as motion sickness and dry eyes, as well as user issues such as preoccupation and addiction. However, it is worth mentioning that VR systems relatively easily deliver virtual environments with well-controlled sensory stimuli. In the future, VR systems may become an innovative clinical tool for patients with specific psychiatric symptoms.']"
102,146,102_shape_shapes_geometry_geometric,"['shape', 'shapes', 'geometry', 'geometric', 'dimensional', 'contours', 'contour', 'layout', 'map', 'template']","['Anatomical landmark detection on 3D human shapes by hierarchically utilizing multiple shape features The availability of 3D human body shapes enables applications such as digital anthropometry by exploiting the geometric information of 3D shapes. In this paper, we propose a method for detecting anatomical landmarks on 3D human shapes by hierarchically utilizing multiple shape features. The backbone of our method is to compute dense correspondences between a pair of template and target shape, and the detection is achieved by transferring the annotated landmarks of the template shape to the target shape. We also investigate several techniques to further enhance the detecting accuracy, such as template selection, fine search and late fusion. Multiple kinds of shape features are used in different parts of our method, and each of them contributes to the improvement of detection accuracy. In experiments, we validate the effectiveness of each part in the proposed method. And our method also demonstrates the state-of-the-art performance in terms of the average detection accuracy. (C) 2017 Elsevier B.V. All rights reserved.', 'Shape space estimation by higher-rank of SOM The aim of this study is to develop an estimation method for a shape space. In this work, """"shape space"""" means a nonlinear subspace formed by a class of visual shapes, in which the continuous change in shapes is naturally represented. By using the shape space, various operations dealing with shapes, such as identification, classification, recognition, and interpolation can be carried out in the shape space. This paper introduces an algorithm based on a generative model of shapes. A higher-rank of the self-organizing map (SOM2) is used to implement the shape space estimation method. We use this method to estimate the shape space of artificial contours. In addition, we present results from a simulation of omnidirectional camera images taken from mobile robots. Our technique accurately predicts changes in image properties as the robot\'s attitude changes. Finally, we consider the addition of local features to our method. We show that the inclusion of local features solves the correspondence problem. These results suggest the potential of our technique in the future.', ""Shape encoding: A biologically inspired method of transforming boundary images into ensembles of shape-related features A biologically inspired method to encode the shape of enclosed image regions is presented, Shape encoding units, called ''shape cells,'' are algebraic filters which receive two-dimensional (2-D) reconstructed image boundaries as input features. Shape cell outputs are calculated as three components, First, a compact description of an image boundary shape surrounding a particular shape cell is obtained in the form of a shape cell centered radial scanning vector, Shape cell activations are then calculated from radial scans, and finally, different shape cells that encode parts of the same shape must be grouped together in ensembles, This process is called feature binding, A process of iterative lateral inhibition is employed to condense the set of active shape cells before feature binding takes place, The output radial scanning vectors of shape cells provide compact descriptions of shape which are useful in object identification, The spatial pattern (2-D coordinates) of active shape cells can be used in object localization, With feature binding separate ensembles are created, even if neighboring shapes are only divided by weak boundaries, Besides its application in pattern recognition, shape encoding provides a possible mechanism of figure-ground separation, Artificial shape encoding is further concluded to be a suitable addendum to the existing collective model of biological vision.""]"
103,145,103_spike_spikes_neural_neuronal,"['spike', 'spikes', 'neural', 'neuronal', 'experimental', 'neuron', 'neurons', 'processing', 'stimulus', 'simulated']","['The Spike Response Model: A framework to predict neuronal spike trains We propose a simple method to map a generic threshold model, namely the Spike Response Model, to artificial data of neuronal activity using a minimal amount of a priori information. Here, data are generated by a detailed mathematical model of neuronal activity. The model neuron is driven with in-vivo-like current injected, and we test to which extent it is possible to predict the spike train of the detailed neuron model from that of the Spike Response Model. In particular, we look at the number of spikes correctly predicted within a biologically relevant time window. We find that the Spike Response Model achieves prediction of up to 80% of the spikes with correct timing (+/-2ms). Other characteristics of activity, such as mean rate and coefficient of variation of spike trains, are predicted in the correct range as well.', 'A data-driven spike sorting feature map for resolving spike overlap in the feature space Objective. Spike sorting is the process of extracting neuronal action potentials, or spikes, from an extracellular brain recording, and assigning each spike to its putative source neuron. Spike sorting is usually treated as a clustering problem. However, this clustering process is known to be affected by overlapping spikes. Existing methods for resolving spike overlap typically require an expensive post-processing of the clustering results. In this paper, we propose the design of a domain-specific feature map, which enables the resolution of spike overlap directly in the feature space. Approach. The proposed domain-specific feature map is based on a neural network architecture that is trained to simultaneously perform spike sorting and spike overlap resolution. Overlapping spikes clusters can be identified in the feature space through a linear relation with the single-neuron clusters for which the neurons contribute to the overlapping spikes. To aid the feature map training, a data augmentation procedure is presented that is based on biophysical simulations. Main results. We demonstrate the potential of our method on independent and realistic test data. We show that our novel approach for resolving spike overlap generalizes to unseen and realistic test data. Furthermore, the sorting performance of our method is shown to be similar to the state-of-the-art, but our method does not assume the availability of spike templates for resolving spike overlap. Significance. Resolving spike overlap directly in the feature space, results in an overall simplified spike sorting pipeline compared to the state-of-the-art. For the state-of-the-art, the overlapping spike snippets exhibit a large spread in the feature space and do not appear as concentrated clusters. This can lead to biased spike template estimates which affect the sorting performance of the state-of-the-art. In our proposed approach, overlapping spikes form concentrated clusters and spike overlap resolution does not depend on the availability of spike templates.', 'A Supervised Learning Algorithm for Spiking Neurons Using Spike Train Kernel Based on a Unit of Pair-Spike In recent years, neuroscientists have discovered that the neural information is encoded by spike trains with precise times. Supervised learning algorithm based on the precise times for spiking neurons becomes an important research field. Although many existing algorithms have the excellent learning ability, most of their mechanisms still have some complex computations and certain limitations. Moreover, the discontinuity of spiking process also makes it very difficult to build an efficient algorithm. This paper proposes a supervised learning algorithm for spiking neurons using the kernel function of spike trains based on a unit of pair-spike. Firstly, we comprehensively divide the intervals of spike trains. Then, we construct an optimal selection and computation method of spikes based on the unit of pair-spike. This method avoids some wrong computations and reduces the computational cost by using each effective input spike only once in every epoch. Finally, we use the kernel function defined by an inner product operator to solve the computing problem of discontinue spike process and multiple output spikes. The proposed algorithm is successfully applied to many learning tasks of spike trains, where the effect of our optimal selection and computation method is verified and the influence of learning factors such as learning kernel, learning rate, and learning epoch is analyzed. Moreover, compared with other algorithms, all experimental results show that our proposed algorithm has the higher learning accuracy and good learning efficiency.']"
104,143,104_volatility_markets_forecasting_stocks,"['volatility', 'markets', 'forecasting', 'stocks', 'market', 'predictions', 'stock', 'investors', 'predicting', 'forecast']","['Fusion ANFIS models based on multi-stock volatility causality for TAIEX forecasting Stock market investors value accurate forecasting of future stock price from trading systems because of the potential for large profits. Thus, investors use different forecasting models, such as the time-series model, to assemble a superior investment portfolio. Unfortunately, there are three major drawbacks to the time-series model: (1) most statistical methods rely on some assumptions about the variables; (2) most conventional time-series models use only one variable in forecasting; and (3) the rules mined from artificial neural networks are not easily understandable. To address these shortcomings, this study proposes a new model based on multi-stock volatility causality, a fusion adaptive-network-based fuzzy inference system (ANFIS) procedure, for forecasting stock price problems in Taiwan. Furthermore, to illustrate the proposed model, three practical, collected stock index datasets from the USA and Taiwan stock markets are used in the empirical experiment. The experimental results indicate that the proposed model is superior to the listing methods in terms of root mean squared error, and further evaluation reveals that the profits comparison results for the proposed model produce higher profits than the listing models. (C) 2009 Elsevier B.V. All rights reserved.', ""DESIGN OF EXPERIMENTS ON NEURAL NETWORK'S PARAMETERS OPTIMIZATION FOR TIME SERIES FORECASTING IN STOCK MARKETS Artificial neural network (ANN) model has been used for years to conduct research in stock price prediction for three reasons. First, it has a higher prediction accuracy rate in empirical research. Second, it is not subject to the assumption of having samples from a normal distribution. Third, it can deal with non-linear problems. Nevertheless, the accuracy of prediction relies on the parameter settings of neural network as well as the complexities of problems and the neural network architecture; the results of the analysis could be even more significant with the selection of optimal parameters and network architecture. Currently, as a way of setting parameters, most researchers employed the trial and error method. However, this method is very time-consuming and labor-intensive and may not result in the optimal parameters. Therefore, this research took advantage of a back propagation neural network (BPNN) for the purpose of parameter optimization through constructing a model of stock price prediction, applying design of experiment (DOE) to systematize experiment scheduling,, and methods of main effects analysis and interaction analysis. The research used two datasets of financial ratios from 50 blue chip companies in Taiwanese stock market and 40 listed American banks in New York stock exchange as experimental samples. Research results showed that the correlation forecasting, root mean squared error (RMSE), and computing time, which can effectively increase the accuracy of stock price prediction, are better than traditional statistical methods and conventional neural network model."", 'Enhancing quantitative intra-day stock return prediction by integrating both market news and stock prices information The interaction between stock price process and market news has been widely analyzed by investors on different markets. Previous works, however, focus either on market news purely as exogenous factors that tend to lead price process or on the analysis of how past stock price process can affect future stock returns. To take a step forward, we quantitatively integrate information from both market news and stock prices in order to improve the accuracy of prediction on stock future price return in an intra-day trading context. In this paper, we present the design and architecture of our approach for market information fusion. By means of multiple kernel learning, the hidden information behind the two sources is effectively extracted, and more importantly, seamlessly integrated rather than simply combined by a single kernel approach. Experiments on comprehensive comparisons between our approach and three baseline methods (which use only one type of information, or naively combine the two sources) have been conducted on the intra-day tick-by-tick data of the Hong Kong Stock Exchange and market news archives of the same period. It has been shown that for both cross-validation and independent testing, our approach is able to achieve the best results. (C) 2014 Elsevier B.V. All rights reserved.']"
105,143,105_robotics_robotic_robots_robot,"['robotics', 'robotic', 'robots', 'robot', 'manipulators', 'manipulator', 'manipulation', 'humanoid', 'controllers', 'autonomous']","['Human-Inspired Eigenmovement Concept Provides Coupling-Free Sensorimotor Control in Humanoid Robot Control of a multi-body system in both robots and humans may face the problem of destabilizing dynamic coupling effects arising between linked body segments. The state of the art solutions in robotics are full state feedback controllers. For human hip-ankle coordination, a more parsimonious and theoretically stable alternative to the robotics solution has been suggested in terms of the Eigenmovement (EM) control. Eigenmovements are kinematic synergies designed to describe the multi DoF system, and its control, with a set of independent, and hence coupling-free, scalar equations. This paper investigates whether the EM alternative shows """"real-world robustness"""" against noisy and inaccurate sensors, mechanical non-linearities such as dead zones, and human-like feedback time delays when controlling hip-ankle movements of a balancing humanoid robot. The EM concept and the EM controller are introduced, the robot\'s dynamics are identified using a biomechanical approach, and robot tests are performed in a human posture control laboratory. The tests show that the EM controller provides stable control of the robot with proactive (""""voluntary"""") movements and reactive balancing of stance during support surface tilts and translations. Although a preliminary robot-human comparison reveals similarities and differences, we conclude (i) the Eigenmovement concept is a valid candidate when different concepts of human sensorimotor control are considered, and (ii) that human-inspired robot experiments may help to decide in future the choice among the candidates and to improve the design of humanoid robots and robotic rehabilitation devices.', ""Use of human gestures for controlling a mobile robot via adaptive CMAC network and fuzzy logic controller Mobile robots with manipulators have been more and more commonly applied in extreme and hostile environments to assist or even replace human operators for complex tasks. In addition to autonomous abilities, mobile robots need to facilitate the human-robot interaction control mode that enables human users to easily control or collaborate with robots. This paper proposes a system which uses human gestures to control an autonomous mobile robot integrating a manipulator and a video surveillance platform. A human user can control the mobile robot just as one drives an actual vehicle in the vehicle's driving cab. The proposed system obtains human's skeleton joints information using a motion sensing input device, which is then recognized and interpreted into a set of control commands. This is implemented, based on the availability of training data set and requirement of in-time performance, by an adaptive cerebellar model articulation controller neural network, a finite state machine, a fuzzy controller and purposely designed gesture recognition and control command generation systems. These algorithms work together implement the steering and velocity control of the mobile robot in real-time. The experimental results demonstrate that the proposed approach is able to conveniently control a mobile robot using virtual driving method, with smooth manoeuvring trajectories in various speeds. (C) 2017 Elsevier B.V. All rights reserved."", 'A Human-like Upper-limb Motion Planner: Generating naturalistic movements for humanoid robots As robots are starting to become part of our daily lives, they must be able to cooperate in a natural and efficient manner with humans to be socially accepted. Human-like morphology and motion are often considered key features for intuitive human-robot interactions because they allow human peers to easily predict the final intention of a robotic movement. Here, we present a novel motion planning algorithm, the Human-like Upper-limb Motion Planner, for the upper limb of anthropomorphic robots, that generates collision-free trajectories with human-like characteristics. Mainly inspired from established theories of human motor control, the planning process takes into account a task-dependent hierarchy of spatial and postural constraints modelled as cost functions. For experimental validation, we generate arm-hand trajectories in a series of tasks including simple point-to-point reaching movements and sequential object-manipulation paradigms. Being a major contribution to the current literature, specific focus is on the kinematics of naturalistic arm movements during the avoidance of obstacles. To evaluate human-likeness, we observe kinematic regularities and adopt smoothness measures that are applied in human motor control studies to distinguish between well-coordinated and impaired movements. The results of this study show that the proposed algorithm is capable of planning arm-hand movements with human-like kinematic features at a computational cost that allows fluent and efficient human-robot interactions.']"
106,142,106_pet_imaging_tomography_scans,"['pet', 'imaging', 'tomography', 'scans', 'scanners', 'scanner', 'scan', 'mri', 'positron', 'ct']","[""Direct Reconstruction of Linear Parametric Images From Dynamic PET Using Nonlocal Deep Image Prior Direct reconstruction methods have been developed to estimate parametric images directly from the measured PET sinograms by combining the PET imaging model and tracer kinetics in an integrated framework. Due to limited counts received, signal-to-noise-ratio (SNR) and resolution of parametric images produced by direct reconstruction frameworks are still limited. Recently supervised deep learning methods have been successfully applied to medical imaging denoising/reconstruction when large number of high-quality training labels are available. For static PET imaging, high-quality training labels can be acquired by extending the scanning time. However, this is not feasible for dynamic PET imaging, where the scanning time is already long enough. In this work, we proposed an unsupervised deep learning framework for direct parametric reconstruction from dynamic PET, which was tested on the Patlak model and the relative equilibrium Logan model. The training objective function was based on the PET statistical model. The patient's anatomical prior image, which is readily available from PET/CT or PET/MR scans, was supplied as the network input to provide a manifold constraint, and also utilized to construct a kernel layer to perform non-local feature denoising. The linear kinetic model was embedded in the network structure as a 1 x 1 x 1 convolution layer. Evaluations based on dynamic datasets of F-18-FDG and C-11-PiB tracers show that the proposed framework can outperform the traditional and the kernel method-based direct reconstruction methods."", 'Anatomically aided PET image reconstruction using deep neural networks Purpose The developments of PET/CT and PET/MR scanners provide opportunities for improving PET image quality by using anatomical information. In this paper, we propose a novel co-learning three-dimensional (3D) convolutional neural network (CNN) to extract modality-specific features from PET/CT image pairs and integrate complementary features into an iterative reconstruction framework to improve PET image reconstruction. Methods We used a pretrained deep neural network to represent PET images. The network was trained using low-count PET and CT image pairs as inputs and high-count PET images as labels. This network was then incorporated into a constrained maximum likelihood framework to regularize PET image reconstruction. Two different network structures were investigated for the integration of anatomical information from CT images. One was a multichannel CNN, which treated PET and CT volumes as separate channels of the input. The other one was multibranch CNN, which implemented separate encoders for PET and CT images to extract latent features and fed the combined latent features into a decoder. Using computer-based Monte Carlo simulations and two real patient datasets, the proposed method has been compared with existing methods, including the maximum likelihood expectation maximization (MLEM) reconstruction, a kernel-based reconstruction and a CNN-based deep penalty method with and without anatomical guidance. Results Reconstructed images showed that the proposed constrained ML reconstruction approach produced higher quality images than the competing methods. The tumors in the lung region have higher contrast in the proposed constrained ML reconstruction than in the CNN-based deep penalty reconstruction. The image quality was further improved by incorporating the anatomical information. Moreover, the liver standard deviation was lower in the proposed approach than all the competing methods at a matched lesion contrast. Conclusions The supervised co-learning strategy can improve the performance of constrained maximum likelihood reconstruction. Compared with existing techniques, the proposed method produced a better lesion contrast versus background standard deviation trade-off curve, which can potentially improve lesion detection.', 'Eliminating CT radiation for clinical PET examination using deep learning Clinical PET/CT examinations rely on CT modality for anatomical localization and attenuation correction of the PET data. However, the use of CT significantly increases the risk of ionizing radiation exposure for patients. We propose a deep learning framework to learn the relationship mapping between attenuation corrected (AC) PET and non-attenuation corrected (NAC) PET images to estimate PET attenuation maps and generate pseudo-CT images for medical observation. In this study, 5760, 1608 and 1351 pairs of transverse PET-CT slices were used as the training, validation, and testing sets, respectively, to implement the proposed framework. A pix2pix model was adopted to predict AC PET images from NAC PET images, which allowed the calculation of PET attenuation maps (mu-maps). The same model was then applied to generate realistic CT images from the calculated mu-maps. The quality of predicted AC PET and CT was assessed using normalized root mean square error (NRMSE), peak signal-to-noise ratio (PSNR), structural similarity index (SSIM) and Pearson correlation coefficient (PCC). Relative to true AC PET, the synthetic AC PET achieved superior quantitative performances with 2.20 +/- 1.17% NRMSE, 34.03 +/- 4.73 dB PSNR, 97.90 +/- 1.22% SSIM and 98.45 +/- 1.31% PCC. The synthetic CT and synthetic AC PET images were deemed acceptable by radiologists who rated the images, as they provided sufficient anatomical and functional information, respectively. This work demonstrates that the proposed deep learning framework is a promising method in clinical applications, such as radiotherapy and low-dose imaging.']"
107,141,107_sentiments_sentiment_emotions_affective,"['sentiments', 'sentiment', 'emotions', 'affective', 'reviews', 'classification', 'analysis', 'semantic', 'relations', 'words']","[""Image sentiment classification via multi-level sentiment region correlation analysis Human's understanding of image content is a multi-level and multi-stage process. For visual sentiment analysis, this process can be specified as the gradual perception from semantic to emotion of regions in an image. The mining of emotion-related regions is valuable for sentiment recognition, and it is even more important to further investigate the semantic associations formed between these regions. In this paper, we propose a novel multi-level sentiment region correlation analysis model, which exploits the regions in an image that are most potentially affected by emotions from multiple perspectives and motivates the interaction between sentiment regions. It makes the visual content of multi-level sentiment regions and the implicit correlations within them robust cues for image sentiment recognition. We innovatively propose a module of correlation analysis of multi-level sentiment regions to exploit the effects of higher-order and rich interactions on emotions with encoders of the Transformer. Experiments on a variety of public visual sentiment analysis datasets at different scales show that the proposed MSRCA model achieve excellent performance in image sentiment classification and outperforms other existing methods. (c) 2021 Elsevier B.V. All rights reserved."", 'BiLSTM with Multi-Polarity Orthogonal Attention for Implicit Sentiment Analysis Sentiment analysis has been a popular field in natural language processing. Sentiments can be expressed explicitly or implicitly. Most current studies on sentiment analysis focus on the identification of explicit sentiments. However, implicit sentiment analysis has become one of the most difficult tasks in sentiment analysis due to the absence of explicit sentiment words. In this article, we propose a BiLSTM model with multi-polarity orthogonal attention for implicit sentiment analysis. Compared to the traditional single attention model, the difference between the words and the sentiment orientation can be identified by using multi-polarity attention. This difference can be regarded as a significant feature for implicit sentiment analysis. Moreover, an orthogonal restriction mechanism is adopted to ensure that the discriminatory performance can be maintained during optimization. The experimental results on the SMP2019 implicit sentiment analysis dataset and two explicit sentiment analysis datasets demonstrate that our model more accurately captures the characteristic differences among sentiment polarities. (C) 2019 Elsevier B.V. All rights reserved.', 'Knowledge-enhanced neural networks for sentiment analysis of Chinese reviews Sentiment analysis aims to extract structured opinions from unstructured reviews and determine their sentiment polarities. However, existing sentiment analysis systems fail to identify aspect-opinion pairs and perform poorly on small training corpora. To address these issues, we propose a novel framework to model aspect-opinion pair identification and aspect-level sentiment classification as a joint text classification task. Moreover, we incorporate external knowledge into neural networks to compensate for the lack of training data. In our approach, context features extracted from review sentences and external knowledge retrieved from a sentiment knowledge graph are used to identify aspect-opinion pairs and determine their sentiment polarities. In this way, our model is able to provide more detailed sentiment analysis results and achieve better performance with limited training corpora. We evaluate our approach using a Chinese car review dataset. Experimental results show that the knowledge-enhanced neural networks consistently outperform the conventional models. (C) 2019 Elsevier B.V. All rights reserved.']"
108,141,108_motions_arm_movements_kinematic,"['motions', 'arm', 'movements', 'kinematic', 'arms', 'torque', 'forearm', 'biomechanical', 'motion', 'kinematics']","['Cortical Spiking Network Interfaced with Virtual Musculoskeletal Arm and Robotic Arm Embedding computational models in the physical world is a critical step towards constraining their behavior and building practical applications. Here we aim to drive a realistic musculoskeletal arm model using a biomimetic cortical spiking model, and make a robot arm reproduce the same trajectories in real time. Our cortical model consisted of a 3 -layered cortex, composed of several hundred spiking model -neurons, which display physiologically realistic dynamics. We interconnected the cortical model to a two -joint musculoskeletal model of a human arm, with realistic anatomical and biomechanical properties. The virtual arm received muscle excitations from the neuronal model, and fed back proprioceptive information, forming a closed -loop system. The cortical model was trained using spike timing -dependent reinforcement learning to drive the virtual arm in a 2D reaching task. Limb position was used to simultaneously control a robot arm using an improved network interface. Virtual arm muscle activations responded to motoneuron firing rates, with virtual arm muscles lengths encoded via population coding in the proprioceptive population. After training, the virtual arm performed reaching movements which were smoother and more realistic than those obtained using a simplistic arm model. This system provided access to both spiking network properties and to arm biophysical properties, including muscle forces. The use of a musculoskeletal virtual arm and the improved control system allowed the robot arm to perform movements which were smoother than those reported in our previous paper using a simplistic arm. This work provides a novel approach consisting of bidirectionally connecting a cortical model to a realistic virtual arm, and using the system output to drive a robotic arm in real time. Our techniques are applicable to the future development of brain neuroprosthetic control systems, and may enable enhanced brain -machine interfaces with the possibility for finer control of limb prosthetics.', 'Superposition of independent units of coordination during pointing movements involving the trunk with and without visual feedback Previous studies addressing the problem of the control of multiple degrees of freedom have examined the influence of trunk movement on pointing movements within the arm&apos;s reach. Such movements may be controlled by two functionally independent units of coordination (synergies): one involving only arm joints and producing the hand trajectory to the target (the transport synergy), and the other coordinating trunk and arm movements leaving the hand trajectory unchanged (the compensatory synergy). The question of whether or not this functional subdivision depends on visual Feedback; was addressed in the present study. We also tested whether or not the motor effects of different synergies are summated as independent components, a control strategy called """"superposition."""" Finally, we investigated whether or not the relationship between different degrees of freedom within each synergy could be considered linear resulting in proportional changes in different joins angles. Seated subjects produced fast, uncorrected arm movements to an ipsi- or a contralateral target in the direction of +/-45 degrees to the sagittal midline of the trunk. Targets could be reached using the arm alone (control trials) or by combining the arm motion with a forward or backward trunk motion produced by hip flexion or extension (test trials), with and without visual feedback. The shape of the hand trajectory, its direction and tangential velocity, movement precision. joint angles and the sequence of the trunk and hand recruitment and de-recruitment were measured. In both visual conditions, the direction of the hand trajectory observed in control trials was generally preserved in rest trials, in terms of sequencing, even in the absence of vision, the trunk movement was initiated before the onset of and outlasted the hand shift, indicating that the potential influence of the trunk on the hand movement was compensated by rotations in the elbow and shoulder joint. The analysis of other variables also implied that the effects of trunk recruitment on the hand trajectory were minor compared to those which could be observed if these these were not compensated by appropriate changes in the arm joint angles, it was concluded that an arm-trunk compensatory synergy is present in pointing movements regardless of visual feedback. Principal component analysis showed that the relationship between elbow, shoulder and hip joint angles in individual arm and combined arm-trunk movements cannot be considered linear, implying that this relationship is adjusted according to the changing arm geometry. The changes in each arm joint angle (elbow, shoulder) elicited by a forward trunk bending in one block of trials were compared with those elicited by a backward bending in another block, whereas the hand moved to the same target in both blocks. These changes were opposite but of similar magnitude, As a result, for each moment of movement. the mean joint angle obtained by averaging across two directions of trunk motion was practically identical to that in control trials in which the trunk was motionless, it is concluded that the transport and arm-trunk compensatory synergies are combined as independent units, according to the principle of superposition. This principle may simplify the control of the coordination of a redundant number of degrees of freedom.', 'Trajectory formation based on physiological characteristics of skeletal muscles Human arm trajectories in natural unrestricted reaching movements were studied. They have particular properties such that a hand path is a rather simple straight or curved line: and a tangential velocity profile of hand is bell-shaped. Also these properties are invariant, independent of movement duration and hand-held load. In this study, trajectory formation is investigated on the basis of physiological characteristics of skeletal muscles, and a criterion prescribed by a derivative of isometric muscle torque is proposed. Subsequently, optimal trajectories are formulated under various conditions of movement to account for a planning strategy of human arm trajectories. In addition to such a theoretical approach, human arm trajectories are experimentally observed by a measuring system which provides a visual sensor and a target tracking device, enabling totally unrestricted movements. Then, optimal trajectories are quantitatively evaluated in comparison with experimental data in which essential properties of human arm trajectories are demonstrated. These results support the idea that human arm trajectories are planned in order to minimize the proposed criterion which is determined from physiological aspects. Finally, the physiological advantages of human arm trajectories are discussed with regard to the analysis of observed and optimal trajectories.']"
109,139,109_alzheimer_dementia_cognitive_neuroimaging,"['alzheimer', 'dementia', 'cognitive', 'neuroimaging', 'brain', 'biomarkers', 'neuropsychological', 'biomarker', 'aging', 'impairment']","[""Early MCI-to-AD Conversion Prediction Using Future Value Forecasting of Multimodal Features In Alzheimer's disease (AD) progression, it is imperative to identify the subjects with mild cognitive impairment before clinical symptoms of AD appear. This work proposes a technique for decision support in identifying subjects who will show transition from mild cognitive impairment (MCI) to Alzheimer's disease (AD) in the future. We used robust predictors from multivariate MRI-derived biomarkers and neuropsychological measures and tracked their longitudinal trajectories to predict signs of AD in the MCI population. Assuming piecewise linear progression of the disease, we designed a novel weighted gradient offset-based technique to forecast the future marker value using readings from at least two previous follow-up visits. Later, the complete predictor trajectories are used as features for a standard support vector machine classifier to identify MCI-to-AD progressors amongst the MCI patients enrolled in the Alzheimer's disease neuroimaging initiative (ADNI) cohort. We explored the performance of both unimodal and multimodal models in a 5-fold cross-validation setup. The proposed technique resulted in a high classification AUC of 91.2% and 95.7% for 6-month- and 1-year-ahead AD prediction, respectively, using multimodal markers. In the end, we discuss the efficacy of MRI markers as compared to NM for MCI-to-AD conversion prediction."", ""Self-Weighting Grading Biomarker Based on Graph-Guided Information Propagation for the Prediction of Mild Cognitive Impairment Conversion Mild cognitive impairment (MCI) represents a transitional stage between normal aging and Alzheimer's disease (AD), with a higher risk to convert to AD. The information of AD and normal control (NC) subjects can aid the classification between progressive MCI and stable MCI. In this paper, we develop an effective biomarker by combining the auxiliary information of AD and NC subjects with the relationship of brain regions of MCI subject, which makes best of auxiliary information and improves the prediction accuracy of MCI-to-AD conversion. Specifically, a projection vector is first obtained for each MCI subject via graph-guided information propagation. Next, the information of projection vector is integrated using a self-weighting grading method to acquire the novel biomarker. Finally, the self-weighting grading biomarkers derived from multiple morphological features are combined to provide more accurate prediction of MCI-to-AD conversion. Experimental results on the Alzheimer's Disease Neuroimaging Initiative database demonstrate the effectiveness of the proposed biomarkers for the prediction of MCI conversion."", ""Machine learning framework for early MRI-based Alzheimer's conversion prediction in MCI subjects Mild cognitive impairment (MCI) is a transitional stage between age-related cognitive decline and Alzheimer's disease (AD). For the effective treatment of AD, it would be important to identify MCI patients at high risk for conversion to AD. In this study, we present a novel magnetic resonance imaging (MRI)-based method for predicting the MCI-to-AD conversion from one to three years before the clinical diagnosis. First, we developed a novel MRI biomarker of MCI-to-AD conversion using semi-supervised learning and then integrated it with age and cognitive measures about the subjects using a supervised learning algorithm resulting in what we call the aggregate biomarker. The novel characteristics of the methods for learning the biomarkers are as follows: 1) We used a semi-supervised learning method (low density separation) for the construction of MRI biomarker as opposed to more typical supervised methods; 2) We performed a feature selection on MRI data from AD subjects and normal controls without using data from MCI subjects via regularized logistic regression; 3) We removed the aging effects from the MRI data before the classifier training to prevent possible confounding between AD and age related atrophies; and 4) We constructed the aggregate biomarker by first learning a separate MRI biomarker and then combining it with age and cognitive measures about the MCI subjects at the baseline by applying a random forest classifier. We experimentally demonstrated the added value of these novel characteristics in predicting the MCI-to-AD conversion on data obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. With the ADNI data, the MRI biomarker achieved a 10-fold cross-validated area under the receiver operating characteristic curve (AUC) of 0.7661 in discriminating progressive MCI patients (pMCI) from stable MCI patients (sMCI). Our aggregate biomarker based on MRI data together with baseline cognitive measurements and age achieved a 10-fold cross-validated AUC score of 0.9020 in discriminating pMCI from sMCI. The results presented in this study demonstrate the potential of the suggested approach for early AD diagnosis and an important role of MRI in the MCI-to-AD conversion prediction. However, it is evident based on our results that combining MRI data with cognitive test results improved the accuracy of the MCI-to-AD conversion prediction. (C) 2014 Elsevier Inc. All rights reserved.""]"
110,138,110_knee_cartilage_osteoarthritis_knees,"['knee', 'cartilage', 'osteoarthritis', 'knees', 'arthritis', 'ligament', 'joint', 'bone', 'osteoporosis', 'imaging']","['From classical to deep learning: review on cartilage and bone segmentation techniques in knee osteoarthritis research Knee osteoarthritis is a major diarthrodial joint disorder with profound global socioeconomic impact. Diagnostic imaging using magnetic resonance image can produce morphometric biomarkers to investigate the epidemiology of knee osteoarthritis in clinical trials, which is critical to attain early detection and develop effective regenerative treatment/therapy. With tremendous increase in image data size, manual segmentation as the standard practice becomes largely unsuitable. This review aims to provide an in-depth insight about a broad collection of classical and deep learning segmentation techniques used in knee osteoarthritis research. Specifically, this is the first review that covers both bone and cartilage segmentation models in recognition that knee osteoarthritis is a """"whole joint"""" disease, as well as highlights on diagnostic values of deep learning in emerging knee osteoarthritis research. Besides, we have collected useful deep learning reviews to serve as source of reference to ease future development of deep learning models in this field. Lastly, we highlight on the diagnostic value of deep learning as key future computer-aided diagnosis applications to conclude this review.', 'Knee Cartilage Defect Assessment by Graph Representation and Surface Convolution Knee osteoarthritis (OA) is the most common osteoarthritis and a leading cause of disability. Cartilage defects are regarded as major manifestations of knee OA, which are visible by magnetic resonance imaging (MRI). Thus early detection and assessment for knee cartilage defects are important for protecting patients from knee OA. In this way, many attempts have been made on knee cartilage defect assessment by applying convolutional neural networks (CNNs) to knee MRI. However, the physiologic characteristics of the cartilage may hinder such efforts: the cartilage is a thin curved layer, implying that only a small portion of voxels in knee MRI can contribute to the cartilage defect assessment; heterogeneous scanning protocols further challenge the feasibility of the CNNs in clinical practice; the CNN-based knee cartilage evaluation results lack interpretability. To address these challenges, we model the cartilages structure and appearance from knee MRI into a graph representation, which is capable of handling highly diverse clinical data. Then, guided by the cartilage graph representation, we design a non-Euclidean deep learning network with the self-attention mechanism, to extract cartilage features in the local and global, and to derive the final assessment with a visualized result. Our comprehensive experiments show that the proposed method yields superior performance in knee cartilage defect assessment, plus its convenient 3D visualization for interpretability.', 'Machine learning to predict incident radiographic knee osteoarthritis over 8 Years using combined MR imaging features, demographics, and clinical factors: data from the Osteoarthritis Initiative Objective: To develop a machine learning-based prediction model for incident radiographic osteoarthritis (OA) of the knee over 8 years using MRI-based cartilage biochemical composition and knee joint structure, demographics, and clinical predictors including muscle strength and symptoms. Design: Individuals (n 1/4 1,044) with baseline Kellgren Lawrence (KL) grade 0-1 in the right knee from the Osteoarthritis Initiative database were analyzed. 3T MRI at baseline was used to quantify knee cartilage T2, and Whole-Organ Magnetic Resonance Imaging Scores (WORMS) were obtained for cartilage, meniscus, and bone marrow. The outcome was set as true if a subject developed KL grade 2-4 OA in the right knee over 8 years (n 1/4 183) and false if the subject remained at KL 0-1 over 8 years (n 1/4 861). We developed and compared three models: Model 1: 112 predictors based on OA risk factors; Model 2: top ten predictors based on feature importance score from Model 1 and clinical relevance; Model 3: Model 2 without the imaging predictors. We compared the models using the area under the ROC curve derived from hold-out data. Results: The 10-predictor model (Model 2, that includes cartilage and meniscus WORMS scores and cartilage T2) had a slightly lower AUC (0.772) compared to the model with 112 predictors (Model 1: AUC 1/4 0.792, p 1/4 0.739); and had a significantly higher AUC compared to the model without MR imaging predictors (Model 3, AUC 1/4 0.669, p 1/4 0.011). Conclusions: A 10-predictor model including MRI parameters coupled with demographics, symptoms, muscle, and physical activity scores provides good prediction of incident radiographic OA over 8 years.']"
111,137,111_cortex_neural_neurons_receptive,"['cortex', 'neural', 'neurons', 'receptive', 'cortical', 'stimuli', 'stimulus', 'ventral', 'visual', 'mechanisms']","['Receptive fields similar to simple cells maximize temporal coherence in natural video Recently, statistical models of natural images have shown emergence of several properties of the visual cortex. Most models have considered the non-Gaussian properties of static image patches, leading to sparse coding or independent component analysis. Here we consider the basic statistical time dependencies of image sequences. We show that simple cell type receptive fields emerge when temporal response strength correlation is maximized for natural image sequences. Thus, temporal response strength correlation, which is a nonlinear measure of temporal coherence, provides an alternative to sparseness in modeling simple cell receptive field properties. Our results also suggest an interpretation of simple cells in terms of invariant coding principles that have previously been used to explain complex cell receptive fields.', 'A computational theory of visual receptive fields A receptive field constitutes a region in the visual field where a visual cell or a visual operator responds to visual stimuli. This paper presents a theory for what types of receptive field profiles can be regarded as natural for an idealized vision system, given a set of structural requirements on the first stages of visual processing that reflect symmetry properties of the surrounding world. These symmetry properties include (i) covariance properties under scale changes, affine image deformations, and Galilean transformations of space-time as occur for real-world image data as well as specific requirements of (ii) temporal causality implying that the future cannot be accessed and (iii) a time-recursive updating mechanism of a limited temporal buffer of the past as is necessary for a genuine real-time system. Fundamental structural requirements are also imposed to ensure (iv) mutual consistency and a proper handling of internal representations at different spatial and temporal scales. It is shown how a set of families of idealized receptive field profiles can be derived by necessity regarding spatial, spatio-chromatic, and spatio-temporal receptive fields in terms of Gaussian kernels, Gaussian derivatives, or closely related operators. Such image filters have been successfully used as a basis for expressing a large number of visual operations in computer vision, regarding feature detection, feature classification, motion estimation, object recognition, spatio-temporal recognition, and shape estimation. Hence, the associated so-called scale-space theory constitutes a both theoretically well-founded and general framework for expressing visual operations. There are very close similarities between receptive field profiles predicted from this scale-space theory and receptive field profiles found by cell recordings in biological vision. Among the family of receptive field profiles derived by necessity from the assumptions, idealized models with very good qualitative agreement are obtained for (i) spatial on-center/off-surround and off-center/on-surround receptive fields in the fovea and the LGN, (ii) simple cells with spatial directional preference in V1, (iii) spatio-chromatic double-opponent neurons in V1, (iv) space-time separable spatio-temporal receptive fields in the LGN and V1, and (v) non-separable space-time tilted receptive fields in V1, all within the same unified theory. In addition, the paper presents a more general framework for relating and interpreting these receptive fields conceptually and possibly predicting new receptive field profiles as well as for pre-wiring covariance under scaling, affine, and Galilean transformations into the representations of visual stimuli. This paper describes the basic structure of the necessity results concerning receptive field profiles regarding the mathematical foundation of the theory and outlines how the proposed theory could be used in further studies and modelling of biological vision. It is also shown how receptive field responses can be interpreted physically, as the superposition of relative variations of surface structure and illumination variations, given a logarithmic brightness scale, and how receptive field measurements will be invariant under multiplicative illumination variations and exposure control mechanisms.', 'Linear Neural Circuitry Model for Visual Receptive Fields The current state of art in the literature indicates that linear visual receptive fields are Gaussian or formed based on Gaussian kernels in biological visual systems. In this paper, by employing hypotheses based on the anatomy and physiology of vertebrate biological vision, we propose a neural circuitry possessing Gaussian-related visual receptive fields. Here, we present a plausible circuitry system matching the characteristic properties of an ideal visual front end of biological visual systems and then present a condition under which this circuit demonstrates a linear behaviour to model the linear receptive fields observed in the biological experimental data. The objective of this study is to understand the hardware circuitry from which various visual receptive fields in biological visual system can be deduced. In our model, a nonlinear neural network communicating with spikes is considered. The condition under which this neural network behaves linearly is discussed. The equivalent linear circuit proposed here employs some anatomical and physiological properties of the early biological visual pathway to derive the visual receptive field profiles for linear cells such as neurons with isotropic separable, non-isotropic separable and non-separable (velocity-adapted) Gaussian receptive fields in the LGN and striate cortex. In the model presented here, the theory of transmission lines for linear distributed electrical circuits is employed for two-dimensional transmission grids to model cell connectivities in a neural layer. The model presented here leads to a formulation similar to the Gaussian scale-space theory for the transmission of visual signals through various layers of neurons. Our model therefore presents a new insight on how the convolution process with Gaussian kernels can be implemented in vertebrate visual systems. The comparison of the numerical simulations of our model presented in this paper with the data analysis of receptive field profiles recorded in the biological literature demonstrates a complete agreement between our theoretical model and experimental data. Our model is also in good agreement with the numerical results of the Gaussian scale-space theory for the visual receptive fields.']"
112,133,112_neural_recurrent_deterministic_psychrnn,"['neural', 'recurrent', 'deterministic', 'psychrnn', 'rnns', 'networks', 'computational', 'learning', 'neurons', 'automaton']","[""FIRST-ORDER RECURRENT NEURAL NETWORKS AND DETERMINISTIC FINITE-STATE AUTOMATA We examine the correspondence between first-order recurrent neural networks and deterministic finite state automata. We begin with the problem of inducing deterministic finite state automata from finite training sets, that include both positive and negative examples, an NP-hard problem (Angluin and Smith 1983). We use a neural network architecture with two recurrent layers, which we argue can approximate any discrete-time, time-invariant dynamic system, with computation of the full gradient during learning. The networks are trained to classify strings as belonging or not belonging to the grammar. The training sets used contain only short strings, and the sets are constructed in a way that does not require a priori knowledge of the grammar. After training, the networks are tested using various test sets with strings of length up to 1000, and are often able to correctly classify all the test strings. These results are comparable to those obtained with second-order networks (Giles et al. 1992; Watrous and Kuhn 1992a; Zeng et al. 1993). We observe that the networks emulate finite state automata, confirming the results of other authors, and we use a vector quantization algorithm to extract deterministic finite state automata after training and during testing of the networks, obtaining a table listing the start state, accept states, reject states, al transitions from the states, as well as some useful statistics. We examine the correspondence between finite state automata and neural networks in detail, showing two major stages in the learning process. To this end, we use a graphics module, which graphically depicts the states of the network during the learning and testing phases. We examine the networks' performance when tested on strings much longer than those in the training set, noting a measure based on clustering that is correlated to the stability of the networks. Finally, we observe that with sufficiently long training times, neural networks can become true finite state automata, due to the attractor structure of their dynamics."", ""Considerations in using recurrent neural networks to probe neural dynamics NEW & NOTEWORTHY Artificial neurons in a recurrent neural network (RNN) may resemble empirical single-unit activity but not adequately capture important features on the neural population level. Dynamics of RNNs can be visualized in low-dimensional projections to provide insight into the RNN's dynamical mechanism. RNNs trained in different ways may reproduce neurophysiological motifs but do so with distinctly different mechanisms. RNNs trained to only perform a delayed reach task can generalize to perform tasks where the target is switched or the target location is changed. Recurrent neural networks (RNNs) are increasingly being used to model complex cognitive and motor tasks performed by behaving animals. RNNs are trained to reproduce animal behavior while also capturing key statistics of empirically recorded neural activity. In this manner, the RNN can be viewed as an in silico circuit whose computational elements share similar motifs with the cortical area it is modeling. Furthermore, because the RNN's governing equations and parameters are fully known, they can be analyzed to propose hypotheses for how neural populations compute. In this context, we present important considerations when using RNNs to model motor behavior in a delayed reach task. First, by varying the network's nonlinear activation and rate regularization, we show that RNNs reproducing single-neuron firing rate motifs may not adequately capture important population motifs. Second, we find that even when RNNs reproduce key neurophysiological features on both the single neuron and population levels, they can do so through distinctly different dynamical mechanisms. To distinguish between these mechanisms, we show that an RNN consistent with a previously proposed dynamical mechanism is more robust to input noise. Finally, we show that these dynamics are sufficient for the RNN to generalize to tasks it was not trained on. Together, these results emphasize important considerations when using RNN models to probe neural dynamics."", 'The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction Recurrent neural networks (RNNs) can learn to perform finite state computations. It is shown that an RNN performing a finite state computation must organize its state space to mimic the states in the minimal deterministic finite state machine that can perform that computation, and a precise description of the attractor structure of such systems is given. This knowledge effectively predicts activation space dynamics, which allows one to understand RNN computation dynamics in spite of complexity in activation dynamics. This theory provides a theoretical framework for understanding finite state machine (FSM) extraction techniques and can be used to improve training methods for RNNs performing FSM computations. This provides an example of a successful approach to understanding a general class of complex systems that has not been explicitly designed, e.g., systems that have evolved or learned their internal structure.']"
113,133,113_synchronization_fractional_neural_equilibrium,"['synchronization', 'fractional', 'neural', 'equilibrium', 'stability', 'stabilization', 'multistability', 'networks', 'analysis', 'theory']","['Global Mittag-Leffler Stabilization of Fractional-Order Memristive Neural Networks According to conventional memristive neural network theories, neurodynamic properties are powerful tools for solving many problems in the areas of brain-like associative learning, dynamic information storage or retrieval, etc. However, as have often been noted in most fractional-order systems, system analysis approaches for integral-order systems could not be directly extended and applied to deal with fractional-order systems, and consequently, it raises difficult issues in analyzing and controlling the fractional-order memristive neural networks. By using the set-valued maps and fractional-order differential inclusions, then aided by a newly proposed fractional derivative inequality, this paper investigates the global Mittag-Leffler stabilization for a class of fractional-order memristive neural networks. Two types of control rules (i.e., state feedback stabilizing control and output feedback stabilizing control) are designed for the stabilization of fractional-order memristive neural networks, while a list of stabilization criteria is established. Finally, two numerical examples are given to show the effectiveness and characteristics of the obtained theoretical results.', 'Mittag-Leffler synchronization of fractional neural networks with time-varying delays and reaction-diffusion terms using impulsive and linear controllers In this paper, we propose a fractional-order neural network system with time-varying delays and reaction-diffusion terms. We first develop a new Mittag-Leffler synchronization strategy for the controlled nodes via impulsive controllers. Using the fractional Lyapunov method sufficient conditions are given. We also study the global Mittag-Leffler synchronization of two identical fractional impulsive reaction-diffusion neural networks using linear controllers, which was an open problem even for integer-order models. Since the Mittag-Leffler stability notion is a generalization of the exponential stability concept for fractional-order systems, our results extend and improve the exponential impulsive control theory of neural network system with time-varying delays and reaction-diffusion terms to the fractional-order case. The fractional-order derivatives allow us to model the long-term memory in the neural networks, and thus the present research provides with a conceptually straightforward mathematical representation of rather complex processes. Illustrative examples are presented to show the validity of the obtained results. We show that by means of appropriate impulsive controllers we can realize the stability goal and to control the qualitative behavior of the states. An image encryption scheme is extended using fractional derivatives. (C) 2017 Elsevier Ltd. All rights reserved.', 'Further results on stability and synchronization of fractional-order Hopfield neural networks This paper focuses on stability and synchronization of fractional-order Hopfield neural networks. By taking information on activation functions into account, two novel convex Lyapunov functions are constructed: one is a fractional-order-dependent Lyapunov function, and the other is a new quadratic Lyapunov function. Based on these two Lyapunov functions, together with a fractional-order differential inequality, a fractional-order-dependent Mittag-Leffler stability criterion is derived for fractional-order Hopfield neural networks, which is in the form of linear matrix inequalities (LMIs). Moreover, a Mittag-Leffler synchronization criterion in terms of LMIs is presented for drive-response fractional-order Hopfield neural networks under linear control. Finally, three numerical examples are provided to indicate the benefits and less conservatism of the obtained criteria in this paper. (C) 2019 Elsevier B.V. All rights reserved.']"
114,133,114_znn_zfs_neural_zhang,"['znn', 'zfs', 'neural', 'zhang', 'gnn', 'znd', 'network', 'simulation', 'solving', 'simulative']","['From different ZFs to different ZNN models accelerated via Li activation functions to finite-time convergence for time-varying matrix pseudoinversion In this paper, a special class of recurrent neural network, termed Zhang neural network (ZNN), is investigated for the online solution of the time-varying matrix pseudoinverse. Meanwhile, a novel activation function, named Li activation function, is employed. Then, based on two basic Zhang functions (ZFs) and the intrinsically nonlinear method of ZNN design, two finite-time convergent ZNN models (termed ZNN-1 model and ZNN-2 model) are first proposed and investigated for time-varying matrix pseudoinversion. Such two ZNN models can be accelerated to finite-time convergence to the time-varying theoretical pseudoinverse. The upper bound of the convergence time is also derived analytically via Lyapunov theory. By exploiting the other three simplified ZFs and the extended nonlinearization method, three simplified finite-time convergent ZNN models (termed ZNN-3 model, ZNN-4 model and ZNN-5 model) are sequentially proposed. In addition, the link between the ZNN models and the Getz-Marsden (G-M) dynamic system is discovered and presented in this paper. Computer-simulation results further substantiate the theoretical analysis and demonstrate the effectiveness of ZNN models based on different ZFs for the time-varying matrix pseudoinverse. (C) 2014 Elsevier B.V. All rights reserved.', 'Different Zhang functions resulting in different ZNN models demonstrated via time-varying linear matrix-vector inequalities solving Our previous work shows that Zhang neural network (ZNN) has the higher efficiency and better performance for solving online time-varying linear matrix-vector inequalities, as compared to the conventional gradient neural network. In this paper, introducing the concept of Zhang function, we further investigate the problem of time-varying linear matrix-vector inequalities solving. Specifically, by defining three different Zhang functions, three types of ZNN models are further elaborately constructed to solve time-varying linear matrix-vector inequalities. The first ZNN model is based on a vector-valued lower-bounded Zhang function and is termed ZNN-1 model. The second one is based on a vector-valued lower-unbounded Zhang function and is termed ZNN-2 model. The third one is based on a transformed lower-unbounded Zhang function and is termed ZNN-3 model. Compared with the ZNN-1 model for solving time-varying linear matrix-vector inequalities, it is surprisedly discovered that the ZNN-2 model incorporates the ZNN-1 model as its special case. Besides, we put research emphasis on the ZNN-3 model for solving time-varying linear matrix-vector inequalities (including its design process, theoretical analysis and simulation verification). When power-sum activation functions are exploited, the ZNN-3 model possesses the property of superior convergence and better accuracy. Computer-simulation results further verify and demonstrate the theoretical analysis and efficacy of the ZNN-3 model for solving time-varying linear matrix-vector inequalities. (C) 2013 Elsevier B.V. All rights reserved.', 'From Different Zhang Functions to Various ZNN Models Accelerated to Finite-Time Convergence for Time-Varying Linear Matrix Equation In addition to the parallel-distributed nature, recurrent neural networks can be implemented physically by designated hardware and thus have been found broad applications in many fields. In this paper, a special class of recurrent neural network named Zhang neural network (ZNN), together with its electronic realization, is investigated and exploited for online solution of time-varying linear matrix equations. By following the idea of Zhang function (i.e., error function), two ZNN models are proposed and studied, which allow us to choose plentiful activation functions (e.g., any monotonically-increasing odd activation function). It is theoretically proved that such two ZNN models globally and exponentially converge to the theoretical solution of time-varying linear matrix equations when using linear activation functions. Besides, the new activation function, named Li activation function, is exploited. It is theoretically proved that, when using Li activation function, such two ZNN models can be further accelerated to finite-time convergence to the time-varying theoretical solution. In addition, the upper bound of the convergence time is derived analytically via Lyapunov theory. Then, we conduct extensive simulations using such two ZNN models. The results substantiate the theoretical analysis and the efficacy of the proposed ZNN models for solving time-varying linear matrix equations.']"
115,133,115_pcf_pca_pcs_component,"['pcf', 'pca', 'pcs', 'component', 'components', 'eigenvector', 'npca', 'matrix', 'kpca', 'mca']","['Kernel principal component analysis for content based image retrieval Kernel principal component analysis (PCA) has recently been proposed as a nonlinear extension of PCA. The basic idea is to first map the input space into a feature space via a nonlinear map and then compute the principal components in that feature space. This paper illustrates the potential of kernel PCA for dimensionality reduction and feature extraction in content-based image retrieval. By the use of Gaussian kernels, the principal components were computed in the feature space of an image data set and they are used as new dimensions to approximate images. Extensive experimental results show that kernel PCA performs better than linear PCA in content-based image retrievals.', 'Principal Component Analysis based on Nuclear norm Minimization Principal component analysis (PCA) is a widely used tool for dimensionality reduction and feature extraction in the field of computer vision. Traditional PCA is sensitive to outliers which are common in empirical applications. Therefore, in recent years, massive efforts have been made to improve the robustness of PCA. However, many emerging PCA variants developed in the direction have some weaknesses. First, few of them pay attention to the 2D structure of error matrix. Second, to estimate data mean from sample set with outliers by averaging is usually biased. Third, if some elements of a sample are disturbed, to extract principal components (PCs) by directly projecting data with transformation matrix causes incorrect mapping of sample to its genuine location in low-dimensional feature subspace. To alleviate these problems, we present a novel robust method, called nuclear norm-based on PCA (N-PCA) to take full advantage of the structure information of error image. Meanwhile, it is developed under a novel unified framework of PCA to remedy the bias of computing data mean and the low-dimensional representation of a sample both of which are treated as unknown variables in a single model together with projection matrix. To solve N-PCA, we propose an iterative algorithm, which has a closed-form solution in each iteration. Experimental results on several open databases demonstrate the effectiveness of the proposed method. (C) 2019 Elsevier Ltd. All rights reserved.', 'A Nonlinear principal component analysis of image data Principal Component Analysis (PCA) has been applied in various areas such as pattern recognition and data compression. In some cases, however, PCA does not extract the characteristics of the data-distribution efficiently. In order to overcome this problem, we have proposed a novel method of Nonlinear PCA which preserves the order of the principal components. In this paper, we reduce the dimensionality of image data using the proposed method, and examine its effectiveness in the compression and recognition of images.']"
116,132,116_hopfield_stochastic_neural_theory,"['hopfield', 'stochastic', 'neural', 'theory', 'theoretical', 'combinatorial', 'simulations', 'exponential', 'networks', 'equilibrium']","['Global exponential stability of a class of Hopfield neural networks with delays This paper investigates global exponential stability of a class of Hopfield neural networks with delays based on contraction mapping principle, Lyapunov function and inequality technique. Some sufficient conditions are derived that ensure the existence, uniqueness, global exponential stability of equilibrium point of the neural networks. Finally, an illustrative numerical example is given to demonstrate the effectiveness of our results.', 'Stochastic high-order Hopfield neural networks In 1984 Hopfield showed that, the time evolution of a symmetric Hopfield neural networks are a motion,in state space that seeks out minima in the energy function (i.e., equilibrium point set of Hopfield neural networks). Because high-order Hopfield neural networks have more extensive applications than Hopfield neural networks, and have been discussed on the convergence of the networks. In,practice, a neural network is often subject to environmental noise. It is. therefore useful and interesting to find out whether the high order neural network system still approacher some limit set-under stochastic perturbation. In this paper, we will give a number of useful bounds. for,the noise intensity under which the stochastic high-order neural network will approach its limit set. Our result cancels the requirement of symmetry of the connection weight matrix and includes the classic result on Hopfield, neural networks, which is a special case of stochastic high-order Hopfield neural networks. In the end, A example is given to verify the effective of our results.', 'High-order Hopfield neural networks In 1984 Hopfield showed that the time evolution of a symmetric Hopfield neural networks are a motion in state space that seeks out minima in the energy function (i.e., equilibrium point set of Hopfield neural networks). Because high-order Hopfield neural networks have more extensive applications than Hopfield neural networks, the paper will discuss the convergence of high-order Hopfield neural networks. The obtained results ensure that high-order Hopfield neural networks ultimately converge to the equilibrium point set. Our result cancels the requirement of symmetry of the connection weight matrix and includes the classic result on Hopfield neural networks, which is a special case of high-order Hopfield neural networks. In the end, A example is given to verify the effective of our results.']"
117,129,117_videos_video_clips_summarization,"['videos', 'video', 'clips', 'summarization', 'compression', 'datasets', 'visual', 'blur', 'features', 'coding']","['A quality enhancement framework with noise distribution characteristics for high efficiency video coding Video coding effectively reduces the amount of video data while unavoidably producing compression noise. Compression noise can cause significant artifacts in compressed video, such as blocking, ringing, and blurring, which seriously affects the visual quality of videos and the value of videos for content analysis. In compressed video quality enhancement, few methods based on deep learning fully consider the relationship between video content and compression noise or the possibility of uniting the encoder or the decoder to enhance the quality of compressed video. In an approach different from existing methods, we propose a video quality enhancement framework based on the distribution characteristics of compression noise. The proposed framework consists of two parts: at the encoder, we propose a convolutional neural network (CNN)-based in-loop filtering network combined with noise distribution (IFN-ND) characteristics for the I frame instead of high efficiency video coding (HEVC) standard in-loop filters; at the decoder, we propose a CNN-based quality enhancement network combined with the noise distribution characteristics (PQEN-ND) for the P frames. The noise characteristics are extracted from the code stream to further improve the performance of the proposed networks. The experiments show that the proposed method can significantly improve the quality of HEVC compressed video, achieving an average 12.84% reduction in the BD rate and up to a 1.0476 dB increase in the peak signal-to-noise ratio (PSNR). (c) 2020 Elsevier B.V. All rights reserved.', 'A video summarization framework based on activity attention modeling using deep features for smart campus surveillance system Like other business domains, digital monitoring has now become an integral part of almost every academic institution. These surveillance systems cover all the routine activities happening on the campus while producing a massive volume of video data. Selection and searching the desired video segment in such a vast video repository is highly time-consuming. Effective video summarization methods are thus needed for fast navigation and retrieval of video content. This paper introduces a keyframe extraction method to summarize academic activities to produce a short representation of the target video while preserving all the essential activities present in the original video. First, we perform fine-grain activity recognition using a realistic Campus Activities Dataset (CAD) by modeling activity attention scores using a deep CNN model. In the second phase, we use the generated attention scores for each activity category to extract significant video frames. Finally, we evaluate the inter-frame similarity index used to reduce the number of redundant frames and extract only the representative keyframes. The proposed framework is tested on different videos, and the experimental results show the performance of the proposed summarization process.', 'Video summarization via spatio-temporal deep architecture Video summarization has unprecedented importance to help us overview current ever-growing amount of video collections. In this paper, we propose a novel dynamic video summarization model based on deep learning architecture. We are the first to solve the imbalanced class distribution problem in video summarization. The over-sampling algorithm is used to balance the class distribution on training data. The novel two-stream deep architecture with the cost-sensitive learning is proposed to handle the class imbalance problem in feature learning. In the spatial stream, RGB images are used to represent the appearance of video frames, and in the temporal stream, multi-frame motion vectors with deep learning framework is firstly introduced to represent and extract temporal information of the input video. The proposed method is evaluated on two standard video summarization datasets and a standard emotional dataset. Empirical validations for video summarization demonstrate that our model achieves performance improvement over the existing and state-of-the-art methods. Moreover, the proposed method is able to highlight the video content with the active level of arousal in affective computing task. In addition, the proposed frame-based model has another advantage. It can automatically preserve the connection between consecutive frames. Although the summary is constructed based on the frame level, the final summary is comprised of informative and continuous segments instead of individual separate frames. (C) 2018 Elsevier B.V. All rights reserved.']"
118,129,118_swarm_optimisation_optimizer_optimization,"['swarm', 'optimisation', 'optimizer', 'optimization', 'pso', 'optima', 'clustering', 'pollination', 'optimum', 'optimal']","['A mechanism based on Artificial Bee Colony to generate diversity in Particle Swarm Optimization Particle Swarm Optimization (PSO) presents fast convergence for problems with continuous variables, but in most cases it may not balance properly exploration and exploitation behaviours. On the other hand, Artificial Bee Colony (ABC) presents an interesting capability to generate diversity when employed bees stagnate in a certain region of the search space. In this paper we put forward a mechanism based on the ABC to generate diversity when all particles of the PSO converge to a single point of the search space. Then, the swarm entities can switch between two pre-defined behaviours by using fuzzy rules depending on the diversity of the whole swarm. As the basis of our proposal, we utilize the Adaptive PSO (APSO) approach because it presents the capability to properly weight the terms of the velocity equation depending mainly on the current diversity of the entire swarm. We name our proposal ABeePSO, which was evaluated and compared to other well known swarm based approaches in all benchmark functions recently proposed in CEC 2010 for large scale optimization. Our proposal outperformed previous approaches in most of the cases. (C) 2014 Elsevier B.V. All rights reserved.', 'Hybrid particle swarm optimization incorporating fuzzy reasoning and weighted particle In conventional particle swarm optimization (PSO), the search behavior has two principal forces of the moving direction to guide the particles toward their personal best (pbest) and the global best (gbest) positions. However, if the particle lies too close to either pbest or gbest, the optimization of the swarm is likely to be trapped into a local optimum. To overcome the local optimum problem, this paper proposes a hybrid particle swarm optimization incorporating fuzzy reasoning and a weighted particle (HPSOFW) to establish a novel search behavior model to improve the searching capability of the conventional PSO algorithm. In the proposed search behavior model, a weighted particle is incorporated into the algorithm to modify the searching direction and fuzzy reasoning is used to adjust an attraction factor and inertia weight such that the particle has a better opportunity to find the optimal solution. Based on adjustment of the attraction factor and inertia weight, the proposed search behavior model takes into consideration of both search strategies of exploitation (local search) and exploration (global search) during the optimization. Simulation results show that the proposed HPSOFW has much better performance than that of the existing optimization algorithms for ten benchmark functions. To demonstrate its feasibility, the proposed HPSOFW is also applied to the learning of neural network for nonlinear system modeling before applying it to model an energy consumption system with satisfactory performance. (C) 2015 Elsevier B.V. All rights reserved.', 'A diversity-guided hybrid particle swarm optimization based on gradient search As an evolutionary computing technique, particle swarm optimization (PSO) has good global search ability, but it is easy to make the swarm lose its diversity and lead to premature convergence. In this paper, a diversity-guided hybrid PSO based on gradient search is proposed to improve the search ability of the swarm. The adaptive PSO is first used to search the solution till the swarm loses its diversity. Then, the search process turns to a new PSO (DGPSOGS), and the particles update their velocities with their gradient directions as well as repel each other to improve the swarm diversity. Depending on the diversity value of the swarm, the proposed hybrid method switches alternately between two PSOs. The hybrid algorithm adaptively searches local minima with random search realized by adaptive PSO and performs global search with semi-deterministic search realized by DGPSOGS, and so its search ability is improved. The experimental results show that the proposed hybrid algorithm has better convergence performance with better diversity compared to some classical PSOs. (C) 2014 Elsevier B.V. All rights reserved.']"
119,129,119_prostate_prostatic_prostatectomy_imaging,"['prostate', 'prostatic', 'prostatectomy', 'imaging', 'prostatex', 'biopsy', 'mri', 'ultrasound', 'biopsies', 'radiotherapy']","['US/MRI Guided Robotic System for the Interventional Treatment of Prostate Needle-based percutaneous prostate interventions include biopsy and brachytherapy and the former is the gold standard for the diagnosis of prostate cancer and the latter is often used in the treatment of prostate cancer. This paper introduces a novel robotic assistant system for prostate intervention and the system architecture and workflow are described, which is significant for the design of similar systems. In order to offer higher precision and better real-time performance, a Ultrasound (US)/Magnetic Resonance Imaging (MRI) fusion method is proposed to guide the procedures in this study. Moreover, image registration is a key step and a hot issue in image fusion, especially in multimodal image fusion. In this work, we adopt a novel registration method based on active demons and optic flow for prostate image fusion. To verify the availability of the system, we evaluate our approach of the US/MRI image fusion by using data acquired from six patients, and root mean square error (RMSE) for anatomical landmarks is 3.15 mm. In order to verify the accuracy and validity of the system developed in this paper, a system experimental platform was built and used for bionic tissue puncture of prostate under the guidance of MR and Transrectal Ultrasound (TRUS) fusion images. The experimental results show that the deviations of the final actual needle points of the three target points on the bionic tissue model measured in the laboratory environment are less than 2.5 mm.', ""MRI-guided and robotic-assisted prostate biopsy Currently, systematic transrectal ultrasound-guided prostate biopsy for prostate cancer detection is the standard of care. Multiparametric MRI providing anatomic, functional and molecular information is the most promising imaging technique to detect and localize prostate cancer. A number of MRI-compatible robots, ranging from simple manipulators to a fully automated system, have been developed. The feasibility of these MRI-compatible robotic devices in closed-bore systems for prostatic interventions have been investigated. However, most studies focused on phantom experiments rather than on patients' studies. Thus far, only a small number of patients have undergone MRI- guided and robotic-assisted prostate biopsy. Although this potential technique shows promising results, there is little evidence for its clinical applicability. In this review, we summarized and critically discussed the most recent developments in the field of MRI-compatible robot-guided prostate interventions. Purpose of review Recent findings Summary The combination of MRI-guided and robotic-assisted prostate biopsy is a promising technique for prostate cancer detection. However, only limited research is performed in patients, and therefore the current clinical value of this technique is highly speculative."", 'A review of artificial. intelligence in prostate cancer detection on imaging A multitude of studies have explored the role of artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists in prostate cancer detection, risk-stratification, and management. This review provides a comprehensive overview of relevant literature regarding the use of AI models in (1) detecting prostate cancer on radiology images (magnetic resonance and ultrasound imaging), (2) detecting prostate cancer on histopathology images of prostate biopsy tissue, and (3) assisting in supporting tasks for prostate cancer detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both the potential of these AI models to assist in the clinical workflow of prostate cancer diagnosis, as well as the current limitations including variability in training data sets, algorithms, and evaluation criteria. We also discuss ongoing challenges and what is needed to bridge the gap between academic research on AI for prostate cancer and commercial solutions that improve routine clinical care.']"
120,129,120_ics_algorithm_algorithms_analysis,"['ics', 'algorithm', 'algorithms', 'analysis', 'ica', 'component', 'aipa', 'components', 'indicator', 'data']","['A one-bit-matching learning algorithm for independent component analysis Independent component analysis (ICA) has many practical applications in the fields of signal and image processing and several ICA learning algorithms have been constructed via the selection of model probability density functions. However, there is still a lack of deep mathematical theory to validate these ICA algorithms, especially for the general case that super- and sub-Gaussian sources coexist. In this paper, according to the one-bit-matching principle and by turning the de-mixing matrix into an orthogonal matrix via certain normalization, we propose a one-bit-matching ICA learning algorithm on the Stiefel manifold. It is shown by the simulated and audio experiments that our proposed learning algorithm works efficiently on the ICA problem with both super- and sub-Gaussian sources and outperforms the extended Infomax and Fast-ICA algorithms.', 'A fast algorithm for one-unit ICA-R Independent component analysis (ICA) aims to recover a set of unknown mutually independent source signals from their observed mixtures without knowledge of the mixing coefficients. In some applications, it is preferable to extract only one desired source signal instead of all source signals, and this can be achieved by a one-unit ICA technique. ICA with reference (ICA-R) is a one-unit ICA algorithm capable of extracting an expected signal by using prior information. However, a drawback of ICA-R is that it is computationally expensive. In this paper, a fast one-unit ICA-R algorithm is derived. The reduction of the computational complexity for the ICA-R algorithm is achieved through (1) pre-whitening the observed signals: and (2) normalizing the weight vector. Computer simulations were performed on synthesized signals, a speech signal, and electrocardiograms (ECG). Results of these analyses demonstrate the efficiency and accuracy of the proposed algorithm. (c) 2006 Elsevier Inc. All rights reserved.', 'Two adaptive matching learning algorithms for independent component analysis Independent component analysis (ICA) has been applied in many fields of signal processing and many ICA learning algorithms have been proposed from different perspectives. However, there is still a lack of a deep mathematical theory to describe the ICA learning algorithm or problem, especially in the cases of both super- and sub-Gaussian sources. In this paper, from the point of view of the one-bit-matching principle, we propose two adaptive matching learning algorithms for the general ICA problem. It is shown by the simulation experiments that the adaptive matching learning algorithms can efficiently solve the ICA problem with both super- and sub-Gaussian sources and outperform the typical existing ICA algorithms in certain aspects.']"
121,128,121_cortex_cerebral_cortical_brain,"['cortex', 'cerebral', 'cortical', 'brain', 'brains', 'subcortical', 'geometry', 'mapping', 'morphometry', 'geometric']","['Automated segmentation of sulcal regions Automatic segmentation and identification of cortical sulci play an important role in the study of brain structure and function. In this work, a method is presented for the automatic segmentation of sulcal regions of cortex. Unlike previous methods that extract the sulcal spaces within the cortex, the proposed method extracts actual regions of the cortical surface that surround sulci. Sulcal regions are. segmented from the medial surface as well as the lateral and inferior surfaces. The method first generates a depth map on the surface, computed by measuring the distance between the cortex and ail outer """"shrink-wrap"""" surface. Sulcal regions are then extracted using a hierarchical algorithm that alternates between thresholding and region growing operations. To visualize the buried regions of the segmented cortical surface, ail efficient technique for mapping the surface to a sphere is proposed. Preliminary results are presented on the geometric analysis of sulcal regions for automated identification.', 'Automatic cortical sulcal parcellation based on surface principal direction flow field tracking The human cerebral cortex is a highly convoluted Structure composed of sulci and gyri, corresponding to the valleys and ridges of the cortical surface respectively. Automatic parcellation of the cortical surface into sulcal regions is of great importance in structural and functional mapping of the human brain. In this paper, a novel method is proposed for automatic Cortical sulcal parcellation based on the geometric characteristics of cortical surface including its principal curvatures and principal directions. This method is composed of two major steps: 1) employing the hidden Markov random field model (HMRF) and the expectation maximization (EM) algorithm on the maximum principal curvatures of the cortical surface for sulcal region segmentation, and 2) using a principal direction flow field tracking method on the cortical surface for sulcal basin segmentation. The flow field is obtained by diffusing the principal direction field on the cortical surface mesh. A unique feature of this method is that the automatic sulcal parcellation process is quite robust and efficient, and is independent of any external guidance Such as atlas-based warping. The method has been successfully applied to the inner cortical surfaces of twelve healthy human brain MR images. Both quantitative and qualitative evaluation results demonstrate the validity and efficiency of the proposed method. (C) 2009 Elsevier Inc. All rights reserved.', 'Hierarchical matching of cortical features for deformable brain image registration This paper builds upon our previous work on elastic registration, using surface-to-surface mapping. In particular, a methodology for finding a smooth map from one cortical surface to another is presented, using constraints imposed by a number of sulcal and gyral curves. The outer cortical surface is represented by a map from the unit sphere to the surface which is obtained by a deformable surface algorithm. The sulcal and gyral constraints are defined as landmark curves on the outer cortical surface representation. The unit sphere is then elastically warped to itself in 3D using the predefined sulcal and gyral constraints, yielding a repaxameterization of the original surface. This method is tested on MR images from. 8 subjects, showing improved registration in the vicinity of the sulci used as constraints. We also describe a hierarchical framework for automating this procedure, by using conditional spatial probability distributions of cortical features on the spherical parametric domain, in order to automatically identify cortical features. This approach is demonstrated on the central and precentral sulci.']"
122,128,122_dementia_virtual_cognitive_alzheimer,"['dementia', 'virtual', 'cognitive', 'alzheimer', 'cognition', 'elderly', 'aging', 'aged', 'experiences', 'reminiscence']","['Cycling and Spatial Navigation in an Enriched, Immersive 3D Virtual Park Environment: A Feasibility Study in Younger and Older Adults Conclusion: This study demonstrates that spatial navigation while cycling is feasible and that older adults report similar experiences to younger adults. VR may be a powerful tool for engaging physical and cognitive activity in older adults with acceptable adverse effects and with reports of enjoyment. Future studies are needed to assess the efficacy of a combined exercise and cognitive VR program as an intervention for promoting healthy brain aging, especially in older adults with increased risk of age-related cognitive decline. Background: Cognitive decline is a significant public health concern in older adults. Identifying new ways to maintain cognitive and brain health throughout the lifespan is of utmost importance. Simultaneous exercise and cognitive engagement has been shown to enhance brain function in animal and human studies. Virtual reality (VR) may be a promising approach for conducting simultaneous exercise and cognitive studies. In this study, we evaluated the feasibility of cycling in a cognitively enriched and immersive spatial navigation VR environment in younger and older adults. Results: A total of 4 subjects withdrew from the study due to adverse effects, yielding a 90% completion rate. Simulator sickness levels were enhanced in both age groups with exposure to the VR environment but were within an acceptable range. Exposure to the virtual environment was associated with high arousal and low stress levels, suggesting a state of excitement, and most participants reported enjoyment of the spatial navigation task and VR environment. No association was found between physical exertion levels and simulator sickness levels. Methods: A total of 20 younger (25.9 +/- 3.7 years) and 20 older (63.6 +/- 5.6 years) adults participated in this study. Participants completed four trials (2 learning and 2 recall) of cycling while wearing a head-mounted device (HMD) and navigating a VR park environment. Questionnaires were administered to assess adverse effects, mood, presence, and physical exertion levels associated with cycling in the VR environment.', 'Using virtual reality-based training to improve cognitive function, instrumental activities of daily living and neural efficiency in older adults with mild cognitive impairment AIM: This study investigated the effects of 12 weeks of VR-based physical and cognitive training on cognitive function, brain activation and IADL and compared the VR intervention with combined physical and cognitive training. BACKGROUND: A combination of physical and cognitive training appears to be the effective intervention to improve cognitive function in older adults with mild cognitive impairment (MCI). Computing technology such as virtual reality (VR) may have the potential to assist rehabilitation in shaping brain health. However, little is known about the potential of VR-based physical and cognitive training designed as an intervention for cognition and brain activation in elderly patients with MCI. Moreover, whether a VR program designed around functional tasks can improve their instrumental activities of daily living (IADL) requires further investigation. CLINICAL REHABILITATION IMPACT: VR training could be implemented for older adults with MCI. CONCLUSIONS: VR-based physical and cognitive training improves cognitive function, IADL and neural efficiency in older adults with MCI. DESIGN: A single-blinded randomized controlled trial. METHODS: Thirty-four community-dwelling older adults with MCI were randomized into either a VR-based physical and cognitive training (VR) group or a combined physical and cognitive training (CPC) group for 36 sessions over 12 weeks. Participants were assessed for their cognitive function (global cognition, executive function and verbal memory) and IADL at pre- and postintervention. Changes in prefrontal cortex activation during the global cognition test were also captured by functional near-infrared spectroscopy (NIRS) to identify the potential mediating pathway of the intervention. POPULATION: Older adults with mild cognitive impairment. RESULTS: Both groups showed improved executive function and verbal memory (immediate recall). However, only the VR group showed significant improvements in global cognition (P<0.001), verbal memory (delayed recall, P=0.002), and IADL (P<0.001) after the intervention. The group x time interaction effects further demonstrated that IADL were more significantly improved with VR training than with CPC training (P=0.006). The hemodynamic data revealed decreased activation in prefrontal areas after training (P=0.0015), indicative of increased neural efficiency, in the VR-trained subjects. SETTING: Communities and day care centers in Taipei, Taiwan.', 'Efficacy and Moderators of Virtual Reality for Cognitive Training in People with Dementia and Mild Cognitive Impairment: A Systematic Review and Meta-Analysis Background: Mild cognitive impairment (MCI) and dementia result in cognitive decline which can negatively impact everyday functional abilities and quality of life. Virtual reality (VR) interventions could benefit the cognitive abilities of people with MCI and dementia, but evidence is inconclusive. Conclusion: Our findings suggest that VR training is an effective treatment for both people with MCI and dementia. These results contribute to the establishment of practical guidelines for VR interventions for patients with cognitive decline. Methods: A systematic literature search was conducted on all major databases for randomized control trial studies. Two separate meta-analyses were performed on studies with people with MCI and dementia. Objective: To investigate the efficacy of VR training on global and domain-specific cognition, activities of daily living and quality of life. To explore the influence of priori moderators (e.g., immersion type, training type) on the effects of VR training. Adverse effects of VR training were also considered. Results: Sixteen studies with people with MCI and four studies with people with dementia were included in each meta-analysis. Results showed moderate to large effects of VR training on global cognition, attention, memory, and construction and motor performance in people with MCI. Immersion and training type were found to be significant moderators of the effect of VR training on global cognition. For people with dementia, results showed moderate to large improvements after VR training on global cognition, memory, and executive function, but a subgroup analysis was not possible.']"
123,127,123_chinese_japanese_characters_language,"['chinese', 'japanese', 'characters', 'language', 'semantic', 'qims', 'font', 'fonts', 'words', 'character']","['Mathematical representation of a Chinese character and its applications In this paper, a novel method to express Chinese characters mathematically is presented based on the knowledge of the structure of Chinese characters. Each Chinese character can be denoted by a mathematical expression in which the operands are components of Chinese characters and the operators are the location relations between the components. Five hundred five components are selected and 6 operators are defined to express all the Chinese characters successfully. These mathematical expressions of Chinese characters are simple, natural, and can be operated like the common mathematical expression of numbers. It makes Chinese information processing much simpler than before. This theory has been applied successfully in fonts automation, Chinese information transmission among different platforms and different operating systems on Internet, and knowledge discovery of the structure of Chinese characters. It can also be applied extensively to many areas such as typesetting, advertising, packing design, virtual library, network transmission, pattern recognition and Chinese mobile communication.', 'Occluded offline handwritten Chinese character inpainting via generative adversarial network and self-attention mechanism Occluded offline handwritten Chinese characters inpainting is a critical step for handwritten Chinese characters recognition. We propose to apply generative adversarial network and self-attention mechanism to inpaint occluded offline handwritten Chinese characters. First, cyclic loss is used to guarantee the cyclic consistency of the uncorrupted area between corrupted images and original real images instead of masks. Second, self-attention mechanism is combined with generative adversarial network to increase receptive field and explore more Chinese character features. Then an improved character-VGG-19 that is pre-trained with handwritten Chinese character dataset is used to calculate content loss to extract character features more effectively and assist generator to generate realistic characters. Finally, adversarial classification loss is used to make our discriminator classify input images instead of just distinguishing real images from fake images in order to learn the distribution of Chinese characters more effectively. The proposed method is evaluated on an occluded CASIA-HWDB1.1 dataset for three challenging inpainting tasks with different portions of blocks, or pixels randomly missing, or pixels randomly adding. Experimental results show that our method is more effective, compared with several state-of-the-art handwritten Chinese character inpainting methods. (C) 2020 Elsevier B.V. All rights reserved.', 'Pronunciation-Enhanced Chinese Word Embedding Chinese word embeddings have recently garnered considerable attention. Chinese characters and their sub-character components, which contain rich semantic information, are incorporated to learn Chinese word embeddings. Chinese characters can represent a combination of meaning, structure, and pronunciation. However, existing embedding learning methods focus on the structure and meaning of Chinese characters. In this study, we aim to develop an embedding learning method that can make complete use of the information represented by Chinese characters, including phonology, morphology, and semantics. Specifically, we propose a pronunciation-enhanced Chinese word embedding learning method, where the pronunciations of context characters and target characters are simultaneously encoded into the embeddings. Evaluation of word similarity, word analogy reasoning, text classification, and sentiment analysis validate the effectiveness of our proposed method.']"
124,126,124_separation_separating_sources_mixing,"['separation', 'separating', 'sources', 'mixing', 'mixtures', 'mixture', 'mixed', 'convergence', 'decorrelation', 'separate']","['Underdetermined blind separation of source using l(p)-norm diversity measures Blind separation of sources (BSS) is to recover the source signals from the observed mixture signals with no knowledge on the mixing channel. Recently, there has been more and more attention to underdetermined BSS. In the study of underdetermined BSS, it is a challenging problem to separate the source signals efficiently while without knowing the number of sources. On the one hand, the number of sources is unknown in practice. On the other hand, most traditional blind separation algorithms encounter highly computational complexity leading to poor separation performance. To remedy the shortcomings of traditional algorithms, in this paper, a novel algorithm based on p-norm-like (l((0< p <= 1))) diversity measures is proposed to solve the underdetermined BSS problem. First of all, we propose an improved information theory criteria method to detect the number of sources in the underdetermined case. Meanwhile, we use a fourth-order tensor blind identification method for the estimation of the mixing matrix. In the stage of source signal reconstruction, we develop an (l((0< p <= 1)))-norm diversity measure for better source signal reconstruction and the computational complexity is reduced significantly. Simulation results and experimental measurements demonstrate that the proposed algorithm can obtain better separation performance and achieve fast running speed. (C) 2020 Elsevier B.V. All rights reserved.', 'Underdetermined Blind Source Separation by Parallel Factor Analysis in Time-Frequency Domain This paper presents a new time-frequency approach to the underdetermined blind source separation using the parallel factor decomposition of third-order tensors. Without any constraint on the number of active sources at an auto-term time-frequency point, this approach can directly separate the sources as long as the uniqueness condition of parallel factor decomposition is satisfied. Compared with the existing two-stage methods where the mixing matrix should be estimated at first and then used to recover the sources, our approach yields better source separation performance in the presence of noise. Moreover, the mixing matrix can be estimated at the same time of the source separation process. Numerical simulations are presented to show the superior performance of the proposed approach to some of the existing two-stage blind source separation methods that use the time-frequency representation as well.', 'Blind source separation of more sources than mixtures using sparse mixture models In this paper, blind source separation is discussed with more sources than mixtures. This blind separation technique assumes a linear mixing model and involves two steps: (1) learning the mixing matrix for the observed data using the sparse mixture model and (2) inferring the sources by solving a linear programming problem after the mixing matrix is estimated. Through the experiments of the speech signals, we demonstrate the efficacy of this proposed approach. (c) 2005 Elsevier B.V. All rights reserved.']"
125,126,125_stressors_stressor_stress_stressful,"['stressors', 'stressor', 'stress', 'stressful', 'stressed', 'psychological', 'fatigue', 'mental', 'distress', 'effects']","['Machine Learning Based Solutions for Real-Time Stress Monitoring Stress may be defined as the reaction of the body to regulate itself to changes within the environment through mental, physical, or emotional responses. Recurrent episodes of acute stress can disturb the physical and mental stability of a person. This subsequently can have a negative effect on work performance and in the long term can increase the risk of physiological disorders like hypertension and psychological illness such as anxiety disorder. Psychological stress is a growing concern for the worldwide population across all age groups. A reliable, cost-efficient, acute stress detection system could enable its users to better monitor and manage their stress to mitigate its long-term negative effects. In this article, we will review and discuss the literature that has used machine learning based approaches for stress detection. We will also review the existing solutions in the literature that have leveraged the concept of edge computing in providing a potential solution in real-time monitoring of stress.', 'The Feasibility of Wearable and Self-Report Stress Detection Measures in a Semi-Controlled Lab Environment Workplace-related stressors, economic strain, and lack of access to educational and basic needs have exacerbated feelings of stress in the United States. Ongoing stress can result in an increased risk of cardiovascular, musculoskeletal, and mental health disorders. Similarly, workplace stress can translate to a decrease in employee productivity and higher costs associated with employee absenteeism in an organization. Detecting stress and the events that correlate with stress during a workday is the first step to addressing its negative effects on health and wellbeing. Although there are a variety of techniques for stress detection using physiological signals, there is still limited research on the ability of behavioral measures to improve the performance of stress detection algorithms. In this study, we evaluated the feasibility of detecting stress using deep learning, a subfield of machine learning, on a small data set consisting of electrodermal activity, skin temperature, and heart rate measurements, in combination with self-reported anxiety and stress. The model was able to detect stress periods with 96% accuracy when using the combined wearable device and survey data, compared to the wearable device dataset alone (88% accuracy). Creating multi-dimensional datasets that include both wearable device data and ratings of perceived stress could help correlate stress-inducing events with feelings of stress at the individual level and help reduce intra-individual variabilities due to the subjective nature of the stress response.', 'Machine Learning Framework for the Detection of Mental Stress at Multiple Levels Mental stress has become a social issue and could become a cause of functional disability during routine work. In addition, chronic stress could implicate several psychophysiological disorders. For example, stress increases the likelihood of depression, stroke, heart attack, and cardiac arrest. The latest neuroscience reveals that the human brain is the primary target of mental stress, because the perception of the human brain determines a situation that is threatening and stressful. In this context, an objective measure for identifying the levels of stress while considering the human brain could considerably improve the associated harmful effects. Therefore, in this paper, a machine learning (ML) framework involving electroencephalogram (EEG) signal analysis of stressed participants is proposed. In the experimental setting, stress was induced by adopting a well-known experimental paradigm based on the montreal imaging stress task. The induction of stress was validated by the task performance and subjective feedback. The proposed ML framework involved EEG feature extraction, feature selection (receiver operating characteristic curve, t-test and the Bhattacharya distance), classification (logistic regression, support vector machine and naive Bayes classifiers) and tenfold cross validation. The results showed that the proposed framework produced 94.6% accuracy for two-level identification of stress and 83.4% accuracy for multiple level identification. In conclusion, the proposed EEG-based ML framework has the potential to quantify stress objectively into multiple levels. The proposed method could help in developing a computer-aided diagnostic tool for stress detection.']"
126,123,126_superresolution_resolution_enhancement_model,"['superresolution', 'resolution', 'enhancement', 'model', 'features', 'images', 'feature', 'mapping', 'experimental', 'reconstructing']","['Example-based super-resolution via social images A novel image patch based example-based super-resolution algorithm is proposed for benefitting from social image data. The proposed algorithm is designed based on matrix-value operator learning techniques where the image patches are understood as the matrices and the single-image super-resolution is treated as a problem of learning a matrix-value operator. Taking advantage of the matrix trick, the proposed algorithm is so fast that it could be trained on social image data. To our knowledge, the proposed algorithm is the fastest single-image super-resolution algorithm when both training and test time are considered. Experimental results have shown the efficiency and the competitive performance of the proposed algorithm to most of state-of-the-art single-image super-resolution algorithms. (C) 2015 Elsevier B.V. All rights reserved.', 'Residual scale attention network for arbitrary scale image super-resolution Research on super-resolution has achieved great success on synthetic data with deep convolutional neural networks. Some recent works tend to apply super-resolution to practical scenarios. Learning an accurate and flexible model for super-resolution of arbitrary scale factor is important for realistic applications, while most existing works only focus on integer scale factor. In this work, we present a residual scale attention network for super-resolution of arbitrary scale factor. Specifically, we design a scale attention module to learn discriminative features of low-resolution images by introducing the scale factor as prior knowledge. Then, we utilize quadratic polynomial of the coordinate information and scale factor to predict pixel-wise reconstruction kernels and achieve super-resolution of arbitrary scale factor. Besides, we use the predicted reconstruction kernels in image domain to interpolate low-resolution image and obtain coarse high-resolution image first, then make our main network learn high-frequency residual image from feature domain. Extensive experiments on both synthetic and real data show that the proposed method outperforms state-of-the-art super-resolution methods of arbitrary scale factor in terms of both objective metrics and subjective visual quality. (c) 2020 Elsevier B.V. All rights reserved.', 'Guided filter-based multi-scale super-resolution reconstruction The learning-based super-resolution reconstruction method inputs a low-resolution image into a network, and learns a non-linear mapping relationship between low-resolution and high-resolution through the network. In this study, the multi-scale super-resolution reconstruction network is used to fuse the effective features of different scale images, and the non-linear mapping between low resolution and high resolution is studied from coarse to fine to realise the end-to-end super-resolution reconstruction task. The loss of some features of the low-resolution image will negatively affect the quality of the reconstructed image. To solve the problem of incomplete image features in low-resolution, this study adopts the multi-scale super-resolution reconstruction method based on guided image filtering. The high-resolution image reconstructed by the multi-scale super-resolution network and the real high-resolution image are merged by the guide image filter to generate a new image, and the newly generated image is used for secondary training of the multi-scale super-resolution reconstruction network. The newly generated image effectively compensates for the details and texture information lost in the low-resolution image, thereby improving the effect of the super-resolution reconstructed image.Compared with the existing super-resolution reconstruction scheme, the accuracy and speed of super-resolution reconstruction are improved.']"
127,123,127_dcnns_dcnn_neural_learning,"['dcnns', 'dcnn', 'neural', 'learning', 'recognition', 'classification', 'convolutional', 'convolution', 'layer', 'layers']","['Convolutional neural networks for hyperspectral image classification As a powerful visual model, convolutional neural networks (CNNs) have demonstrated remarkable performance in various visual recognition problems, and attracted considerable attention in recent years. However, due to the highly correlated bands and insufficient training samples of hyperspectral image data, it still remains a challenging problem to effectively apply the CNN models on hyperspectral images. In this paper, an efficient CNN architecture has been proposed to boost its discriminative capability for hyperspectral image classification, in which the original data is used as the input and the final CNN outputs are the predicted class-related results. The proposed CNN infrastructure has several distinct advantages. Firstly, different from traditional classification methods those need hand-crafted features, the CNN model used here is designed to deal with the problem of hyperspectral image analysis in an end-to-end way. Secondly, the parameters of the CNN model are optimized from a small training set, while the over-fitting problem of the neural network has been alleviated to some extent. Finally, in order to better deal with the hyperspectral image information, 1 x 1 convolutional layers have been adopted, and an average pooling layer and larger dropout rates have also been employed in the whole CNN procedure. The experiments on three benchmark data sets have demonstrated that the proposed CNN architecture considerably outperforms other state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.', 'Hybrid pooling for enhancement of generalization ability in deep convolutional neural networks Convolutional neural networks (CNNs) have attracted considerable attention in many application fields for their great ability to deal with image recognition and object detection tasks. A pooling process is an important process in CNNs, which serves to decrease the dimensionality of processed data for reducing computational cost as well as for enhancing tolerance to translation and noise. Although standard pooling methods, such as the max pooling and the average pooling, are typically adopted in many studies, a newly devised pooling method could improve the generalization ability of CNNs. In this study, we propose a hybrid pooling method which stochastically chooses the max pooling or the average pooling in each pooling layer. A characteristic of the hybrid pooling is that the probability for choosing one of the two pooling methods can be controlled for each convolutional layer. In image classification tasks with benchmark datasets, we show that the hybrid pooling is effective for increasing the generalization ability of CNNs. Moreover, we demonstrate that the hybrid pooling combined with the dropout is competitive with other existing methods in classification performance. (C) 2018 Elsevier B.V. All rights reserved.', 'Content-based image retrieval with compact deep convolutional features Convolutional neural networks (CNNs) with deep learning have recently achieved a remarkable success with a superior performance in computer vision applications. Most of CNN-based methods extract image features at the last layer using a single CNN architecture with orderless quantization approaches, which limits the utilization of intermediate convolutional layers for identifying image local patterns. As one of the first works in the context of content-based image retrieval (CBIR), this paper proposes a new bilinear CNN-based architecture using two parallel CNNs as feature extractors. The activations of convolutional layers are directly used to extract the image features at various image locations and scales. The network architecture is initialized by deep CNNs sufficiently pre-trained on a large generic image dataset then fine-tuned for the CBIR task. Additionally, an efficient bilinear root pooling is proposed and applied to the low-dimensional pooling layer to reduce the dimension of image features to compact but high discriminative image descriptors. Finally, an end-to-end training with backpropagation is performed to fine-tune the final architecture and to learn its parameters for the image retrieval task. The experimental results achieved on three standard benchmarking image datasets demonstrate the outstanding performance of the proposed architecture at extracting and learning complex features for the CBIR task without prior knowledge about the semantic meta-data of images. For instance, using a very compact image vector of 16-length, we achieve a retrieval accuracy of 95.7% (mAP) on Oxford 5K and 88.6% on Oxford 105K; which outperforms the best results reported by state-of-the-art approaches. Additionally, a noticeable reduction is attained in the required extraction time for image features and the memory size required for storage. 2017 Elsevier B.V. All rights reserved.']"
128,121,128_dendritic_neuronal_neuron_dendrites,"['dendritic', 'neuronal', 'neuron', 'dendrites', 'dendrite', 'motoneurons', 'neurons', 'spines', 'spine', 'cortex']","['A neurocomputational method for fully automated 3D dendritic spine detection and segmentation of medium-sized spiny neurons Acquisition and quantitative analysis of high resolution images of dendritic spines are challenging tasks but are necessary for the study of animal models of neurological and psychiatric diseases. Currently available methods for automated dendritic spine detection are for the most part customized for 2D image slices, not volumetric 3D images. In this work, a fully automated method is proposed to detect and segment dendritic spines from 3D confocal microscopy images of medium-sized spiny neurons (MSNs). MSNs constitute a major neuronal population in striatum, and abnormalities in their function are associated with several neurological and psychiatric diseases. Such automated detection is critical for the development of new 3D neuronal assays which can be used for the screening of drugs and the studies of their therapeutic effects. The proposed method utilizes a generalized gradient vector flow (GGVF) with a new smoothing constraint and then detects feature points near the central regions of dendrites and spines. Then, the central regions are refined and separated based on eigen-analysis and multiple shape measurements. Finally, the spines are segmented in 3D space using the fast marching algorithm, taking the detected central regions of spines as initial points. The proposed method is compared with three popular existing methods for centerline extraction and also with manual results for dendritic spine detection in 3D space. The experimental results and comparisons show that the proposed method is able to automatically and accurately detect, segment, and quantitate dendritic spines in 3D images of MSNs. (C) 2010 Elsevier Inc. All rights reserved.', 'Dendritic spine detection using curvilinear structure detector and LDA classifier Dendritic spines are small, bulbous cellular compartments that carry synapses. Biologists have been studying the biochemical pathways by examining the morphological and statistical changes of the dendritic spines at the intracellular level. In this paper a novel approach is presented for automated detection of dendritic spines in neuron images. The dendritic spines are recognized as small objects of variable shape attached or detached to multiple dendritic backbones in the 2D projection of the image stack along the optical direction. We extend the curvilinear structure detector to extract the boundaries as well as the centerlines for the dendritic backbones and spines. We further build a classifier using Linear Discriminate Analysis (LDA) to classify the attached spines into valid and invalid types to improve the accuracy of the spine detection. We evaluate the proposed approach by comparing with the manual results in terms of backbone length, spine number, spine length, and spine density. (c) 2007 Elsevier Inc. All rights reserved.', 'Automated dendritic spine detection using convolutional neural networks on maximum intensity projected microscopic volumes Background: Dendritic spines are structural correlates of excitatory synapses in the brain. Their density and structure are shaped by experience, pointing to their role in memory encoding. Dendritic spine imaging, followed by manual analysis, is a primary way to study spines. However, an approach that analyses dendritic spines images in an automated and unbiased manner is needed to fully capture how spines change with normal experience, as well as in disease. Comparison with existing methods: Our method significantly outperforms two well-known software, NeuronStudio and Neurolucida (p-value < 0.02). Conclusions: FCN architectures used in this work allow for automated dendritic spine detection. Superior outcomes are possible even with small training data-sets. The proposed method may generalize to other datasets on larger scales. New method: We propose an approach based on fully convolutional neural networks (FCNs) to detect dendritic spines in two-dimensional maximum-intensity projected images from confocal fluorescent micrographs. We experiment on both fractionally strided convolution and efficient sub-pixel convolutions. Dendritic spines far from the dendritic shaft are pruned by extraction of the shaft to reduce false positives. Performance of the proposed method is evaluated by comparing predicted spine positions to those manually marked by experts. Results: The averaged distance between predicted and manually annotated spines is 2.81 +/- 2.63 pixels (0.082 +/- 0.076 microns) and 2.87 +/- 2.33 pixels (0.084 +/- 0.068 microns) based on two different experts. FCN-based detection achieves F scores > 0.80 for both sets of expert annotations.']"
129,119,129_neuron_neuronal_microscopy_neural,"['neuron', 'neuronal', 'microscopy', 'neural', 'neurons', 'axons', 'microscope', 'brain', 'imaging', 'axon']","[""Anisotropic path searching for automatic neuron reconstruction Full reconstruction of neuron morphology is of fundamental interest for the analysis and understanding of their functioning. We have developed a novel method capable of automatically tracing neurons in three-dimensional microscopy data. In contrast to template-based methods, the proposed approach makes no assumptions about the shape or appearance of neurite structure. Instead, an efficient seeding approach is applied to capture complex neuronal structures and the tracing problem is solved by computing the optimal reconstruction with a weighted graph. The optimality is determined by the cost function designed for the path between each pair of seeds and by topological constraints defining the component interrelations and completeness. In addition, an automated neuron comparison method is introduced for performance evaluation and structure analysis. The proposed algorithm is computationally efficient and has been validated using different types of microscopy data sets including Drosophila's projection neurons and fly neurons with presynaptic sites. In all cases, the approach yielded promising results. (C) 2011 Elsevier B.V. All rights reserved."", 'Large-scale automatic reconstruction of neuronal processes from electron microscopy images Automated sample preparation and electron microscopy enables acquisition of very large image data sets. These technical advances are of special importance to the field of neuroanatomy, as 3D reconstructions of neuronal processes at the nm scale can provide new insight into the fine grained structure of the brain. Segmentation of large-scale electron microscopy data is the main bottleneck in the analysis of these data sets. In this paper we present a pipeline that provides state-of-the art reconstruction performance while scaling to data sets in the GB-TB range. First, we train a random forest classifier on interactive sparse user annotations. The classifier output is combined with an anisotropic smoothing prior in a Conditional Random Field framework to generate multiple segmentation hypotheses per image. These segmentations are then combined into geometrically consistent 3D objects by segmentation fusion. We provide qualitative and quantitative evaluation of the automatic segmentation and demonstrate large-scale 3D reconstructions of neuronal processes from a 27, 000 mu m(3) volume of brain tissue over a cube of 30 mu m in each dimension corresponding to 1000 consecutive image sections. We also introduce Mojo, a proofreading tool including semi-automated correction of merge errors based on sparse user scribbles. (C) 2015 Elsevier B.V. All rights reserved.', '3D axon structure extraction and analysis in confocal fluorescence microscopy images The morphological properties of axons, such as their branching patterns and oriented structures, are of great interest for biologists in the study of the synaptic connectivity of neurons. In these studies, researchers use triple immunofluorescent confocal microscopy to record morphological changes of neuronal processes. Three-dimensional (3D) microscopy image analysis is then required to extract morphological features of the neuronal structures. In this article, we propose a highly automated 3D centerline extraction tool to assist in this task. For this project, the most difficult part is that some axons are overlapping such that the boundaries distinguishing them are barely visible. Our approach combines a 3D dynamic programming (DP) technique and marker-controlled watershed algorithm to solve this problem. The approach consists of tracking and updating along the navigation directions of multiple axons simultaneously. The experimental results show that the proposed method can rapidly and accurately extract multiple axon centerlines and can handle complicated axon structures such as cross-over sections and overlapping objects.']"
130,119,130_optimization_algorithms_adaptive_evolutionary,"['optimization', 'algorithms', 'adaptive', 'evolutionary', 'algorithm', 'optimal', 'optima', 'evolution', 'multiobjective', 'genetic']","['Set-based many-objective optimization guided by a preferred region Set-based evolutionary optimization based on performance indicators is one of effective methods to solve many objective optimization problems. However, preference information of a high-dimensional objective space has not yet been fully used to guide the evolution of a population. In this paper, we propose a set-based many objective evolutionary algorithm guided by a preferred region. In the set-based evolution, the preferred region of a high-dimensional objective space is dynamically determined, a selection Strategy on sets by combining the Pareto dominance on sets with the above preferred region is designed, and the crossover operators on sets guided by the above preferred region are developed to produce a Pareto front with superior performances. The proposed method is applied to four benchmark many-objective optimization problems and a real-world engineering design optimization problem, and the experimental results empirically demonstrate its effectiveness.', 'An improved multi-objective evolutionary algorithm based on environmental and history information Proximity and diversity are two basic issues in multi-objective optimization problems. However, it is hard to optimize them simultaneously, especially when tackling problems with complicated Pareto fronts and Pareto sets. To make a better performance of multi-objective optimization evolutionary algorithm, the environmental information and history information are used to generate better offsprings. The conception of locality and reference front is introduced to improve the diversity. Adaptation mechanism of evolutionary operator is proposed to solve searching issue during different stages in evolutionary process. Based on these improvement, an improved multi-objective evolutionary algorithm based on environmental and history information (MOEA-EHI) is presented. The performance of our proposed method is validated based inverted generation distance (IGD) and compared with three state-of-the-art algorithms on a number of unconstrained benchmark problems. Empirical results fully demonstrate the superiority of our proposed method on complicated benchmarks.', 'NEW EVOLUTIONARY GENETIC ALGORITHMS FOR NP-COMPLETE COMBINATORIAL OPTIMIZATION PROBLEMS Evolutionary genetic algorithms have been proposed to solve NP-complete combinatorial optimization problems. A new crossover operator based on group theory has been created. Computational processes motivated by proposed evolutionary genetic algorithms were described as stochastic processes, using population dynamics and interactive markovian chains. The proposed algorithms were used in solving flowshop problems and an asymmetric traveling salesman problem. The experimental results showed the superiority of new evolutionary algorithms in comparison with the standard genetic algorithm.']"
131,118,131_bipolar_psychiatric_disorder_depressive,"['bipolar', 'psychiatric', 'disorder', 'depressive', 'disorders', 'mania', 'moodswings', 'manic', 'depression', 'analyses']","['Classification of bipolar disorder episodes based on analysis of voice and motor activity of patients There is growing amount of scientific evidence that motor activity is the most consistent indicator of bipolar disorder. Motor activity includes several areas such as body movement, motor response time, level of psychomotor activity, and speech related motor activity. Studies of motor activity in bipolar disorder have typically used self-reported questionnaires with clinical observer-rated scales, which are therefore subjective and have often limited effectiveness. Motor activity information can be used to classify epiaide type in bipolar patients, which is highly relevant, since severe depression and manic states can result in mortality. This paper introduces a system able to classify the state of patients suffering from bipolar disorder using sensed information from smartphones. We collected audio, accelerometer and self-assessment data from five patients over a time-period of 12 weeks during their real-life activities. In this research we evaluated the performance of several classifiers, different sets of features and the role of the questionnaires for classifying bipolar disorder episodes. In particular, we have shown that it is possible to classify with high confidence (approximate to 15%) the course of mood episodes or relapse in bipolar patients. To our knowledge, no research to date has focused on naturalistic observation of day-to-day phone conversation to classify impaired life functioning in individuals with bipolar disorder. (C) 2016 Elsevier B.V. All rights reserved.', 'Can machine learning identify childhood characteristics that predict future development of bipolar disorder a decade later? Early identification of bipolar disorder may provide appropriate support and treatment, however there is no current evidence for statistically predicting whether a child will develop bipolar disorder. Machine learning methods offer an opportunity for developing empirically-based predictors of bipolar disorder. This study examined whether bipolar disorder can be predicted using clinical data and machine learning algorithms. 492 children, ages 6-18 at baseline, were recruited from longitudinal case-control family studies. Participants were assessed at baseline, then followed-up after 10 years. In addition to sociodemographic data, children were assessed with psychometric scales, structured diagnostic interviews, and cognitive and social functioning as-sessments. Using the Balanced Random Forest algorithm, we examined whether the diagnostic outcome of full or subsyndromal bipolar disorder could be predicted from baseline data. 45 children (10%) developed bipolar disorder at follow-up. The model predicted subsequent bipolar disorder with 75% sensitivity, 76% specificity, and an Area Under the Receiver Operating Characteristics of 75%. Predictors best differentiating between children who did or did not develop bipolar disorder were the Child Behavioral Checklist Externalizing and Internalizing behaviors, the Child Behavioral Checklist Total t-score, problematic school functions indexed through the Child Behavioral Checklist School Competence scale, and the Child Behavioral Checklist Anxiety/ Depression and Aggression scales. Our study provides the first quantitative model to predict bipolar disorder. Longitudinal prediction may help clinicians assess children with emergent psychopathology for future risk of bipolar disorder, an area of clinical and scientific importance. Machine learning algorithms could be imple-mented to alert clinicians to risk for bipolar disorder.', 'Critical Predictors for the Early Detection of Conversion From Unipolar Major Depressive Disorder to Bipolar Disorder: Nationwide Population-Based Retrospective Cohort Study Background: Unipolar major depressive disorder (MDD) and bipolar disorder are two major mood disorders. The two disorders have different treatment strategies and prognoses. However, bipolar disorder may begin with depression and could be diagnosed as MDD in the initial stage, which may later contribute to treatment failure. Previous studies indicated that a high proportion of patients diagnosed with MDD will develop bipolar disorder over time. This kind of hidden bipolar disorder may contribute to the treatment resistance observed in patients with MDD. Conclusions: The CART method identified five variables as significant predictors of bipolar disorder conversion. In a simple two- to four-step process, these variables permit the identification of patients with low, intermediate, or high risk of bipolar disorder conversion. The developed model can be applied to routine clinical practice for the early diagnosis of bipolar disorder. Methods: We conducted a retrospective cohort study involving patients who were newly diagnosed with MDD between January 1, 2000, and December 31, 2004, by using the Taiwan National Health Insurance Research Database. All patients with depression were observed until (1) diagnosis of bipolar disorder by a psychiatrist, (2) death, or (3) December 31, 2013. All patients with depression were divided into the following two groups, according to whether bipolar disorder was diagnosed during the follow-up period: converted group and nonconverted group. Six groups of variables within the first 6 months of enrollment, including personal characteristics, physical comorbidities, psychiatric comorbidities, health care usage behaviors, disorder severity, and psychotropic use, were extracted and were included in a classification and regression tree (CART) analysis to generate a risk stratification model for MDD-to-bipolar disorder conversion. Objective: In this population-based study, our aim was to investigate the rate and risk factors of a diagnostic change from unipolar MDD to bipolar disorder during a 10-year follow-up. Furthermore, a risk stratification model was developed for MDD-to-bipolar disorder conversion. Results: Our study enrolled 2820 patients with MDD. During the follow-up period, 536 patients were diagnosed with bipolar disorder (conversion rate=19.0%). The CART method identified five variables (kinds of antipsychotics used within the first 6 months of enrollment, kinds of antidepressants used within the first 6 months of enrollment, total psychiatric outpatient visits, kinds of benzodiazepines used within one visit, and use of mood stabilizers) as significant predictors of the risk of bipolar disorder conversion. This risk CART was able to stratify patients into high-, medium-, and low-risk groups with regard to bipolar disorder conversion. In the high-risk group, 61.5%-100% of patients with depression eventually developed bipolar disorder. On the other hand, in the low-risk group, only 6.4%-14.3% of patients with depression developed bipolar disorder.']"
132,117,132_cerebrospinal_cerebrovascular_intracranial_cerebral,"['cerebrospinal', 'cerebrovascular', 'intracranial', 'cerebral', 'brain', 'pressure', 'hypertension', 'icp', 'cranial', 'arterial']","['Improved Noninvasive Intracranial Pressure Assessment With Nonlinear Kernel Regression The only established technique for intracranial pressure (ICP) measurement is an invasive procedure requiring surgically penetrating the skull for placing pressure sensors. However, there are many clinical scenarios where a noninvasive assessment of ICP is highly desirable. With an assumption of a linear relationship among arterial blood pressure (ABP), ICP, and flow velocity (FV) of major cerebral arteries, an approach has been previously developed to estimate ICP noninvasively, the core of which is the linear estimation of the coefficients f between ABP and ICP from the coefficients w calculated between ABP and FV. In this paper, motivated by the fact that the relationships among these three signals are so complex that simple linear models may be not adequate to depict the relationship between these two coefficients, i.e., f and w, we investigate the adoption of several nonlinear kernel regression approaches, including kernel spectral regression (KSR) and support vector machine (SVM) to improve the original linear ICP estimation approach. The ICP estimation results on a dataset consisting of 446 entries from 23 patients show that the mean ICP error by the nonlinear approaches can be reduced to below 6.0 mmHg compared to 6.7 mmHg of the original approach. The statistical test also demonstrates that the ICP error by the proposed nonlinear kernel approaches is statistically smaller than that estimated with the original linear model (p < 0.05). The current result confirms the potential of using nonlinear regression to achieve more accurate noninvasive ICP assessment.', 'A Spectral Approach to Model-Based Noninvasive Intracranial Pressure Estimation Background: Intracranial pressure (ICP) normally ranges from 5 to 15 mmHg. Elevation in ICP is an important clinical indicator of neurological injury, and ICP is therefore monitored routinely in several neurological conditions to guide diagnosis and treatment decisions. Current measurement modalities for ICP monitoring are highly invasive, largely limiting the measurement to critically ill patients. An accurate noninvasive method to estimate ICP would dramatically expand the pool of patients that could benefit from this cranial vital sign. Methods: This article presents a spectral approach to model-based ICP estimation from arterial blood pressure (ABP) and cerebral blood flow velocity (CBFV) measurements. The model captures the relationship between the ABP, CBFV, and ICP wave-forms and utilizes a second-order model of the cerebral vasculature to estimate ICP. Results: The estimation approach was validated on two separate clinical datasets, one recorded from thirteen pediatric patients with a total duration of around seven hours, and the other recorded from five adult patients, one hour and 48 minutes in total duration. The algorithm was shown to have an accuracy (mean error) of 0.4 mmHg and -1.5 mmHg, and a precision (standard deviation of the error) of 5.1 mmHg and 4.3 mmHg, in estimating mean ICP (range of 1.3 mmHg to 24.8 mmHg) on the pediatric and adult data, respectively. These results are comparable to previous results and within the clinically relevant range. Additionally, the accuracy and precision in estimating the pulse pressure of ICP on a beat-by-beat basis were found to be 1.3 mmHg and 2.9 mmHg respectively. Conclusion: These contributions take a step towards realizing the goal of implementing a real-time noninvasive ICP estimation modality in a clinical setting, to enable accurate clinical-decision making while overcoming the drawbacks of the invasive ICP modalities.', 'Pseudo-Bayesian Model-Based Noninvasive Intracranial Pressure Estimation and Tracking Objective: A noninvasive intracranial pressure (ICP) estimation method is proposed that incorporates a model-based approach within a probabilistic framework to mitigate the effects of data and modeling uncertainties. Methods: A first-order model of the cerebral vasculature relates measured arterial blood pressure (ABP) and cerebral blood flow velocity (CBFV) to ICP. The model is driven by the ABP waveform and is solved for a range of mean ICP values to predict the CBFV waveform. The resulting errors between measured and predicted CBFV are transformed into likelihoods for each candidate ICP in two steps. First, a baseline ICP estimate is established over five data windows of 20 beats by combining the likelihoods with a prior distribution of the ICP to yield an a posteriori distribution whose median is taken as the baseline ICP estimate. A single-state model of cerebral autoregulatory dynamics is then employed in subsequent data windows to track changes in the baseline by combining ICP estimates obtained with a uniform prior belief and model-predicted ICP. For each data window, the estimated model parameters are also used to determine the ICP pulse pressure. Results: On a dataset of thirteen pediatric patients with a variety of pathological conditions requiring invasive ICP monitoring, the method yielded for mean ICP estimation a bias (mean error) of 0.6 mmHg and a root-mean-squared error of 3.7 mmHg. Conclusion: These performance characteristics are well within the acceptable range for clinical decision making. Significance: The method proposed here constitutes a significant step towards robust, continuous, patient-specific noninvasive ICP determination.']"
133,115,133_clustering_multiview_cluster_datasets,"['clustering', 'multiview', 'cluster', 'datasets', 'grouping', 'views', 'view', 'multi', 'framework', 'matrices']","['Multi-view clustering via pairwise sparse subspace representation Multi-view clustering, which aims to cluster datasets with multiple sources of information, has a wide range of applications in the communities of data mining and pattern recognition. Generally, it makes use of the complementary information embedded in multiple views to improve clustering performance. Recent methods usually find a low-dimensional embedding of multi-view data, but often ignore some useful prior information that can be utilized to better discover the latent group structure of multi-view data. To alleviate this problem, a novel pairwise sparse subspace representation model for multi-view clustering is proposed in this paper. The objective function of our model mainly includes two parts. The first part aims to harness prior information to achieve a sparse representation of each high-dimensional data point with respect to other data points in the same view. The second part aims to maximize the correlation between the representations of different views. An alternating minimization method is provided as an efficient solution for the proposed multi-view clustering algorithm. A detailed theoretical analysis is also conducted to guarantee the convergence of the proposed method. Moreover, we show that the must-link and cannot-link constraints can be naturally integrated into the proposed model to obtain a link constrained multi-view clustering model. Extensive experiments on five real world datasets demonstrate that the proposed model performs better than several state-of-the-art multi-view clustering methods. (C) 2015 Elsevier B.V. All rights reserved.', 'Robust multi-view data clustering with multi-view capped-norm K-means Real-world data sets are often comprised of multiple representations or views which provide different and complementary aspects of information. Multi-view clustering is an important approach to analyze multi-view data in a unsupervised way. Previous studies have shown that better clustering accuracy can be achieved using integrated information from all the views rather than just relying on each view individually. That is, the hidden patterns in data can be better explored by discovering the common latent structure shared by multiple views. However, traditional multi-view clustering methods are usually sensitive to noises and outliers, which greatly impair the clustering performance in practical problems. Furthermore, existing multi-view clustering methods, e.g. graph-based methods, are with high computational complexity due to the kernel/affinity matrix construction or the eigendecomposition. To address these problems, we propose a novel robust multi-view clustering method to integrate heterogeneous representations of data. To make our method robust to the noises and outliers, especially the extreme data outliers, we utilize the capped-norm loss as the objective. The proposed method is of low complexity, and in the same level as the classic K-means algorithm, which is a major advantage for unsupervised learning. We derive a new efficient optimization algorithm to solve the multi-view clustering problem. Finally, extensive experiments on benchmark data sets show that our proposed method consistently outperforms the state-of-the-art clustering methods. (C) 2018 Elsevier B.V. All rights reserved.', 'Orthogonal multi-view tensor-based learning for clustering Multi-view spectral clustering aims to improve the performance of spectral clustering through multiview data. Many multi-view spectral clustering methods have been proposed recently and achieved promising performance. Among these methods, most of them are designed to pursue numerical consistency in multi-view similarity matrices. However, each similarity matrix has its unique statistic distribution, which makes it not appropriate to seek numerical consistency in multi-view similarity matrices or directly average the multi-view similarity matrices. To overcome the aforementioned problem, we propose a novel Orthogonal Multi-view Tensor-based Learning for clustering, abbreviated as OMTL. Specifically, OMTL introduces an orthogonal matrix factorization to eliminate the view-specific statistic distribution and preserve the intrinsic clustering structure of each view, which fully considers the consensus information contained in multiple views to boost multi-view spectral clustering performance. Further, we employ a low-rank tensor constraint to explore the high order correlations among multiple views. By designing an alternating direction method of multipliers (ADMM) based optimization algorithm, the intrinsic similarity matrix of multi-view data can be efficiently learned for spectral clustering. Extensive experiments on several benchmark datasets have illustrated the superior clustering performance of the proposed method compared to several state-of-the-art multi-view clustering methods. (C) 2022 Published by Elsevier B.V.']"
134,115,134_alcoholics_alcoholism_alcoholic_alcohol,"['alcoholics', 'alcoholism', 'alcoholic', 'alcohol', 'ethanol', 'addicts', 'drinking', 'drinkers', 'addictive', 'addiction']","['EEG Analysis of Working Memory Between Sober State and Intoxicated State More and more people are exposed to drinking and in addicted. In recent years, Electroencephalography (EEG) technology has been used to diagnose the effects of alcohol on brain structure and functions. Since the brain contains a variety of different functions, it is difficult to explore the effects of alcohol on a certain cognitive function by single tasks to induce EEG signals. Additionally, alcohol has an effect on the performance of the working memory (WM) which is particularly susceptible to external stimulus and recovering in the short-term. This study investigates the differences of the EEG signals on the WM-load before and after alcohol intake by using the working memory tasks. Ten participants take part in the N-back experiments with taking alcohol. After preprocessing the EEG signals, seven different features are selected to classify the different WM-load levels, and these features are also used to distinguish the states whether in drinking or not. At last, the support vector machine (SVM) is applied for the classification and the accuracies for some subjects can achieve 100% in the time domain. This work not only provides a new way to explore the effects of alcohol on the specific functions of the brain but also indicates that mild alcohol consumption could alter the perception of the brain on working memory load and reduce the WM-load level.', 'Inhibitory-control event-related potentials correlate with individual differences in alcohol use Impulsivity is a multidimensional construct that is related to different aspects of alcohol use, abuse, and dependence. Inhibitory control, one facet of impulsivity, can be assayed using the stop-signal task (SST) and quantified behaviorally via the stop-signal reaction time (SSRT) and electrophysiologically using event-related potentials (ERPs). Research on the relationship between alcohol use and SSRTs, and between alcohol use and inhibitory-control ERPs, is mixed. Here, adult alcohol users (n = 79), with a wide range of scores on the Alcohol Use Disorders Identification Test (AUDIT), completed the SST under electroencephalography (EEG) (70% of participants had AUDIT total scores greater than or equal to 8). Other measures, including demographic, self-report, and task-based measures of impulsivity, personality, and psychological factors, were also recorded. A machine-learning method with penalized linear regression was used to correlate individual differences in alcohol use with impulsivity measures. Four separate models were tested, with out-of-sample validation used to quantify performance. ERPs alone statistically predicted alcohol use (cross-validated r = 0.28), with both early and late ERP components contributing to the model (larger N2, but smaller P3, amplitude). Behavioral data from a wide range of impulsivity measures were also associated with alcohol use (r = 0.37). SSRT was a relatively weak statistical predictor, whereas the Stroop interference effect was relatively strong. The addition of nonimpulsivity behavioral measures did not improve the correlation (r = 0.34) and was similar when ERPs were combined with non-ERP data (r = 0.29). These findings show that inhibitory control ERPs are robustly correlated individual differences in alcohol use.', 'Resting state connectivity best predicts alcohol use severity in moderate to heavy alcohol users Background: In the United States, 13% of adults are estimated to have alcohol use disorder (AUD). Most studies examining the neurobiology of AUD treat individuals with this disorder as a homogeneous group; however, the theories of the neurocircuitry of AUD call for a quantitative and dimensional approach. Previous imaging studies find differences in brain structure, function, and resting-state connectivity in AUD, but few use a multimodal approach to understand the association between severity of alcohol use and the brain differences. Conclusions: These findings indicate that the neural effects of AUD vary according to severity. Our results emphasize the utility of resting state fMRI as a neuroimaging biomarker for quantitative clinical evaluation of AUD. Methods: Adults (ages 22-60) with problem drinking patterns (n = 59) completed a behavioral and neuroimaging protocol at the National Institutes of Health. Alcohol severity was quantified with the Alcohol Use Disorders Identification Test (AUDIT). In a 3 T MRI scanner, participants underwent a structural MRI as well as restingstate, monetary incentive delay, and face matching fMRI scans. Machine learning was applied and trained using the neural data from MRI scanning. The model was tested for generalizability in a validation sample (n = 24). Results: The resting state-connectivity features model best predicted AUD severity in the naive sample, compared to task fMRI, structural MRI, combined MRI features, or demographic features. Network connectivity features between salience network, default mode network, executive control network, and sensory networks explained 33% of the variance associated with AUDIT in this model.']"
135,114,135_identification_identity_adaptive_reid,"['identification', 'identity', 'adaptive', 'reid', 'attention', 'dataset', 'features', 'id', 'feature', 'viewpoint']","['Person re-identification with activity prediction based on hierarchical spatial-temporal model Person re-identification (re-id) across cameras remains a very challenging problem, especially when the wide range searching exists in a multi-camera surveillance network. Current person re-identification methods focus on using visual model to search the specified person. In fact, in practical applications, due to the large-scale search range, the searching way only relying on visual model is not efficient. Moreover, the recall ability of visual model usually is limited in large-scale searching, because it does not consider the spatial-temporal information of person. However, the current public re-id datasets only include the visual samples. To address this problem, in this work, we collect a large-scale re-id dataset, PKU-SVD-B-REID, which includes both visual and spatial-temporal information of over 133 K samples. Then, we propose a novel person re-id framework, named Hierarchical Spatial-Temporal Model (HSTM), which can effectively predict the person activity path and reduce the search range in the real multiple cameras surveillance system. Extensive experiments on PKU-SVD-B-REID validate the superiority of our method over conventional re-id methods based on only visual information in terms of both efficiency and accuracy. (C) 2017 Elsevier B.V. All rights reserved.', 'Learning Domain-Specific Features From General Features for Person Re-Identification Person re-identification (re-id) plays a vital role in surveillance and forensics application. Since the labeled images for person re-id task is limited, the generalization ability of existed person re-id models is poor. On the other hand, images of different classes (pedestrian and non-pedestrian images) share some general features. To this end, this paper aims to improve the performance of person re-id by designing a relearning network which can learn domain-specific features and general features simultaneously. The proposed relearning network consists of a pretrained backbone network which provides the general features, and several attention-based subnetworks that learn domain-specific features from general features of different levels. Besides, we propose a coarse-fine loss to improve the generalization of person re-id model by making full use of the massive labeled non-pedestrian images. Experimental results on the publicly available Market-1501, DukeMTMC-reID and CUHK03 pedestrian re-id datasets demonstrate the effectiveness of the proposed relearning network and coarse-fine loss.', 'Combining multilevel feature extraction and multi-loss learning for person re-identification The goal of person re-identification (re-id) is to match images of the same person captured by multiple cameras with non-overlapping views. It is a challenging task due to the large spatial displacement and human pose change of person images across different views. Recently, the deep Convolutional Neural Network (CNN) has significantly improved the performance of person re-id. In this paper, we present a hybrid deep model that combines multilevel feature extraction and multi-loss learning for more robust pedestrian descriptors. The multi-loss function jointly optimizes the verification task that aims to verify if two images belong to same person, and the recognition task that aims to predict the identity of each image. Specifically, given two person images, we first apply a deep learning network, called Feature Aggregation Network (FAN), to extract their multilevel CNN features by fusing the information of different layers. For the verification task, a Recurrent Comparative Network (RCN) is presented to learn joint representation of paired CNN features. RCN determines whether two images depict the same person through focusing on discriminative regions and alternatively comparing their appearance. It is an algorithmic imitation of human decision-making process, in which a person repeatedly compares two objects before making decision about their similarity. For the recognition task, a parameter-free operation termed Global Average Pooling (GAP) is followed after each CNN feature to extract identity-related features. Extensive experiments are conducted on four datasets, including CUHK03, CUHK01, Market1501 and DukeMTMC, and the experimental results demonstrate the effectiveness of our presented method. (C) 2019 Elsevier B.V. All rights reserved.']"
136,114,136_prosthesis_prosthetics_prosthetic_stimulation,"['prosthesis', 'prosthetics', 'prosthetic', 'stimulation', 'wrist', 'amputation', 'proprioceptive', 'limbs', 'prostheses', 'hand']","['A Review of Non-Invasive Sensory Feedback Methods for Transradial Prosthetic Hands Any implant or prosthesis replacing a function or functions of an organ or group of organs should be biologically and sensorily integrated with the human body in order to increase their acceptance with their user. If this replacement is for a human hand, which is an important interface between humans and their environment, the acceptance issue and developing sensory-motor embodiment will be more challenging. Despite progress in prosthesis technologies, 50-60% of hand amputees wear a prosthetic device. One primary reason for the rejection of the prosthetic hands is that there is no or negligibly small feedback or tactile sensation from the hand to the user, making the hands less functional. In fact, the loss of a hand means interrupting the closed-loop sensory feedback between the brain (motor control) and the hand (sensory feedback through the nerves). The lack of feedback requires significant cognitive efforts from the user in order to do basic gestures and daily activities. To this aim, recently, there has been significant development in the provision of sensory feedback from transradial prosthetic hands, to enable the user take part in the control loop and improve user embodiment. Sensory feedback to the hand users can be provided via invasive and non-invasive methods. The latter includes the use of temperature, vibration, mechanical pressure and skin stretching, electrotactile stimulation, phantom limb stimulation, audio feedback, and augmented reality. This paper provides a comprehensive review of the non-invasive methods, performs their critical evaluation, and presents challenges and opportunities associated with the non-invasive sensory feedback methods.', ""Longitudinal Case Study of Regression-Based Hand Prosthesis Control in Daily Life Hand prostheses are usually controlled by electromyographic (EMG) signals from the remnant muscles of the residual limb. Most prostheses used today are controlled with very simple techniques using only two EMG electrodes that allow to control a single prosthetic function at a time only. Recently, modern prosthesis controllers based on EMG classification, have become clinically available, which allow to directly access more functions, but still in a sequential manner only. We have recently shown in laboratory tests that a regression-based mapping from EMG signals into prosthetic control commands allows for a simultaneous activation of two functions and an independent control of their velocities with high reliability. Here we aimed to study how such regression-based control performs in daily life in a two-month case study. The performance is evaluated in functional tests and with a questionnaire at the beginning and the end of this phase and compared with the participant's own prosthesis, controlled with a classical approach. Already 1 day after training of the regression model, the participant with transradial amputation outperformed the performance achieved with his own Michelangelo hand in two out of three functional metrics. No retraining of the model was required during the entire study duration. During the use of the system at home, the performance improved further and outperformed the conventional control in all three metrics. This study demonstrates that the high fidelity of linear regression-based prosthesis control is not restricted to a laboratory environment, but can be transferred to daily use."", ""Factors Associated With Prosthesis Embodiment and Its Importance for Prosthetic Satisfaction in Lower Limb Amputees Perceptual integration of a prosthesis into an amputee's body representation, that is, prosthesis embodiment, has been proposed to be a major goal of prosthetic treatment, potentially contributing to the user's satisfaction with the device. However, insufficient knowledge about individual or prosthetic factors associated with prosthesis embodiment challenges basic as well as rehabilitation research. In the present study, hierarchical multiple regression analyses on prosthesis embodiment-as assessed with the recently introduced Prosthesis Embodiment Scale-were applied to the survey data of a large sample of prosthesis-using lower limb amputees, entering relevant objective-descriptive (i.e., unbiased characteristics of the amputation or the prosthesis) and subjective-evaluative variables (i.e., the amputee's perceptions related to the amputation or the prosthesis) as first- or second-level regressors, respectively. Significant regressors identified in these analyses together explained R-2 = 36.3% of prosthesis embodiment variance in the present sample, with a lower level of amputation, less intense residual limb pain, more realistic visual appearance of the device, higher prosthetic mobility, and more positive valence of prosthesis-induced residual limb stimulations representing significantly associated factors. Using the identical set of regressors hierarchically complemented by prosthesis embodiment on measures of prosthetic satisfaction-as assessed with the Trinity Amputation and Prosthesis Experience Scales-revealed that prosthesis embodiment was significantly and positively associated with aesthetic as well as functional prosthesis satisfaction. These findings emphasize the importance of psychological factors for the integration of a prosthesis into the amputee's body representation, which itself represents a crucial factor associated with prosthesis satisfaction. The results might have important implications for future prosthetic treatment; however, replication of the findings in an independent sample is required, as well as sophisticated experimental designs in order to elucidate the causality of effects.""]"
137,113,137_spinal_robotics_robotic_neurosurgery,"['spinal', 'robotics', 'robotic', 'neurosurgery', 'neurosurgical', 'spine', 'surgical', 'surgeons', 'robots', 'surgery']","['Spinal Robotics: Current Applications and Future Perspectives Even though robotic technology holds great potential for performing spinal surgery and advancing neurosurgical techniques, it is of utmost importance to establish its practicality and to demonstrate better clinical outcomes compared with traditional techniques, especially in the current cost-effective era. Several systems have proved to be safe and reliable in the execution of tasks on a routine basis, are commercially available, and are used for specific indications in spine surgery. However, workflow, usability, interdisciplinary setups, efficacy, and cost-effectiveness have to be proven prospectively. This article includes a short description of robotic structures and workflow, followed by preliminary results of a randomized prospective study comparing conventional free-hand techniques with routine spine navigation and robotic-assisted procedures. Additionally, we present cases performed with a spinal robotic device, assessing not only the accuracy of the robotic-assisted procedure but also other factors (eg, minimal invasiveness, radiation dosage, and learning curves). Currently, the use of robotics in spinal surgery greatly enhances the application of minimally invasive procedures by increasing accuracy and reducing radiation exposure for patients and surgeons compared with standard procedures. Second-generation hardware and software upgrades of existing devices will enhance workflow and intraoperative setup. As more studies are published in this field, robot-assisted therapies will gain wider acceptance in the near future.', 'Navigation and Robotics in Spinal Surgery: Where Are We Now? Spine surgery has experienced much technological innovation over the past several decades. The field has seen advancements in operative techniques, implants and biologics, and equipment such as computer-assisted navigation and surgical robotics. With the arrival of real-time image guidance and navigation capabilities along with the computing ability to process and reconstruct these data into an interactive three-dimensional spinal """"map"""", so too have the applications of surgical robotic technology. While spinal robotics and navigation represent promising potential for improving modern spinal surgery, it remains paramount to demonstrate its superiority as compared to traditional techniques prior to assimilation of its use amongst surgeons. Spine surgery relies upon meticulous fine motor skills to manipulate neural elements and a steady hand while doing so, often exploiting small working corridors utilizing exposures that minimize collateral damage. Additionally, the procedures may be long and arduous, predisposing the surgeon to both mental and physical fatigue. In light of these characteristics, spine surgery may actually be an ideal candidate for the integration of navigation and robotic-assisted procedures. The applications for intraoperative navigation and image-guided robotics have expanded to surgical resection of spinal column and intradural tumors, revision procedures on arthrodesed spines, and deformity cases with distorted anatomy. Additionally, these platforms may mitigate much of the harmful radiation exposure in minimally invasive surgery to which the patient, surgeon, and ancillary operating room staff are subjected. With this paper, we aim to critically evaluate the current literature and explore the options available for intraoperative navigation and robotic-assisted spine surgery.', 'Robotic Spine Surgery: Current State in Minimally Invasive Surgery Although robotic application in spine surgery has been gradual, the past decade has seen the arrival of several novel robotic systems for spinal procedures, suggesting the evolution of technology capable of augmenting surgical ability. Conclusion: Methods: Narrative review. Objectives: Results: Robotic systems in spinal surgery may offer potential benefits for both patients and surgeons. In this article, the authors explore the future prospects and current limitations of robotic systems in minimally invasive spine surgery. Spine surgery is well positioned to benefit from robotic assistance and automation. Paired with enhanced navigation technologies, robotic systems have tremendous potential to supplement the skills of spine surgeons, improving patient safety and outcomes while limiting complications and costs. Study Design: We describe recent developments in robotic spine surgery and minimally invasive spine surgery. Institutional review board approval was not needed.']"
138,112,138_spammers_social_spam_popularity,"['spammers', 'social', 'spam', 'popularity', 'tweets', 'tweet', 'facebook', 'posting', 'networks', 'popular']","['Co-detecting social spammers and spam messages in microblogging via exploiting social contexts Microblogging websites, such as Twitter, have become popular platforms for information dissemination and sharing. However, they are also full of spammers who frequently conduct social spamming on them. Massive social spammers and spam messages heavily hurt the user experience and hinder the healthy development of microblogging systems. Thus, effectively detecting the social spammers and spam messages is of great value to both microblogging users and websites. Existing studies usually treat social spammer detection and spam message detection as two separate tasks. However, social spammers and spam messages have strong inherent connections, since social spammers tend to post more spam messages and spam messages have high probabilities to be posted by social spammers. Thus combining social spammer detection with spam message detection has the potential to boost the performance of both tasks. In this paper, we propose a unified approach for social spammer and spam message co-detection in microblogging. Our approach utilizes the posting relations between users and messages to combine social spammer detection with spam message detection. In addition, we extract the social relations between users and the connections between messages to refine detection results. We regard these social contexts as the graph structure over the detection results and incorporate them into our approach as regularization terms. Besides, we introduce an efficient optimization algorithm to solve the model of our approach and propose an accelerated method to tackle the most time-consuming step. Extensive experiments on a real-world microblog dataset demonstrate that our approach can improve the performance of both social spammer detection and spam message detection effectively and efficiently. (C) 2016 Elsevier B.V. All rights reserved.', ""Online social support for young people: Does it recapitulate in-person social support; can it help? As social media websites have grown in popularity, public concern about online victimization has grown as well; however, much less attention has focused on the possible beneficial effects of online social networks. If theory and research about in-person social networks pertain, then online social relationships may represent an important modern source of or vehicle for support. In a study of 231 undergraduates, three major findings emerged: (1) for people with weaker in-person social support, social media sites provide a source of social support that is less redundant of the social support they receive in person; (2) in ways that were not redundant of each other, both online and in-person social support were associated with lower levels of depression-related thoughts and feelings, and (3) the beneficial effects of online social support (like in-person social support) offset some of the adverse effects of peer victimization. The study suggests that augmenting social relations via strategic use of social media can enhance young people's social support systems in beneficial ways. (C) 2016 Elsevier Ltd. All rights reserved."", 'Detection of spam-posting accounts on Twitter Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data. (c) 2018 The Authors. Published by Elsevier B.V.']"
139,112,139_agenttest_agents_coordination_agent,"['agenttest', 'agents', 'coordination', 'agent', 'multiagent', 'cooperation', 'strategies', 'role', 'cooperative', 'capabilities']","[""Role and member selection in team formation using resource estimation for large-scale multi-agent systems We propose an efficient team formation method for multi-agent systems consisting of self-interested agents in task-oriented domains where agents have no prior knowledge of the resources/abilities of the other agents. Internet services based on services computing and cloud computing, which have been rapidly increasing, are usually achieved by combining a number of service elements that are distributed over the Internet. We modelled the executions of these elements as teams of agents with the resources and abilities required in the corresponding service elements. This team formation method with the appropriate agents for the service elements makes the entire system efficient. Our proposed method is based on our previous parameter learning method that enables agents to identify their roles in forming a team but requires prior knowledge of all others' resources. This restricts the applicability to real systems. The contribution of this paper is twofold. First, we extended our original method by adding a resource estimation method. Second, we further improved the first extension for large scale multi-agent systems by introducing purviews, which are a relatively small set of agents that are potential members of the teams, for practical computational time and required memory size. We experimentally evaluated our first method by comparing it with the previous method and the task allocation using the contract net protocol (CNP). Then, after increasing the number of agents, we evaluated our second extended method and investigated how the number of agents and the size of the purview affected the overall performances. Results showed that the learning speed was faster in the proposed method so it outperformed other methods in a practical sense even though it did not require prior knowledge of resources in other agents in busy, large-scale, multi-agent systems. (C) 2014 Elsevier B.V. All rights reserved."", 'Learning collaboration strategies for committees of learning agents A main issue in cooperation in multi-agent systems is how an agent decides in which situations is better to cooperate with other agents, and with which agents does the agent cooperate. Specifically in this paper we focus on multi-agent systems composed of learning agents, where the goal of the agents is to achieve a high accuracy on predicting the correct solution of the problems they encounter. For that purpose, when encountering a new problem each agent has to decide whether to solve it individually or to ask other agents for collaboration. We will see that learning agents can collaborate forming committees in order to improve performance. Moreover, in this paper we will present a proactive learning approach that will allow the agents to learn when to convene a committee and with which agents to invite to join the committee. Our experiments show that learning results in smaller committees while maintaining (and sometimes improving) the problem solving accuracy than forming committees composed of all agents.', ""Multi-agent reinforcement learning by the actor-critic model with an attention interface Multi-agent reinforcement learning algorithms have achieved satisfactory performances in various scenarios, but many of them encounter difficulties in partially observable environments. In partially observable environments, the inability to perceive environment states results in unsteadiness and misconvergence, especially in large-scale multi-agent environments. To improve interactions among homogeneous agents in a partially observable environment, we propose a novel multi-agent actor critic model with a visual attention interface to solve this problem. First, a recurrent visual attention interface is used to extract a latent state from each agent's partial observation. These latent states allow agents to focus on several local environments, in which each agent has a complete perception of a local environment and the intricate multi-agent environment is teased out by the interaction among several agents in the same local environment. The proposed method trains multi-agent systems with a centralized training and decentralized execution mechanism. The joint action of agents is approximated by the mean-field theory because the number of agents in a local environment is uncertain. Experimental results on the simulation platform suggest that our model performs better when training large-scale multi-agent systems in partially observable environments than baselines. (c) 2021 Elsevier B.V. All rights reserved.""]"
140,111,140_alzheimer_amyloid_neurodegenerative_acetylcholinesterase,"['alzheimer', 'amyloid', 'neurodegenerative', 'acetylcholinesterase', 'acetylcholine', 'proteins', 'disease', 'beta', 'peptides', 'protein']","[""Inhibitory mechanism of 17 beta-aminoestrogens in the formation of A beta aggregates Alzheimer's disease (AD) is a complex neurodegenerative disorder associated with the aggregation of the amyloid-beta peptide (A beta) into large oligomers and fibrils that damage healthy brain cells. The predominant peptide fragments in the plaques are mainly formed by the A beta(1-40) and A beta(1-42) peptides, albeit the eleven-residue A beta(25-35) segment is largely used in biological studies because it retains the neurotoxic properties of the longer A beta peptides. Recent studies indicate that treatment with therapeutic steroid hormones reduces the progress of the disease in AD models. Particularly, treatment with 17 beta-aminoestrogens (AEs) has shown a significant alleviation of the AD development by inhibiting oxidative stress and neuronal death. Yet, the mechanism by which the AE molecules exhibit their beneficial effects remains speculative. To shed light into the molecular mechanism of inhibition of the AD development by AEs, we investigated the possibility of direct interaction with the A beta(25-35) peptide. First, we calculate various interacting electronic properties of three AE derivatives as follows: prolame, butolame, and pentolame by performing DFT calculations. To account for the polymorphic nature of the A beta aggregates, we considered four different A beta(25-35) systems extracted from AD relevant fibril structures. From the calculation of different electron density properties, specific interacting loci were identified that guided the construction and optimization of various complexes. Interestingly, the results suggest a similar inhibitory mechanism based on the direct interaction between the AEs and the M35 residue that seems to be general and independent of the polymorphic properties of the A beta aggregates. Our analysis of the complex formation provides a structural framework for understanding the AE therapeutic properties in the molecular inhibitory mechanism of A beta aggregation."", ""1,2,3,4,6-penta-O-galloyl-beta-D-glucopyranose binds to the N-terminal metal binding region to inhibit amyloid beta-protein oligomer and fibril formation The early oligomerization of amyloid beta-protein (A beta) is a crucial step in the etiology of Alzheimer's disease (AD), in which soluble and highly neurotoxic oligomers are produced and accumulated inside neurons. In search of therapeutic solutions for AD treatment and prevention, potent inhibitors that remodel A beta assembly and prevent neurotoxic oligomer formation offer a promising approach. In particular, several polyphenolic compounds have shown anti-aggregation properties and good efficacy on inhibiting oligomeric amyloid formation. 1,2,3,4,6-penta-O-galloyl-beta-D-glucopyranose is a large polyphenol that has been shown to be effective at inhibiting aggregation of full-length A beta(1-40) and A beta(1-42), but has the opposite effect on the C-terminal fragment A beta(25-35). Here, we use a combination of ion mobility coupled to mass spectrometry (IMS-MS), transmission electron microscopy (TEM) and molecular dynamics (MD) simulations to elucidate the inhibitory effect of PGG on aggregation of full-length A beta(1-40) and A beta(1-42). We show that PGG interacts strongly with these two peptides, especially in their N-terminal metal binding regions, and suppresses the formation of A beta(1-40) tetramer and A beta(1-42) dodecamer. By exploring multiple facets of polyphenol-amyloid interactions, we provide a molecular basis for the opposing effects of PGG on full-length A beta and its C-terminal fragments. (C) 2016 Elsevier B.V. All rights reserved."", ""Review of Synthesis, Biological Assay and QSAR Studies of beta-Secretase Inhibitors Alzheimer's disease (AD) is highly complex. While several pathologies characterize this disease, amyloid plaques, composed of the beta-amyloid peptide, are hallmark neuropathological lesions in Alzheimer's disease brain. Indeed, a wealth of evidence suggests that beta-amyloid is central to the pathophysiology of AD and is likely to play an early role in this intractable neurodegenerative disorder. The BACE-1 enzyme is essential for the generation of beta-amyloid. BACE-1 knockout mice do not produce beta-amyloid and are free from Alzheimer's associated pathologies, including neuronal loss and certain memory deficits. The fact that BACE-1 initiates the formation of beta-amyloid, and the observation that BACE-1 levels are elevated in this disease provide direct and compelling reasons to develop therapies directed at BACE-1 inhibition, thus reducing beta-amyloid and its associated toxicities. In this sense, quantitative structure-activity relationships (QSAR) could play an important role in studying these beta-secretase inhibitors. QSAR models are necessary in order to guide the beta-secretase synthesis. This work is aimed at reviewing different design and synthesis and computational studies for a very large and heterogeneous series of beta-secretase inhibitors. First, we review design, synthesis, and Biological assay of beta-secretase inhibitors. Next, we review 2D QSAR, 3D QSAR, CoMFA, CoMSIA and Docking with different compounds to find out the structural requirements. Next, we review QSAR studies using the method of Linear Discriminant Analysis (LDA) in order to understand the essential structural requirement for receptor binding for beta-secretase inhibitors.""]"
141,111,141_retinal_retinas_retina_vision,"['retinal', 'retinas', 'retina', 'vision', 'retinitis', 'neurons', 'visual', 'receptive', 'photoreceptors', 'regeneration']","['Model-based comparison of current flow in rod bipolar cells of healthy and early-stage degenerated retina Retinal degenerative diseases, such as retinitis pigmentosa, are generally thought to initiate with the loss of photoreceptors, though recent work suggests that plasticity and remodeling occurs prior to photoreceptor cell loss. This degeneration subsequently leads to death of other retinal neurons, creating functional alterations and extensive remodeling of retinal networks. Retinal prosthetic devices stimulate the surviving retinal cells by applying external current using implanted electrodes. Although these devices restore partial vision, the quality of restored vision is limited. Further knowledge about the precise changes in degenerated retina as the disease progresses is essential to understand how current flows in retinas undergoing degenerative disease and to improve the performance of retinal prostheses. We developed computational models that describe current flow from rod photoreceptors to rod bipolar cells (RodBCs) in the healthy and early-stage degenerated retina. Morphologically accurate models of retinal cells with their synapses are constructed based on retinal connectome datasets, created using serial section transmission electron microscopy (TEM) images of 70 nm-thick slices of either healthy (RC1) or early-stage degenerated (RPC1) rabbit retina. The passive membrane and active ion currents of each cell are implemented using conductance-based models in the Neuron simulation environment. In response to photocurrent input at rod photoreceptors, the simulated membrane potential at RodBCs in early degenerate tissue is approximately 10-20 mV lower than that of RodBCs of that observed in wild type retina. Results presented here suggest that although RodBCs in RPC1 show early, altered morphology compared to RC1, the lower membrane potential is primarily a consequence of reduced rod photoreceptor input to RodBCs in the degenerated retina. Frequency response and step input analyses suggest that individual cell responses of RodBCs in either healthy or early-degenerated retina, prior to substantial photoreceptor cell loss, do not differ significantly.', ""Computational modelling of salamander retinal ganglion cells using machine learning approaches Artificial vision using computational models that can mimic biological vision is an area of ongoing research. One of the main themes within this research is the study of the retina and in particular, retinal ganglion cells which are responsible for encoding the visual stimuli. A common approach to modelling the internal processes of retinal ganglion cells is the use of a linear - non-linear cascade model, which models the cell's response using a linear filter followed by a static non-linearity. However, the resulting model is generally restrictive as it is often a poor estimator of the neuron's response. In this paper we present an alternative to the linear - non-linear model by modelling retinal ganglion cells using a number of machine learning techniques which have a proven track record for learning complex non-linearities in many different domains. A comparison of the model predicted spike rate shows that the machine learning models perform better than the standard linear - non-linear approach in the case of temporal white noise stimuli. Crown Copyright (C) 2018 Published by Elsevier B.V. All rights reserved."", ""Artificial intelligence techniques for retinal prostheses: a comprehensive review and future direction Objective. Retinal prostheses are promising devices to restore vision for patients with severe age-related macular degeneration or retinitis pigmentosa disease. The visual processing mechanism embodied in retinal prostheses play an important role in the restoration effect. Its performance depends on our understanding of the retina's working mechanism and the evolvement of computer vision models. Recently, remarkable progress has been made in the field of processing algorithm for retinal prostheses where the new discovery of the retina's working principle and state-of-the-arts computer vision models are combined together. Approach. We investigated the related research on artificial intelligence techniques for retinal prostheses. The processing algorithm in these studies could be attributed to three types: computer vision-related methods, biophysical models, and deep learning models. Main results. In this review, we first illustrate the structure and function of the normal and degenerated retina, then demonstrate the vision rehabilitation mechanism of three representative retinal prostheses. It is necessary to summarize the computational frameworks abstracted from the normal retina. In addition, the development and feature of three types of different processing algorithms are summarized. Finally, we analyze the bottleneck in existing algorithms and propose our prospect about the future directions to improve the restoration effect. Significance. This review systematically summarizes existing processing models for predicting the response of the retina to external stimuli. What's more, the suggestions for future direction may inspire researchers in this field to design better algorithms for retinal prostheses.""]"
142,109,142_reinforcement_model_learning_algorithm,"['reinforcement', 'model', 'learning', 'algorithm', 'algorithms', 'learned', 'approach', 'learns', 'method', 'gradient']","['Reinforcement learning in continuous time and space The performance of the proposed algorithms is first tested in a nonlinear control task of swinging a pendulum up with limited torque. It is shown in the simulations that (1) the task is accomplished by the continuous actor-critic method in a number of trials several times fewer than by the conventional discrete actor-critic method; (2) among the continuous policy update methods, the value-gradient-based policy with a known or learned dynamic model performs several times better than the actor-critic method; and (3) a value function update using exponential eligibility traces is more efficient and stable than that based on Euler approximation. The algorithms are then tested in a higher-dimensional task: cart-pole swing-up. This task is accomplished in several hundred trials using the value-gradient-based policy with a learned dynamic model. This article presents a reinforcement learning framework for continuous-time dynamical systems without a priori discretization of time, state, and action. Based on the Hamilton-Jacobi-Bellman (HJB) equation for infinite-horizon, discounted reward problems, we derive algorithms for estimating value functions and improving policies with the use of function approximators. The process of value function estimation is formulated as the minimization of a continuous-time form of the temporal difference (TD) error. Update methods based on backward Euler approximation and exponential eligibility traces are derived, and their correspondences with the conventional residual gradient, TD(0), and TD(lambda) algorithms are shown. For policy improvement, two methods-a continuous actor-critic method and a value-gradient-based greedy policy-are formulated. As a special case of the latter, a nonlinear feedback control law using the value gradient and the model of the input gain is derived. The advantage updating, a model-free algorithm derived previously, is also formulated in the HJB-based framework.', 'Focus of attention in reinforcement learning Classification-based reinforcement learning (RL) methods have recently been proposed as an alternative to the traditional value-function based methods. These methods use a classifier to represent a policy, where the input (features) to the classifier is the state and the output (class label) for that state is the desired action. The reinforcement-learning community knows that focusing on more important states can lead to improved performance. In this paper, we investigate the idea of focused learning in the context of classification-based RL. Specifically, we define a useful notation of state importance, which we use to prove rigorous bounds on policy loss. Furthermore, we show that a classification-based RL agent may behave arbitrarily poorly if it treats all states as equally important.', 'Model-based policy gradients with parameter-based exploration by least-squares conditional density estimation The goal of reinforcement learning (RL) is to let an agent learn an optimal control policy in an unknown environment so that future expected rewards are maximized. The model-free RL approach directly learns the policy based on data samples. Although using many samples tends to improve the accuracy of policy learning, collecting a large number of samples is often expensive in practice. On the other hand, the model-based RL approach first estimates the transition model of the environment and then learns the policy based on the estimated transition model. Thus, if the transition model is accurately learned from a small amount of data, the model-based approach is a promising alternative to the model-free approach. In this paper, we propose a novel model-based RL method by combining a recently proposed model-free policy search method called policy gradients with parameter-based exploration and the state-of-the-art transition model estimator called least-squares conditional density estimation. Through experiments, we demonstrate the practical usefulness of the proposed method. (C) 2014 Elsevier Ltd. All rights reserved.']"
143,109,143_inspection_detection_defects_defect,"['inspection', 'detection', 'defects', 'defect', 'identification', 'classification', 'recognition', 'accuracy', 'detect', 'features']","['Deep-learning-based anomaly detection for lace defect inspection employing videos in production line Defect inspection plays an essential role in ensuring quality of industrial products. The most widely used human visual inspection method has some drawbacks such as high cost and low efficiency, which bring an eager demand for the application of automatic defect inspection algorithm in actual production. However, few industrial production lines use automatic detection devices due to the gap between data collected in the actual production environment and ready-made datasets. Lace is one of the industrial products which completely depends on manual defect inspection. The complex and fine texture of lace makes it difficult to extract regular patterns using the existing image-based defect inspection methods. In this paper, we propose to collect lace videos in the weaving stage and design a deep-learning-based anomaly detection framework to detect lace defects. The framework contains three stages, namely video pre-processing stage, pixel reconstruction stage and pixel classification stage. In the offline phase, only defect-free lace videos are needed to train the pixel reconstruction model and calculate the detection threshold by our adaptive thresholding method. In the online phase, the proposed framework reconstructs lace videos and performs defect inspection using reconstruction error and the pre-set threshold. As far as we know, this paper the first to detect fabric defects by videos. Experimental results on artificial defect videos demonstrate the effectiveness of the proposed framework.', 'A novel MAS-GAN-based data synthesis method for object surface defect detection Surface defect detection in industrial processes is an essential step in production. The use of surface defect detection technology is of great significance for improving product quality and increasing production efficiency. However, the number of surface defect samples collected in the industrial process is limited, making training deep learning-based object detection models challenging. This paper proposes a multi-scale progressive generative adversarial network (MAS-GAN) that combines non-leaking data augmentation and self-attention mechanisms to solve this problem. The model uses an asymptotic growth strategy to synthesize multi-scale surface defect images and uses a non-leaking data augmentation method to deal with the degradation of the performance of the generative model in the case of insufficient samples. The self-attention mechanism further optimizes the generative adversarial network to make the details of high-resolution images more perfect. Using MAS-GAN to synthesize surface defect images to assist in training a deep learning-based object detection algorithm, both the training convergence speed of the surface defect detection model and the detection accuracy is improved. The experimental results on different datasets show the effectiveness of the proposed data synthesis method in the detection of surface defects of objects.', 'A simulation-based few samples learning method for surface defect segmentation In industrial production, it is difficult to obtain a well-trained surface detection algorithm since the real defect samples are lacking. In this paper, we propose a surface defect segmentation method based on defect sample simulation, which only needs few defect training samples. The entire method includes two modules: a local defect simulation algorithm and a residual-restored-based segmentation algorithm. In order to ensure both structural and local texture consistency of the simulated defects, we design a two stage simulation algorithm based on generation adversarial net and neural style transfer. The simulation method requires one single defect reference sample for training, and can generate the same type of defect in the specified area. The segmentation algorithm, trained with the simulated images and reference samples, can restore the defect area and yield the predicted label from the residual image. We carry out experiments on the button, road crack, and silicon steel strip datasets. The results show that the proposed method can remarkably improve the defect segmentation accuracy, attaining F1 score of 0.82. (c) 2020 Elsevier B.V. All rights reserved.']"
144,107,144_electromyogram_electromyography_electromyographic_torque,"['electromyogram', 'electromyography', 'electromyographic', 'torque', 'electrodes', 'movements', 'muscles', 'motions', 'gestures', 'innervation']","[""EMG feature assessment for myoelectric pattern recognition and channel selection: A study with incomplete spinal cord injury Myoelectric pattern recognition with a large number of electromyogram (EMG) channels provides an approach to assessing motor control information available from the recorded muscles. In order to develop a practical myoelectric control system, a feature dependent channel reduction method was developed in this study to determine a small number of EMG channels for myoelectric pattern recognition analysis. The method selects appropriate raw EMG features for classification of different movements, using the minimum Redundancy Maximum Relevance (mRMR) and the Markov random field (MRF) methods to rank a large number of EMG features, respectively. A k-nearest neighbor (KNN) classifier was used to evaluate the performance of the selected features in terms of classification accuracy. The method was tested using 57 channels' surface EMG signals recorded from forearm and hand muscles of individuals with incomplete spinal cord injury (SCI). Our results demonstrate that appropriate selection of a small number of raw EMG features from different recording channels resulted in similar high classification accuracies as achieved by using all the EMG channels or features. Compared with the conventional sequential forward selection (SFS) method, the feature dependent method does not require repeated classifier implementation. It can effectively reduce redundant information not only cross different channels, but also cross different features in the same channel. Such hybrid feature-channel selection from a large number of EMG recording channels can reduce computational cost for implementation of a myoelectric pattern recognition based control system. (C) 2014 IPEM. Published by Elsevier Ltd. All rights reserved."", 'Homology Characteristics of EEG and EMG for Lower Limb Voluntary Movement Intention In the field of lower limb exoskeletons, besides its electromechanical system design and control, attention has been paid to realizing the linkage of exoskeleton robots to humans via electroencephalography (EEG) and electromyography (EMG). However, even the state of the art performance of lower limb voluntary movement intention decoding still faces many obstacles. In the following work, focusing on the perspective of the inner mechanism, a homology characteristic of EEG and EMG for lower limb voluntary movement intention was conducted. A mathematical model of EEG and EMG was built based on its mechanism, which consists of a neural mass model (NMM), neuromuscular junction model, EMG generation model, decoding model, and musculoskeletal biomechanical model. The mechanism analysis and simulation results demonstrated that EEG and EMG signals were both excited by the same movement intention with a response time difference. To assess the efficiency of the proposed model, a synchronous acquisition system for EEG and EMG was constructed to analyze the homology and response time difference from EEG and EMG signals in the limb movement intention. An effective method of wavelet coherence was used to analyze the internal correlation between EEG and EMG signals in the same limb movement intention. To further prove the effectiveness of the hypothesis in this paper, six subjects were involved in the experiments. The experimental results demonstrated that there was a strong EEG-EMG coherence at 1 Hz around movement onset, and the phase of EEG was leading the EMG. Both the simulation and experimental results revealed that EEG and EMG are homologous, and the response time of the EEG signals are earlier than EMG signals during the limb movement intention. This work can provide a theoretical basis for the feasibility of EEG-based pre-perception and fusion perception of EEG and EMG in human movement detection.', 'Changes in EMG-EMG Coherence During Hand Grasp Movements It is challenging to recognize human hand grasp movements through electromyogram (EMG) signals. In this paper, EMG-EMG coherence measure is used to describe correlations of EMG recordings during different hand grasp movements. Meanwhile, linear discriminant analysis (LDA) is utilized to evaluate the performance of the EMG-EMG coherence measure for identifying the grasp movements. Experimental results show that the EMG-EMG coherence measure is effective to extract correlations among EMG recordings, with which different types of hand grasp movements have been successfully distinguished. It is shown that the EMG-EMG coherence measure might be a potential tool to reveal the EMG-EMG correlation between the intermuscular interactions during hand grasp movements.']"
145,106,145_multilayered_perceptron_perceptrons_perturbation,"['multilayered', 'perceptron', 'perceptrons', 'perturbation', 'multilayer', 'gradient', 'neural', 'algorithms', 'algorithm', 'optimization']","['METHODS OF TRAINING AND CONSTRUCTING MULTILAYER PERCEPTRONS WITH ARBITRARY PATTERN SETS This paper presents two compensation methods for multilayer perceptrons (MLPs) which are very difficult to train by traditional Back Propagation (BP) methods. For MLPs trapped in local minima, compensating methods can correct the wrong outputs one by one using constructing techniques until all outputs are right, so that the MLPs can skip from the local minima to the global minima. A hidden neuron is added as compensation for a binary input three-layer perceptron trapped in a local minimum; and one or two hidden neurons are added as compensation for a real input three-layer perceptron. For a perceptron of more than three layers, the second hidden layer from behind will be temporarily treated as the input layer during compensation, hence the above methods can also be used. Examples are given.', 'Tutorial on brain-inspired computing - Part 2: Multilayer perceptron and natural gradient learning Since the perceptron was developed for learning to classify input patterns, there have been plenty of studies on simple perceptrons and multilayer perceptrons. Despite wide and active studies in theory and applications, multilayer perceptrons still have many unsettled problems such as slow learning speed and overfitting. To find a thorough solution to these problems, it is necessary to consolidate previous studies, and find new directions for uplifting the practical power of multilayer perceptrons. As a first step toward the new stage of studies on multilayer perceptrons. we give short reviews on two interesting and important approaches; one is stochastic approach and the other is geometric approach. We also explain an efficient learning algorithm developed from the statistical and geometrical studies, which is now well known as the natural gradient learning method.', 'Derivation of the multilayer perceptron weight constraints for direct network interpretation and knowledge discovery This paper examines the multilayer perceptron (MLP) network from a hidden layer decision region perspective and derives the output layer and hidden layer weight constraints that the network must satisfy in performing a general classification task. This provides a foundation for direct knowledge discovery from the MLP, using a new method published by the author, which finds the key inputs that the MLP uses to classify an input case. The knowledge that the MLP network learns from the training examples is represented as ranked data relationships and induced rules, which can be used to validate the MLP network. The bounds of the network knowledge are established in the n-dimensional input space and a measure of the limit of the MLP network knowledge is proposed. An algorithm is presented for the calculation of the maximum number of hidden layer decision regions in the MLP input space. (C) 1999 Elsevier Science Ltd. All rights reserved.']"
146,105,146_fingerprint_fingerprints_palmprints_palmprint,"['fingerprint', 'fingerprints', 'palmprints', 'palmprint', 'fingercode', 'biometrics', 'biometric', 'finger', 'identification', 'recognition']","['Advanced methods for two-class pattern recognition problem formulation for minutiae-based fingerprint verification We present a new method for minutiae-based fingerprint verification that approaches the problem as a two-class pattern recognition problem. In our knowledge, this is one of the first works that uses as features for fingerprint verification the response of a minutiae matcher between two fingerprint. The feature vector obtained by the minutiae matching is classified into """"genuine"""" or """"impostor"""" by support vector machines. Results from FVC2002 are presented, yielding remarkable performance improvement with respect to other state-of-the-art approaches. (c) 2007 Elsevier B.V. All rights reserved.', 'Fingerprint matching based on weighting method and the SVM Fingerprint verification is an important biometric technology. In this paper, an improved fingerprint matching approach that uses both the weighting method and the support vector machine (SVM) is presented. A new weighting feature based on the distance between minutiae is introduced to supplement the minutiae information, which is particularly useful for fingerprint images of poor quality. Furthermore, the traditional minutiae-based matching task is studied as a classification task in the proposed approach by using SVM. To give an objective assessment of the approach, both international and domestic fingerprint verification competition databases have been used for the evaluation. Experimental results show substantial improvements in the accuracy and performance of fingerprint verification. (c) 2006 Elsevier B.V. All rights reserved.', 'Fingerprints verification based on their spectrum The goal of this paper is proposing a novel fingerprint verification approach to increase the accuracy and robustness of fingerprint verification process. The proposed approach is based on spectrum features extraction from the fingerprint image. In the proposed approach, the two dimensions (2-D) fingerprint image after enhancement is transformed into one dimension (1-D) using lexicographic ordering by dividing the image into non overlapped square blocks, each block scanned column by column. The scanned block pixel values are combined into a 1-D signal, and then the spectrum features are extracted from this signal. Support Vector Machines (SVMs) have been used for matching the features to decide whether these features belong to the same person or not. Furthermore, minutia based fingerprint verification approach is carried out in five steps; enhancement, binarization, thinning, minutiae extraction and minutiae matching. The proposed approach is compared with the minutia based approach and with other published approaches. The international fingerprint verification competitions (FVCs) databases have been used for the evaluation. The results proved the superiority of the proposed approach to the minutia based approach. (C) 2015 Elsevier B.V. All rights reserved.']"
147,104,147_labeling_labels_correlations_multilabel,"['labeling', 'labels', 'correlations', 'multilabel', 'correlation', 'label', 'classification', 'labeled', 'multigraph', 'unlabeled']","['Missing multi-label learning with non-equilibrium based on classification margin Multi-labels are more suitable for the ambiguity of the real world. However, missing labels are common in multi-label learning datasets; this results in unbalanced labeling and label diversity, which directly affect the performance of multi-label learning. Therefore, the classification and modeling of imbalanced data in missing multi-label learning are problems that need to be urgently solved Current methods mostly focus on combining sampling techniques with cost-sensitive learning and incorporating label correlation to improve the performance of the classifier, but generally they do not consider label loss caused by label cost. In fact, labeling unknown instances is often affected by the threshold of the discriminant function, especially for the label types near the threshold. Based on our previous research, we believe that information such as data distribution density and label density can be integrated into the label correlation, and that the classification margin can be expanded to effectively solve the labeling quality of labels near the threshold. Therefore, in this paper we propose a non-equilibrium multi-label learning algorithm based on the classification margin and aimed at completing the missing labels. First, the classification margin is proposed, and the label space is expanded by the label density. Then, the information entropy is used to measure the correlation between labels, and the label confidence matrix is constructed. The label confidence matrix is then unbalanced using the positive and negative label density, and the non-equilibrium label confidence matrix is used for label completion to obtain an informative label completion matrix. Finally, the kernel extreme learning machine and the label completion matrix are used for linear prediction. The experimental results show that the proposed algorithm has some advantages over other multi-label learning algorithms. (C) 2019 Elsevier B.V. All rights reserved.', ""Multi-label learning based on label-specific features and local pairwise label correlation Multi-label learning has drawn great attention in recent years. One of its tasks aims to build classification models for the problem where each instance associates with a set of labels. In order to exploit discriminative features for classification, some methods are proposed to construct label-specific features. However, these methods neglect the correlation among labels. In this paper, we propose a new method called LF-LPLC for multi-label learning, which integrates Label-specific features and local pairwise label correlation simultaneously. Firstly, we convert the original feature space to a low dimensional label-specific feature space, and therefore each label has a specific representation of its own. Then, we exploit the local correlation between each pair of labels by means of nearest neighbor techniques. According to the local correlation, the label-specific features of each label are expanded by uniting the related data from other label-specific features. With such a framework, it enriches the labels' semantic information and solves the imbalanced class-distribution problem. Finally, for each label, based on its label-specific features we construct a binary classification algorithm to test unlabeled instances. Comprehensive experiments are conducted on a collection of benchmark data sets. Comparison results with the state-of-the-art approaches validate the competitive performance of our proposed method. (C) 2017 Elsevier B.V. All rights reserved."", 'Learning label-specific features with global and local label correlation for multi-label classification Multi-label algorithms often use an identical feature space to build classification models for all labels. However, labels generally express different semantic information and should have their own characteristics. A few algorithms have been proposed to find label-specific features to construct discriminative classification models. Some use global label correlation to make the reconstructed features more discriminative, but they usually neglect the local correlation between labels. To solve this problem, we propose a new algorithm, named learning Label-specific Features with Global and Local label Correlation (LFGLC). The algorithm integrates both global and local label correlation to extract label-specific features for each label. Specifically, global label correlation is calculated by the label co-occurrence frequency between label pairs, and local label correlation is learned from the neighborhood of each instance. Comprehensive experiments on 12 multi-label data sets clearly manifest that the proposed algorithm performs competitively in feature selection and multi-label classification.']"
