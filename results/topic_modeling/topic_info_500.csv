Topic,Count,Name,Representation,Representative_Docs
-1,8793,-1_neural_learning_brain_training,"['neural', 'learning', 'brain', 'training', 'cognitive', 'prediction', 'accuracy', 'experimental', 'classification', 'research']","['Weakly Supervised Deep Learning for Brain Disease Prognosis Using MRI and Incomplete Clinical Scores As a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (MRI) data helps to assess the stage of pathology and predict future development of the disease. Due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. This would result in limited training data for learning reliable and robust models. Also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of MRI data, and these features may not be well coordinated with prediction models. In this paper, we propose a weakly supervised densely connected neural network (wiseDNN) for brain disease prognosis using baseline MRI data and incomplete clinical scores. Specifically, we first extract multiscale image patches (located by anatomical landmarks) from MRI to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. A weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. The experimental results on 1469 subjects from both ADNI-1 and ADNI-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.', 'Multilevel Weighted Feature Fusion Using Convolutional Neural Networks for EEG Motor Imagery Classification Deep learning methods, such as convolution neural networks (CNNs), have achieved remarkable success in computer vision tasks. Hence, an increasing trend in using deep learning for electroencephalograph (EEG) analysis is evident. Extracting relevant information from CNN features is one of the key reasons behind the success of the CNN-based deep learning models. Some CNN models use convolutional features from different CNN layers with good effect. However, extraction and fusion of multilevel convolutional features remain unexplored for EEG applications. Moreover, cognitive computing and artificial intelligence experience increasing applications in all fields. Cognitive process is based on understanding human brain cognition through signals, such as EEG. Hence, deep learning can aid in developing cognitive systems and related applications by improving EEG decoding. The classification and recognition of EEG have consistently been challenging due to its characteristics of dynamic time series data and low signal-to-noise ratio. However, the information hidden in different convolution layers can aid in improving feature discrimination capability. In this paper, we use the EEG motor imagery data to uncover the benefits of extracting and fusing multilevel convolutional features from different CNN layers, which are abstract representations of the input at various levels. Our proposed CNN model can learn robust spectral and temporal features from the raw EEG data. We demonstrate that such multilevel feature fusion outperforms the models that use features only from the last layer. Our results are better than the state of the art for EEG decoding and classification.', 'Intelligent Analysis of Exercise Health Big Data Based on Deep Convolutional Neural Network In this paper, the algorithm of the deep convolutional neural network is used to conduct in-depth research and analysis of sports health big data, and an intelligent analysis system is designed for the practical process. A convolutional neural network is one of the most popular methods of deep learning today. The convolutional neural network has the feature of local perception, which allows a complete image to be divided into several small parts, by learning the characteristic features of each local part and then merging the local information at the high level to get the full representation information. In this paper, we first apply a convolutional neural network for four classifications of brainwave data and analyze the accuracy and recall of the model. The model is then further optimized to improve its accuracy and is compared with other models to confirm its effectiveness. A demonstration platform of emotional fatigue detection with multimodal data feature fusion was established to realize data acquisition, emotional fatigue detection, and emotion feedback functions. The emotional fatigue detection platform was tested to verify that the proposed model can be used for time-series data feature learning. According to the platform requirement analysis and detailed functional design, the development of each functional module of the platform was completed and system testing was conducted. The big data platform constructed in this study can meet the basic needs of health monitoring for data analysis, which is conducive to the formation of a good situation of orderly and effective interaction among multiple subjects, thus improving the information service level of health monitoring and promoting comprehensive health development.']"
0,2446,0_alzheimer_dementia_neurodegenerative_amyloid,"['alzheimer', 'dementia', 'neurodegenerative', 'amyloid', 'cognitive', 'neuroimaging', 'neural', 'brain', 'aging', 'disease']","[""Early MCI-to-AD Conversion Prediction Using Future Value Forecasting of Multimodal Features In Alzheimer's disease (AD) progression, it is imperative to identify the subjects with mild cognitive impairment before clinical symptoms of AD appear. This work proposes a technique for decision support in identifying subjects who will show transition from mild cognitive impairment (MCI) to Alzheimer's disease (AD) in the future. We used robust predictors from multivariate MRI-derived biomarkers and neuropsychological measures and tracked their longitudinal trajectories to predict signs of AD in the MCI population. Assuming piecewise linear progression of the disease, we designed a novel weighted gradient offset-based technique to forecast the future marker value using readings from at least two previous follow-up visits. Later, the complete predictor trajectories are used as features for a standard support vector machine classifier to identify MCI-to-AD progressors amongst the MCI patients enrolled in the Alzheimer's disease neuroimaging initiative (ADNI) cohort. We explored the performance of both unimodal and multimodal models in a 5-fold cross-validation setup. The proposed technique resulted in a high classification AUC of 91.2% and 95.7% for 6-month- and 1-year-ahead AD prediction, respectively, using multimodal markers. In the end, we discuss the efficacy of MRI markers as compared to NM for MCI-to-AD conversion prediction."", ""Alzheimer Disease Detection Techniques and Methods: A Review Brain pathological changes linked with Alzheimer's disease (AD) can be measured with Neuroimaging. In the past few years, these measures are rapidly integrated into the signatures of Alzheimer disease (AD) with the help of classification frameworks which are offering tools for diagnosis and prognosis. Here is the review study of Alzheimer's disease based on Neuroimaging and cognitive impairment classification. This work is a systematic review for the published work in the field of AD especially the computer-aided diagnosis. The imaging modalities include 1) Magnetic resonance imaging (MRI) 2) Functional MRI (fMRI) 3) Diffusion tensor imaging 4) Positron emission tomography (PET) and 5) amyloid-PET. The study revealed that the classification criterion based on the features shows promising results to diagnose the disease and helps in clinical progression. The most widely used machine learning classifiers for AD diagnosis include Support Vector Machine, Bayesian Classifiers, Linear Discriminant Analysis, and K-Nearest Neighbor along with Deep learning. The study revealed that the deep learning techniques and support vector machine give higher accuracies in the identification of Alzheimer's disease. The possible challenges along with future directions are also discussed in the paper."", ""Hippocampal atrophy based Alzheimer's disease diagnosis via machine learning methods Alzheimer's disease is the most common form of dementia and is a serious health problem. The disease is expected to increase further in the upcoming years with the increase of the elderly population. Developing new treatments and diagnostic methods is getting more important. In this study, we focused on the early diagnosis of dementia in Alzheimer's disease via analysis of neuroimages. We analyzed the data diagnosed by the Alzheimer's Disease Neuroimaging Initiative (ADNI) protocol. The analyzed data were T1-weighted magnetic resonance images of 159 patients with Alzheimer's disease, 217 patients with mild cognitive impairment and 109 cognitively healthy older people. In this study, we propose that the volumetric reduction in the hippocampus is the most important indicator of Alzheimer's disease. There is not much research about the relationship between the volumetric reduction in the hippocampus and Alzheimer's disease. This volume information was calculated through semi-automatic segmentation software ITK-SNAP and a data set was created based on age, gender, diagnosis, and right and left hippocampal volume values. The diagnosis via hippocampal volume information was made by using machine learning techniques. By using this approach, we conclude that brain MRIs can be used to distinguish the patients with Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI) and Cognitive Normal (CN) from each other; while most of the studies were only able to distinguish AD from CN. Our results have revealed that our approach improves the performance of the computer-aided diagnosis of Alzheimer's disease.""]"
1,2421,1_neural_electroencephalogram_brain_electroencephalography,"['neural', 'electroencephalogram', 'brain', 'electroencephalography', 'recognition', 'classification', 'learning', 'stimuli', 'detection', 'processing']","['A Novel Time-Incremental End-to-End Shared Neural Network with Attention-Based Feature Fusion for Multiclass Motor Imagery Recognition In the research of motor imagery brain-computer interface (MI-BCI), traditional electroencephalogram (EEG) signal recognition algorithms appear to be inefficient in extracting EEG signal features and improving classification accuracy. In this paper, we discuss a solution to this problem based on a novel step-by-step method of feature extraction and pattern classification for multiclass MI-EEG signals. First, the training data from all subjects is merged and enlarged through autoencoder to meet the need for massive amounts of data while reducing the bad effect on signal recognition because of randomness, instability, and individual variability of EEG data. Second, an end-to-end sharing structure with attention-based time-incremental shallow convolution neural network is proposed. Shallow convolution neural network (SCNN) and bidirectional long short-term memory (BiLSTM) network are used to extract frequency-spatial domain features and time-series features of EEG signals, respectively. Then, the attention model is introduced into the feature fusion layer to dynamically weight these extracted temporal-frequency-spatial domain features, which greatly contributes to the reduction of feature redundancy and the improvement of classification accuracy. At last, validation tests using BCI Competition IV 2a data sets show that classification accuracy and kappa coefficient have reached 82.7 +/- 5.57% and 0.78 +/- 0.074, which can strongly prove its advantages in improving classification accuracy and reducing individual difference among different subjects from the same network.', 'EEG Motor Imagery Classification With Sparse Spectrotemporal Decomposition and Deep Learning Classification of electroencephalogram-based motor imagery (MI-EEG) tasks raises a big challenge in the design and development of brain-computer interfaces (BCIs). In view of the characteristics of nonstationarity, time-variability, and individual diversity of EEG signals, a deep learning framework termed SSD-SE-convolutional neural network (CNN) is proposed for MI-EEG classification. The framework consists of three parts: 1) the sparse spectrotemporal decomposition (SSD) algorithm is proposed for feature extraction, overcoming the drawbacks of conventional time-frequency analysis methods and enhancing the robustness to noise; 2) a CNN is constructed to fully exploit the time-frequency features, thus outperforming traditional classification methods both in terms of accuracy and kappa value; and 3) the squeeze-and-excitation (SE) blocks are adopted to adaptively recalibrate channelwise feature responses, which further improves the overall performance and offers a compelling classification solution for MI-EEG applications. Experimental results on two datasets reveal that the proposed framework outperforms state-of-the-art methods in terms of both classification quality and robustness. The advantages of SSD-SE-CNN include high accuracy, high efficiency, and robustness to cross-trial and cross-session variations, making it an ideal candidate for long-term MI-EEG applications. Note to Practitioners-Motor imagery-based brain-computer interfaces (MI-BCIs) are widely used to allow a user to control a device using only his or her neural activity. This article proposed a new framework to classify two-class MI tasks based on electroencephalography (EEG) signals. In this framework, a new sparse spectrotemporal decomposition method is used to extract time-frequency features from EEG signals. A convolutional neural network with squeeze-and-excitation blocks is then constructed to classify the MI tasks. We show the superiority of our method on two datasets and prove its feasibility for long-term MI-BCI applications.', 'Attention-Based DSC-ConvLSTM for Multiclass Motor Imagery Classification With the rapid development of deep learning, researchers have gradually applied it to motor imagery brain computer interface (MI-BCI) and initially demonstrated its advantages over traditional machine learning. However, its application still faces many challenges, and the recognition rate of electroencephalogram (EEG) is still the bottleneck restricting the development of MI-BCI. In order to improve the accuracy of EEG classification, a DSC-ConvLSTM model based on the attention mechanism is proposed for the multi-classification of motor imagery EEG signals. To address the problem of the small sample size of well-labeled and accurate EEG data, the preprocessing uses sliding windows for data augmentation, and the average prediction loss of each sliding window is used as the final prediction loss for that trial. This not only increases the training sample size and is beneficial to train complex neural network models, but also the network no longer extracts the global features of the whole trial so as to avoid learning the difference features among trials, which can effectively eliminate the influence of individual specificity. In the aspect of feature extraction and classification, the overall network structure is designed according to the characteristics of the EEG signals in this paper. Firstly, depth separable convolution (DSC) is used to extract spatial features of EEG signals. On the one hand, this reduces the number of parameters and improves the response speed of the system. On the other hand, the network structure we designed is more conducive to extract directly the direct extraction of spatial features of EEG signals. Secondly, the internal structure of the Long Short-Term Memory (LSTM) unit is improved by using convolution and attention mechanism, and a novel bidirectional convolution LSTM (ConvLSTM) structure is proposed by comparing the effects of embedding convolution and attention mechanism in the input and different gates, respectively. In the ConvLSTM module, the convolutional structure is only introduced into the input-to-state transition, while the gates still remain the original fully connected mechanism, and the attention mechanism is introduced into the input to further improve the overall decoding performance of the model. This bidirectional ConvLSTM extracts the time-domain features of EEG signals and integrates the feature extraction capability of the CNN and the sequence processing capability of LSTM. The experimental results show that the average classification accuracy of the model reaches 73.7% and 92.6% on two datasets, BCI Competition IV Dataset 2a and High Gamma Dataset, respectively, which proves the robustness and effectiveness of the model we proposed. It can be seen that the model in this paper can deeply excavate significant EEG features from the original EEG signals, show good performance in different subjects and different datasets, and improve the influence of individual variability on the classification performance, which is of practical significance for promoting the development of brain-computer interface technology towards a practical and marketable direction.']"
2,2267,2_visual_perception_vision_eye,"['visual', 'perception', 'vision', 'eye', 'recognition', 'attention', 'stimuli', 'features', 'neural', 'model']","['Learning-Based Prediction of Visual Attention for Video Signals Visual attention, which is an important characteristic of human visual system, is a useful clue for image processing and compression applications in the real world. This paper proposes a computational scheme that adopts both low-level and high-level features to predict visual attention from video signal by machine learning. The adoption of low-level features (color, orientation, and motion) is based on the study of visual cells, and the adoption of the human face as a high-level feature is based on the study of media communications. We show that such a scheme is more robust than those using purely single low- or high-level features. Unlike conventional techniques, our scheme is able to learn the relationship between features and visual attention to avoid perceptual mismatch between the estimated salience and the actual human fixation. We also show that selecting the representative training samples according to the fixation distribution improves the efficacy of regressive training. Experimental results are shown to demonstrate the advantages of the proposed scheme.', 'AN APPROACH FOR TARGET DETECTION AND EXTRACTION BASED ON BIOLOGICAL VISION Inspired by the mechanism of multi-scale image fusion of insect compound eye, this paper proposed a target detection and extraction method based on insect compound eye and human visual attention mechanism. The main feature of this method is that multi-scale visual attention mechanism is designed for improving the detection accuracy of interested target, meanwhile image is pre-segment based on it, then the target is extracted based on the LEGION (Locally Excitatory Globally Inhibitory Oscillator Networks) selection network model. For multi-scale visual attention mechanism, on intensity channel, this approach adopts multi-scale analysis to get the intensity saliency map on both global-level and local-level; on orientation channel, according to the mechanism of the large vision field of compound eye, directional information is added to improve the orientation sensitivity; on color channel, according to the characteristic of color sensitivity of human vision system, HSI color space is used instead of RGB to enhance color features. Compared with the experiment results of Itti visual attention model, the proposed approach can locate the interested targets in clutter scene more accurately, and complete fast extraction of the target without increasing of computation and time-consuming.', 'A coherent computational approach to model bottom-up visual attention Visual attention is a mechanism which filters out redundant visual information and detects the most relevant parts of our visual field. Automatic determination of the most visually relevant areas would be useful in many applications such as image and video coding, watermarking, video browsing, and quality assessment. Many research groups are currently investigating computational modeling of the visual attention system. The first published computational models have been based on some basic and well-understood Human Visual System (HVS) properties. These models feature a single perceptual layer that simulates only one aspect of the visual system. More recent models integrate complex features of the HVS and simulate hierarchical perceptual representation of the visual input. The bottom-up mechanism is the most occurring feature found in modern models. This mechanism refers to involuntary attention (i.e., salient spatial visual features that effortlessly or involuntary attract our attention). This paper presents a coherent computational approach to the modeling of the bottom-up visual attention. This model is mainly based on the current understanding of the HVS behavior. Contrast sensitivity functions, perceptual decomposition, visual masking, and center-surround interactions are some of the features implemented in this model. The performances of this algorithm are assessed by using natural images and experimental measurements from an eye-tracking system. Two adequate well-known metrics (correlation coefficient and Kullbacl-Leibler divergence) are used to validate this model. A further metric is also defined. The results from this model are finally compared to those from a reference bottom-up model.']"
3,2109,3_depressive_depression_psychiatric_disorder,"['depressive', 'depression', 'psychiatric', 'disorder', 'disorders', 'psychological', 'anxiety', 'mental', 'mood', 'interventions']","['Polysomnographic identification of anxiety and depression using deep learning Anxiety and depression are common psychiatric conditions associated with significant morbidity and healthcare costs. Sleep is an evolutionarily conserved health state. Anxiety and depression have a bidirectional relationship with sleep. This study reports on the use of analysis of polysomnographic data using deep learning methods to detect the presence of anxiety and depression. Polysomnography data on 940 patients performed at an academic sleep center during the 3-year period from 01/01/2016 to 12/31/2018 were identified for analysis. The data were divided into 3 subgroups: 205 patients with Anxiety/Depression, 349 patients with no Anxiety/Depression, and 386 patients with likely Anxiety/Depression. The first two subgroups were used for training and testing of the deep learning algorithm, and the third subgroup was used for external validation of the resulting model. Hypnograms were constructed via automatic sleep staging, with the 12-channel PSG data being transformed into three-channel RGB (red, green, blue channels) images for analysis. Composite patient images were generated and utilized for training the Xception model, which provided a validation set accuracy of 0.9782 on the ninth training epoch. In the independent test set, the model achieved a high accuracy (0.9688), precision (0.9533), recall (0.9630), and F1-score (0.9581). Classification performance of most other mainstream deep learning models was comparable. These findings suggest that machine learning techniques have the potential to accurately detect the presence of anxiety and depression from analysis of sleep study data. Further studies are needed to explore the utility of these techniques in the field of psychiatry.', ""Classifying major depression patients and healthy controls using EEG, eye tracking and galvanic skin response data Objective: Major depression disorder (MDD) is one of the most prevalent mental disorders worldwide. Diagnosing depression in the early stage is crucial to treatment process. However, due to depression's comorbid nature and the subjectivity in diagnosis, an early diagnosis could be challenging. Recently, machine learning approaches have been used to process Electroencephalography (EEG) and neuroimaging data to facilitate the diagnosis. In the present study, we used a multimodal machine learning approach involving EEG, eye tracking and galvanic skin response data as input to classify depression patients and healthy controls."", ""Deep learning for prediction of depressive symptoms in a large textual dataset Depression is a common illness worldwide with potentially severe implications. Early identification of depressive symptoms is a crucial first step towards assessment, intervention, and relapse prevention. With an increase in data sets with relevance for depression, and the advancement of machine learning, there is a potential to develop intelligent systems to detect symptoms of depression in written material. This work proposes an efficient approach using Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) to identify texts describing self-perceived symptoms of depression. The approach is applied on a large dataset from a public online information channel for young people in Norway. The dataset consists of youth's own text-based questions on this information channel. Features are then provided from a one-hot process on robust features extracted from the reflection of possible symptoms of depression pre-defined by medical and psychological experts. The features are better than conventional approaches, which are mostly based on the word frequencies (i.e., some topmost frequent words are chosen as features from the whole text dataset and applied to model the underlying events in any text message) rather than symptoms. Then, a deep learning approach is applied (i.e., RNN) to train the time-sequential features discriminating texts describing depression symptoms from posts with no such descriptions (non-depression posts). Finally, the trained RNN is used to automatically predict depression posts. The system is compared against conventional approaches where it achieved superior performance than others. The linear discriminant space clearly reveals the robustness of the features by generating better clustering than other traditional features. Besides, since the features are based on the possible symptoms of depression, the system may generate meaningful explanations of the decision from machine learning models using an explainable Artificial Intelligence (XAI) algorithm called Local Interpretable Model-Agnostic Explanations (LIME). The proposed depression symptom feature-based approach shows superior performance compared to the traditional general word frequency-based approaches where frequency of the features gets more importance than the specific symptoms of depression. Although the proposed approach is applied on a Norwegian dataset, a similar robust approach can be applied on other depression datasets developed in other languages with proper annotations and symptom-based feature extraction. Thus, the depression prediction approach can be adopted to contribute to develop better mental health care technologies such as intelligent chatbots.""]"
4,1849,4_algorithms_algorithm_learning_models,"['algorithms', 'algorithm', 'learning', 'models', 'model', 'neural', 'optimization', 'regression', 'analysis', 'clustering']","['Efficient Learning and Feature Selection in High-Dimensional Regression We present a novel algorithm for efficient learning and feature selection in high-dimensional regression problems. We arrive at this model through a modification of the standard regression model, enabling us to derive a probabilistic version of the well-known statistical regression technique of backfitting. Using the expectation-maximization algorithm, along with variational approximation methods to overcome intractability, we extend our algorithm to include automatic relevance detection of the input features. This variational Bayesian least squares (VBLS) approach retains its simplicity as a linear model, but offers a novel statistically robust black-box approach to generalized linear regression with high-dimensional inputs. It can be easily extended to nonlinear regression and classification problems. In particular, we derive the framework of sparse Bayesian learning, the relevance vector machine, with VBLS at its core, offering significant computational and robustness advantages for this class of methods. The iterative nature of VBLS makes it most suitable for real-time incremental learning, which is crucial especially in the application domain of robotics, brain-machine interfaces, and neural prosthetics, where real-time learning of models for control is needed. We evaluate our algorithm on synthetic and neurophysiological data sets, as well as on standard regression and classification benchmark data sets, comparing it with other competitive statistical approaches and demonstrating its suitability as a drop-in replacement for other generalized linear regression techniques.', 'Theoretical method for solving BSS-ICA using SVM In this work we propose a new method for solving the blind source separation (BSS) problem using a support vector machine (SVM) workbench. Thus, we provide an introduction to SVM-ICA, a theoretical approach to unsupervised learning based on learning machines, which has frequently been proposed for classification and regression tasks. The key idea is to construct a Lagrange function from both the objective function and the corresponding constraints, by introducing a dual set of variables and solving the optimization problem. For this purpose we define a specific cost function and its derivative in terms of independence, i.e. inner products between the output and the objective function, transforming an unsupervised learning problem into a supervised learning machine task where optimization theory can be applied to develop effective algorithms.', 'A global optimum approach for one-layer neural networks The article presents a method for learning the weights in one-layer feed-forward neural networks minimizing either the sum of squared errors or the maximum absolute error, measured in the input scale. This leads to the existence of a global optimum that can be easily obtained solving linear systems of equations or linear programming problems, using much less computational power than the one associated with the standard methods. Another version of the method allows computing a large set of estimates for the weights, providing robust, mean or median, estimates for them, and the associated standard errors, which give a good measure for the quality of the fit. Later, the standard one-layer neural network algorithms are improved by learning the neural functions instead of assuming them known. A set of examples of applications is used to illustrate the methods. Finally, a comparison with other high-performance learning algorithms shows that the proposed methods are at least 10 times faster than the fastest standard algorithm used in the comparison.']"
5,1654,5_neural_neuroscience_brain_neuronal,"['neural', 'neuroscience', 'brain', 'neuronal', 'neuroimaging', 'cognitive', 'neurons', 'fmri', 'analyses', 'imaging']","[""Sparse representation of whole-brain fMRI signals for identification of functional networks There have been several recent studies that used sparse representation for fMRI signal analysis and activation detection based on the assumption that each voxel's fMRI signal is linearly composed of sparse components. Previous studies have employed sparse coding to model functional networks in various modalities and scales. These prior contributions inspired the exploration of whether/how sparse representation can be used to identify functional networks in a voxel-wise way and on the whole brain scale. This paper presents a novel, alternative methodology of identifying multiple functional networks via sparse representation of whole-brain task-based fMRI signals. Our basic idea is that all fMRI signals within the whole brain of one subject are aggregated into a big data matrix, which is then factorized into an over-complete dictionary basis matrix and a reference weight matrix via an effective online dictionary learning algorithm. Our extensive experimental results have shown that this novel methodology can uncover multiple functional networks that can be well characterized and interpreted in spatial, temporal and frequency domains based on current brain science knowledge. Importantly, these well-characterized functional network components are quite reproducible in different brains. In general, our methods offer a novel, effective and unified solution to multiple fMRI data analysis tasks including activation detection, de-activation detection, and functional network identification. (C) 2014 Elsevier B.V. All rights reserved."", 'An efficient functional magnetic resonance imaging data reduction strategy using neighborhood preserving embedding algorithm High dimensionality data have become common in neuroimaging fields, especially group-level functional magnetic resonance imaging (fMRI) datasets. fMRI connectivity analysis is a widely used, powerful technique for studying functional brain networks to probe underlying mechanisms of brain function and neuropsychological disorders. However, data-driven technique like independent components analysis (ICA), can yield unstable and inconsistent results, confounding the true effects of interest and hindering the understanding of brain functionality and connectivity. A key contributing factor to this instability is the information loss that occurs during fMRI data reduction. Data reduction of high dimensionality fMRI data in the temporal domain to identify the important information within group datasets is necessary for such analyses and is crucial to ensure the accuracy and stability of the outputs. In this study, we describe an fMRI data reduction strategy based on an adapted neighborhood preserving embedding (NPE) algorithm. Both simulated and real data results indicate that, compared with the widely used data reduction method, principal component analysis, the NPE-based data reduction method (a) shows superior performance on efficient data reduction, while enhancing group-level information, (b) develops a unique stratagem for selecting components based on an adjacency graph of eigenvectors, (c) generates more reliable and reproducible brain networks under different model orders when the outputs of NPE are used for ICA, (d) is more sensitive to revealing task-evoked activation for task fMRI, and (e) is extremely attractive and powerful for the increasingly popular fast fMRI and very large datasets.', 'Four-Dimensional Modeling of fMRI Data via Spatio-Temporal Convolutional Neural Networks (ST-CNNs) Since the human brain functional mechanism has been enabled for investigation by the functional magnetic resonance imaging (fMRI) technology, simultaneous modeling of both the spatial and temporal patterns of brain functional networks from 4-D fMRI data has been a fundamental but still challenging research topic for neuroimaging and medical image analysis fields. Currently, general linear model (GLM), independent component analysis (ICA), sparse dictionary learning, and recently deep learning models, are major methods for fMRI data analysis in either spatial or temporal domains, but there are few joint spatial-temporal methods proposed, as far as we know. As a result, the 4-D nature of fMRI data has not been effectively investigated due to this methodological gap. The recent success of deep learning applications for functional brain decoding and encoding greatly inspired us in this paper to propose a novel framework called spatio-temporal convolutional neural network (ST-CNN) to extract both spatial and temporal characteristics from targeted networks jointly and automatically identify of functional networks. The identification of default mode network (DMN) from fMRI data was used for evaluation of the proposed framework. Results show that only training the framework on one fMRI data set is sufficiently generalizable to identify the DMN from different data sets of different cognitive tasks and resting state. Further investigation of the results shows that the joint-learning scheme can capture the intrinsic relationship between the spatial and temporal characteristics of DMN and thus it ensures the accurate identification of DMN from independent data sets. The ST-CNN model brings new tools and insights for fMRI analysis in cognitive and clinical neuroscience studies.']"
6,1502,6_imaging_tumors_tumor_cancer,"['imaging', 'tumors', 'tumor', 'cancer', 'malignant', 'brain', 'mri', 'tumour', 'neural', 'radiomics']","['The Application of Deep Convolutional Neural Networks to Brain Cancer Images: A Survey In recent years, improved deep learning techniques have been applied to biomedical image processing for the classification and segmentation of different tumors based on magnetic resonance imaging (MRI) and histopathological imaging (H&E) clinical information. Deep Convolutional Neural Networks (DCNNs) architectures include tens to hundreds of processing layers that can extract multiple levels of features in image-based data, which would be otherwise very difficult and time-consuming to be recognized and extracted by experts for classification of tumors into different tumor types, as well as segmentation of tumor images. This article summarizes the latest studies of deep learning techniques applied to three different kinds of brain cancer medical images (histology, magnetic resonance, and computed tomography) and highlights current challenges in the field for the broader applicability of DCNN in personalized brain cancer care by focusing on two main applications of DCNNs: classification and segmentation of brain cancer tumors images.', 'MRI-Based Deep Learning Segmentation and Radiomics of Sarcoma in Mice Small-animal imaging is an essential tool that provides noninvasive, longitudinal insight into novel cancer therapies. However, considerable variability in image analysis techniques can lead to inconsistent results. We have developed quantitative imaging for application in the preclinical arm of a coclinical trial by using a genetically engineered mouse model of soft tissue sarcoma. Magnetic resonance imaging (MRI) images were acquired 1 day before and 1 week after radiation therapy. After the second MRI, the primary tumor was surgically removed by amputating the tumor-bearing hind limb, and mice were followed for up to 6 months. An automatic analysis pipeline was used for multicontrast MRI data using a convolutional neural network for tumor segmentation followed by radiomics analysis. We then calculated radiomics features for the tumor, the peritumoral area, and the 2 combined. The first radiomics analysis focused on features most indicative of radiation therapy effects; the second radiomics analysis looked for features that might predict primary tumor recurrence. The segmentation results indicated that Dice scores were similar when using multicontrast versus single T2-weighted data (0.863 vs 0.861). One week post RT, larger tumor volumes were measured, and radiomics analysis showed greater heterogeneity. In the tumor and peritumoral area, radiomics features were predictive of primary tumor recurrence (AUC: 0.79). We have created an image processing pipeline for high-throughput, reduced-bias segmentation of multiparametric tumor MRI data and radiomics analysis, to better our understanding of preclinical imaging and the insights it provides when studying new cancer therapies.', ""Application of deep learning for automatic segmentation of brain tumors on magnetic resonance imaging: a heuristic approach in the clinical scenario Purpose Accurate brain tumor segmentation on magnetic resonance imaging (MRI) has wide-ranging applications such as radiosurgery planning. Advances in artificial intelligence, especially deep learning (DL), allow development of automatic segmentation that overcome the labor-intensive and operator-dependent manual segmentation. We aimed to evaluate the accuracy of the top-performing DL model from the 2018 Brain Tumor Segmentation (BraTS) challenge, the impact of missing MRI sequences, and whether a model trained on gliomas can accurately segment other brain tumor types. Methods We trained the model using Medical Decathlon dataset, applied it to the BraTS 2019 glioma dataset, and developed additional models using individual and multimodal MRI sequences. The Dice score was calculated to assess the model's accuracy compared to ground truth labels by neuroradiologists on BraTS dataset. The model was then applied to a local dataset of 105 brain tumors, performance of which was qualitatively evaluated. Results The DL model using pre- and post-gadolinium contrast T1 and T2 FLAIR sequences performed best, with a Dice score 0.878 for whole tumor, 0.732 tumor core, and 0.699 active tumor. Lack of T1 or T2 sequences did not significantly degrade performance, but FLAIR and T1C were important contributors. All segmentations performed by the model in the local dataset, including non-glioma cases, were considered accurate by a pool of specialists. Conclusion The DL model could use available MRI sequences to optimize glioma segmentation and adopt transfer learning to segment non-glioma tumors, thereby serving as a useful tool to improve treatment planning and personalized surveillance of patients.""]"
7,1474,7_robotics_robotic_robot_robots,"['robotics', 'robotic', 'robot', 'robots', 'controller', 'locomotion', 'mechanism', 'adaptive', 'autonomous', 'humanoid']","['Inferring Human-Robot Performance Objectives During Locomotion Using Inverse Reinforcement Learning and Inverse Optimal Control Quantitatively characterizing a locomotion performance objective for a human-robot system is an important consideration in the assistive wearable robot design towards human-robot symbiosis. This problem, however, has only been addressed sparsely in the literature. In this study, we propose a new inverse approach from observed human-robot walking behavior to infer a human-robot collective performance objective represented in a quadratic form. By an innovative design of human experiments and simulation study, respectively, we validated the effectiveness of two solution approaches to solving the inverse problem using inverse reinforcement learning (IRL) and inverse optimal control (IOC). The IRL-based experiments of human walking with robotic transfemoral prosthesis validated the realistic applicability of the proposed inverse approach, while the IOC-based analysis provided important human-robot system properties such as stability and robustness that are difficult to obtain from human experiments. This study introduces a new tool to the field of wearable lower limb robots. It is expected to be expandable to quantify joint human-robot locomotion performance objectives for personalizing wearable robot control in the future.', 'Human-Inspired Eigenmovement Concept Provides Coupling-Free Sensorimotor Control in Humanoid Robot Control of a multi-body system in both robots and humans may face the problem of destabilizing dynamic coupling effects arising between linked body segments. The state of the art solutions in robotics are full state feedback controllers. For human hip-ankle coordination, a more parsimonious and theoretically stable alternative to the robotics solution has been suggested in terms of the Eigenmovement (EM) control. Eigenmovements are kinematic synergies designed to describe the multi DoF system, and its control, with a set of independent, and hence coupling-free, scalar equations. This paper investigates whether the EM alternative shows ""real-world robustness"" against noisy and inaccurate sensors, mechanical non-linearities such as dead zones, and human-like feedback time delays when controlling hip-ankle movements of a balancing humanoid robot. The EM concept and the EM controller are introduced, the robot\'s dynamics are identified using a biomechanical approach, and robot tests are performed in a human posture control laboratory. The tests show that the EM controller provides stable control of the robot with proactive (""voluntary"") movements and reactive balancing of stance during support surface tilts and translations. Although a preliminary robot-human comparison reveals similarities and differences, we conclude (i) the Eigenmovement concept is a valid candidate when different concepts of human sensorimotor control are considered, and (ii) that human-inspired robot experiments may help to decide in future the choice among the candidates and to improve the design of humanoid robots and robotic rehabilitation devices.', 'Attention-based robot control We apply an engineering control framework for attention in the human brain to the problem of creating an autonomous robot control system. We first describe a specific task, that of route planning for a robot in a dynamic environment, then the general control architecture, and finally we show how it can be applied to the problem. Initial results of a simple simulation are presented.']"
8,1340,8_optimization_algorithm_algorithms_intelligent,"['optimization', 'algorithm', 'algorithms', 'intelligent', 'smart', 'swarm', 'model', 'efficiency', 'approach', 'strategy']","['An Intelligent Optimization for Building Design Based on BP Neural Network and SPEA-II Multiobjective Algorithm With the continuous development of the field of building optimization, more and more optimization methods have sprung up, among which there are many kinds of intelligent optimization algorithms. This kind of intelligent optimization algorithm usually relies on the traditional building performance simulation method to obtain the building performance index for optimization. However, intelligent optimization algorithms generally require large-scale calculations. At the same time, the time required for building performance simulation is often limited by the complexity of building models and the configuration of computers, which leads to a long time for performance optimization, which cannot give efficient and accurate feedback to designers in engineering. Building performance optimization methods based on intelligent optimization algorithms are mainly used in scientific research and are difficult to put into practical projects. Therefore, this paper builds an accurate and efficient platform for building performance prediction and optimization to help designers make decisions combined with BP neural network and the SPEA-II multiobjective optimization algorithm. Besides, the optimization results of the case are quantitatively and qualitatively analyzed and presented in visual form based on the BP neural network prediction model. Quantitative analysis includes the evolution process of solution set, convergence process, and comprehensive quality evaluation of solution set. Qualitative analysis includes Pareto frontier and optimal architectural scheme analysis. Finally, the conclusion shows that the platform prediction and optimization can give accurate and reliable optimal solution, and the optimal building scheme is reasonable and has high engineering application value.', 'Multimedia Urban Road Path Optimization Based on Genetic Algorithm In order to study multimedia urban road path optimization based on genetic algorithm, a dynamic path optimization based on genetic algorithm is proposed. Firstly, for the current situation of traffic congestion, time constraints are strictly considered based on the traditional hard time window logistics distribution vehicle scheduling problem model. Then, the mathematical model is established, and the optimal solution is solved by the combination of decomposition coordination algorithm and genetic algorithm. We divide multiple customers into different customer groups and determine the service object order of each express car in each customer group, so as to obtain the most valuable scheduling scheme. Finally, in the process of solving the model, the relevant and reliable distribution basis for enterprise distribution is collected, including customer geographical coordinates, demand, delivery time window, unit cost required for loading and unloading, loading and unloading time, and penalty cost to be borne by distribution enterprises after early arrival and late arrival. Using the improved genetic algorithm, the optimal solution of each objective function is actually obtained in about 140 generations, which is faster than that before the improvement. Using the genetic algorithm based on sequence coding, a hybrid genetic algorithm is constructed to solve the model problem. Through the comparative analysis of experimental data, it is known that the algorithm has good performance, is a feasible algorithm to solve the VSP problem with time window, and can quickly obtain the vehicle routing scheduling scheme with reference value.', 'Smart teaching mode based on particle swarm image recognition and human-computer interaction deep learning The smart teaching mode overcomes the shortcomings of traditional teaching online and offline, but there are certain deficiencies in the real-time feature extraction of teachers and students. In view of this, this study uses the particle swarm image recognition and deep learning technology to process the intelligent classroom video teaching image and extracts the classroom task features in real time and sends them to the teacher. In order to overcome the shortcomings of the premature convergence of the standard particle swarm optimization algorithm, an improved strategy for multiple particle swarm optimization algorithms is proposed. In order to improve the premature problem in the search performance algorithm of PSO algorithm, this paper combines the algorithm with the useful attributes of other algorithms to improve the particle diversity in the algorithm, enhance the global search ability of the particle, and achieve effective feature extraction. The research indicates that the method proposed in this paper has certain practical effects and can provide theoretical reference for subsequent related research.']"
9,1224,9_stroke_rehabilitation_treadmill_limb,"['stroke', 'rehabilitation', 'treadmill', 'limb', 'impairment', 'robotic', 'therapy', 'recovery', 'exoskeleton', 'ankle']","[""A strategy for computer-assisted mental practice in stroke rehabilitation Objective. To investigate the technical and clinical viability of using computer-facilitated mental practice in the rehabilitation of upper-limb hemiparesis following stroke. Design. A single-case study. Setting. Academic-affiliated rehabilitation center. Participant. A 46-year-old man with stable motor deficit of the upper right limb following subcortical ischemic stroke. Intervention. Three computer-enhanced mental practice sessions per week at the rehabilitation center, in addition to usual physical therapy. A custom-made virtual reality system equipped with arm-tracking sensors was used to guide mental practice. The system was designed to superimpose over the (unseen) paretic arm a virtual reconstruction of the movement registered from the nonparetic arm. The laboratory intervention was followed by a 1-month home- rehabilitation program, making use of a portable display device. Main outcome measures. Pretreatment and posttreatment clinical assessment measures were the upper-extremity scale of the Fugl-Meyer Assessment of Sensorimotor Impairment and the Action Research Arm Test. Performance of the affected arm was evaluated using the healthy arm as the control condition. Results. The patient's paretic limb improved after the first phase of intervention, with modest increases after home rehabilitation, as indicated by functional assessment scores and sensors data. Conclusion. Results suggest that technology-supported mental training is a feasible and potentially effective approach for improving motor skills after stroke."", ""Randomized Trial of a Robotic Assistive Device for the Upper Extremity During Early Inpatient Stroke Rehabilitation Background. A recent Cochrane Review showed that early robotic training of the upper limb in stroke survivors can be more effective than other interventions when improving activities of daily living involving the arm function is the aim of therapy. Objective. We tested for efficacy of the study a protocol which involved the use of the NeReBot therapy in partial substitution of standard upper limb rehabilitation in post-acute stroke patients. Methods. In this dose-matched, randomized controlled clinical trial, 34 hemiparetic participants with movement against gravity in shoulder, elbow, and wrist muscle groups were enrolled within 15 days of the onset of stroke. All participants received a total daily rehabilitation treatment for 120 minutes, 5 days per week for 5 weeks. The control group received standard therapy for the upper limb. The experimental group received standard therapy (65% of exercise time) associated with robotic training (35% of exercise time). Muscle tone (Modified Ashworth Scale), strength (Medical Research Council), and synergism (Fugl-Meyer motor scores) were measured at impairment level, whereas dexterity (Box and Block Test and Frenchay Arm Test) and activities of daily living (Functional Independence Measure) were measured at activity level. All assessments were performed at baseline, at the end of therapy (time T1), at 3 months (time T2), and at 7 months (time T3) after entry. All between-group analyses were tested using nonparametric test with Bonferroni's adjustments for multiple testing. Results. No significant between-group differences were found with respect to demographic characteristics, motor, dexterity, and ADLs at baseline, postintervention (T1) and at follow-up (T2 and T3). Conclusions. The robot therapy by NeReBot did not lead to better outcomes compared with conventional inpatient rehabilitation."", ""Myoelectrically controlled wrist robot for stroke rehabilitation Background: Robot-assisted rehabilitation is an advanced new technology in stroke rehabilitation to provide intensive training. Post-stroke motor recovery depends on active rehabilitation by voluntary participation of patient's paretic motor system as early as possible in order to promote reorganization of brain. However, voluntary residual motor efforts to the affected limb have not been involved enough in most robot-assisted rehabilitation for patients after stroke. The objective of this study is to evaluate the feasibility of robot-assisted rehabilitation using myoelectric control on upper limb motor recovery.""]"
10,1184,10_stroke_infarct_cardiovascular_cerebral,"['stroke', 'infarct', 'cardiovascular', 'cerebral', 'outcomes', 'artery', 'arterial', 'prediction', 'vascular', 'predict']","['Predicting Ischemic Stroke in Patients with Atrial Fibrillation Using Machine Learning Background: Atrial fibrillation (AF) is a well-known risk factor for stroke. Predicting the risk is important to prevent the first and secondary attacks of cerebrovascular diseases by determining early treatment. This study aimed to predict the ischemic stroke in AF patients based on the massive and complex Korean National Health Insurance (KNH1S) data through a machine learning approach. Methods: We extracted 65-dimensional features, including demographics, health examination, and medical history information, of 754,949 patients with AF from KNHES. Logistic regression was used to determine whether the extracted features had a statistically significant association with ischemic stroke occurrence. Then, we constructed the ischemic stroke prediction model using an attention-based deep neural network. The extracted features were used as input, and the occurrence of ischemic stroke after the diagnosis of AF was the output used to train the model. Results: We found 48 features significantly associated with ischemic stroke occurrence through regression analysis (p-value < 0.001). When the proposed deep learning model was applied to 150,989 AF patients, it was confirmed that the occurrence ischemic stroke was predicted to be higher AUROC (AUROC = 0.727 +/- 0.003) compared to CHA(2)DS(2)-VASc score (AUROC = 0.651 +/- 0.007) and other machine learning methods. Conclusions: As part of preventive medicine, this study could help AF patients prepare for ischemic stroke prevention based on predicted stoke associated features and risk scores.', 'Automatic Segmentation in Acute Ischemic Stroke: Prognostic Significance of Topological Stroke Volumes on Stroke Outcome Background: Stroke infarct volume predicts patient disability and has utility for clinical trial outcomes. Accurate infarct volume measurement requires manual segmentation of stroke boundaries in diffusion-weighted magnetic resonance imaging scans which is time-consuming and subject to variability. Automatic infarct segmentation should be robust to rotation and reflection; however, prior work has not encoded this property into deep learning architecture. Here, we use rotation-reflection equivariance and train a deep learning model to segment stroke volumes in a large cohort of well-characterized patients with acute ischemic stroke in different vascular territories. Methods: In this retrospective study, patients were selected from a stroke registry at Houston Methodist Hospital. Eight hundred seventy-five patients with acute ischemic stroke in any brain area who had magnetic resonance imaging with diffusion-weighted imaging were included for analysis and split 80/20 for training/testing. Infarct volumes were manually segmented by consensus of 3 independent clinical experts and cross-referenced against radiology reports. A rotation-reflection equivariant model was developed based on U-Net and grouped convolutions. Segmentation performance was evaluated using Dice score, precision, and recall. Ninety-day modified Rankin Scale outcome prediction was also evaluated using clinical variables and segmented stroke volumes in different brain regions. Results: Segmentation model Dice scores are 0.88 (95% CI, 0.87-0.89; training) and 0.85 (0.82-0.88; testing). The modified Rankin Scale outcome prediction AUC using stroke volume in 30 refined brain regions based upon modified Rankin Scale-relevance areas adjusted for clinical variables was 0.80 (0.76-0.83) with an accuracy of 0.75 (0.72-0.78). Conclusions: We trained a deep learning model with encoded rotation-reflection equivariance to segment acute ischemic stroke lesions in diffusion- weighted imaging using a large data set from the Houston Methodist stroke center. The model achieved competitive performance in 175 well-balanced hold-out testing cases that include strokes from different vascular territories. Furthermore, the location specific stroke volume segmentations from the deep learning model combined with clinical factors demonstrated high AUC and accuracy for 90-day modified Rankin Scale in an outcome prediction model.', ""Development and Validation of Prediction Models for Severe Complications After Acute Ischemic Stroke: A Study Based on the Stroke Registry of Northwestern Germany Background The treatment of stroke has been undergoing rapid changes. As treatment options progress, prediction of those under risk for complications becomes more important. Available models have, however, frequently been built based on data no longer representative of today's care, in particular with respect to acute stroke management. Our aim was to build and validate prediction models for 4 clinically important, severe outcomes after stroke. Methods and Results We used German registry data from 152 710 patients with acute ischemic stroke obtained in 2016 (development) and 2017 (validation). We took into account potential predictors that were available at admission and focused on in-hospital mortality, intracranial mass effect, secondary intracerebral hemorrhage, and deep vein thrombosis as outcomes. Validation cohort prediction and calibration performances were assessed using the following 4 statistical approaches: logistic regression with backward selection, l1-regularized logistic regression, k-nearest neighbor, and gradient boosting classifier. In-hospital mortality and intracranial mass effects could be predicted with high accuracy (both areas under the curve, 0.90 [95% CI, 0.90-0.90]), whereas the areas under the curve for intracerebral hemorrhage (0.80 [95% CI, 0.80-0.80]) and deep vein thrombosis (0.73 [95% CI, 0.73-0.73]) were considerably lower. Stroke severity was the overall most important predictor. Models based on gradient boosting achieved better performances than those based on logistic regression for all outcomes. However, area under the curve estimates differed by a maximum of 0.02. Conclusions We validated prediction models for 4 severe outcomes after acute ischemic stroke based on routinely collected, recent clinical data. Model performance was superior to previously proposed approaches. These predictions may help to identify patients at risk early after stroke and thus facilitate an individualized level of care.""]"
11,1134,11_imaging_brain_segmentation_segmentations,"['imaging', 'brain', 'segmentation', 'segmentations', 'mri', 'atlases', 'dimensional', 'scans', 'atlas', 'mapping']","['Multi-Atlas Segmentation of Anatomical Brain Structures Using Hierarchical Hypergraph Learning Accurate segmentation of anatomical brain structures is crucial for many neuroimaging applications, e.g., early brain development studies and the study of imaging biomarkers of neurodegenerative diseases. Although multi-atlas segmentation (MAS) has achieved many successes in the medical imaging area, this approach encounters limitations in segmenting anatomical structures associated with poor image contrast. To address this issue, we propose a new MAS method that uses a hypergraph learning framework to model the complex subject-within and subject-to-atlas image voxel relationships and propagate the label on the atlas image to the target subject image. To alleviate the low-image contrast issue, we propose two strategies equipped with our hypergraph learning framework. First, we use a hierarchical strategy that exploits high-level context features for hypergraph construction. Because the context features are computed on the tentatively estimated probability maps, we can ultimately turn the hypergraph learning into a hierarchical model. Second, instead of only propagating the labels from the atlas images to the target subject image, we use a dynamic label propagation strategy that can gradually use increasing reliably identified labels from the subject image to aid in predicting the labels on the difficult-to-label subject image voxels. Compared with the state-of-the-art label fusion methods, our results show that the hierarchical hypergraph learning framework can substantially improve the robustness and accuracy in the segmentation of anatomical brain structures with low image contrast from magnetic resonance (MR) images.', 'Construction and validation of mean shape atlas templates for atlas-based brain image segmentation In this paper, we evaluate different schemes for constructing a mean shape anatomical atlas for atlas-based segmentation of MR brain images. Each atlas is constructed and validated using a database of 20 images for which detailed manual delineations of 49 different subcortical structures are available. Atlas construction and atlas based segmentation are performed by non-rigid intensity-based registration using a viscous fluid deformation model with parameters that were optimally tuned for this particular task. The segmentation performance of each atlas scheme is evaluated on the same database using a leave-one-out approach and measured by the volume overlap of corresponding regions in the ground-truth manual segmentation and the warped atlas label image.', ""Brain MR Multimodal Medical Image Registration Based on Image Segmentation and Symmetric Self-similarity With the development of medical imaging technology, image registration has been widely used in the field of disease diagnosis. The registration between different modal images of brain magnetic resonance (MR) is particularly important for the diagnosis of brain diseases. However, previous registration methods don't take advantage of the prior knowledge of bilateral brain symmetry. Moreover, the difference in gray scale information of different modal images increases the difficulty of registration. In this paper, a multimodal medical image registration method based on image segmentation and symmetric self-similarity is proposed. This method uses modal independent self-similar information and modal consistency information to register images. More particularly, we propose two novel symmetric self-similarity constraint operators to constrain the segmented medical images and convert each modal medical image into a unified modal for multimodal image registration. The experimental results show that the proposed method can effectively reduce the error rate of brain MR multimodal medical image registration with rotation and translation transformations (average 0.43mm and 0.60mm) respectively, whose accuracy is better compared to state-of-the-art image registration methods.""]"
12,1022,12_neurosurgery_neurosurgical_surgical_preoperative,"['neurosurgery', 'neurosurgical', 'surgical', 'preoperative', 'surgeons', 'surgery', 'postoperative', 'intraoperative', 'surgeon', 'imaging']","['Non-invasive 3-D patient registration for image-guided skull base surgery Image-guided, computer-assisted surgery systems require a common reference between the preoperative image data and the corresponding patient pathology. Therefore, the problem of an accurate and reliable 3-D patient registration and referencing has to be solved. Considering that during image data acquisition patient misalignment and movement can arise in three dimensions, an automatic image registration method must be based on a three-dimensional approach. The method presented in this paper provides accurate 3-D patient registration for correction of these movement errors during data acquisition and active patient referencing to update the position of the head during surgery. Experimental data concerning the accuracy of repeated positionings of our patient registration and reference system demonstrated a high degree of accuracy with mean spatial errors of 0.82 mm +/- 0.31 mm in a plastic skull and 1.56 +/- 0.76 mm in patients, respectively. Results suggest that non-invasive 3-D patient registration for image-guided surgery may be a precise and useful method for computer-assisted identification of anatomical structures. Copyright (C) 1996 Elsevier Science Ltd.', ""Augmented reality in neurosurgical navigation: A survey Background Neurosurgery has exceptionally high requirements for minimally invasive and safety. This survey attempts to analyse the practical application of AR in neurosurgical navigation. Also, this survey describes future trends in augmented reality neurosurgical navigation systems. Methods In this survey, we searched related keywords 'augmented reality', 'virtual reality', 'neurosurgery', 'surgical simulation', 'brain tumour surgery', 'neurovascular surgery', 'temporal bone surgery' and 'spinal surgery' through Google Scholar, World Neurosurgery, PubMed and Science Direct. We collected 85 articles published over the past 5 years in areas related to this survey. Results Detailed study has been conducted on the application of AR in neurosurgery and found that AR is constantly improving the overall efficiency of doctor training and treatment, which can help neurosurgeons learn and practice surgical procedures with zero risks. Conclusions Neurosurgical navigation is essential in neurosurgery. Despite certain technical limitations, it is still a necessary tool for the pursuit of maximum security and minimal intrusiveness."", 'Surgical models for computer-assisted neurosurgery In this paper, we outline a way to improve computer-assisted neurosurgery using surgical models along with patient- specific models built from multimodal images. We propose a methodological framework for surgical models that include the definition of a surgical ontology, the development of software for describing surgical procedures based on this ontology and the analysis ofthese descriptions to generate knowledge about surgical practice. Knowledge generation is illustrated by two studies. One hundred fifty-nine patients who underwent brain tumor surgery were described from postoperative reports using the surgical ontology. First, from a subset of 106 surgical cases, we computed a decision tree using a prediction approach that gave probability in terms of operating room patient positioning percentages and according to tumor location within one or more lobes. Second, from the whole set of 159 surgical cases, we identified 6 clusters describing families of cases according to pathology-related parameters. Results from both studies showed possible prediction of parts of the surgical procedure from pathology- related characteristics of the patient. Surgical models enable surgical knowledge to be made explicit, facilitating the surgical decision-making process and surgical planning and improving the human-computer interface during surgery. (c) 2007 Elsevier Inc. All rights reserved.']"
13,955,13_neural_neuron_neurons_neuronal,"['neural', 'neuron', 'neurons', 'neuronal', 'neuroscience', 'cortex', 'neuromorphic', 'experimental', 'computational', 'brain']","['Learning and data clustering with an RBF-based spiking neuron network A spiking neuron is a simplified model of the biological neuron as the input, output, and internal representation of information based on the relative timing of individual spikes, and is closely related to the biological network. We extend the learning algorithms with spiking neurons developed by earlier workers. These algorithms explicitly concerned a single pair of pre- and postsynaptic spikes and cannot be applied to situations involving multiple spikes arriving at the same synapse. The aim of the algorithm presented here is to achieve synaptic plasticity by using relative timing between single pre- and postsynaptic spikes and therefore to improve the performance on large datasets. The learning algorithm is based on spike timing-dependent synaptic plasticity, which uses exact spike timing to optimize the information stream through the neural network as well as to enforce the competition between neurons during unsupervised Hebbian learning. We demonstrate the performance of the proposed spiking neuron model and learning algorithm on clustering and provide a comparative analysis with other state-of-the-art approaches.', 'A Spiking Neuron and Population Model Based on the Growth Transform Dynamical System In neuromorphic engineering, neural populations are generally modeled in a bottom-up manner, where individual neuron models are connected through synapses to form large-scale spiking networks. Alternatively, a top-down approach treats the process of spike generation and neural representation of excitation in the context of minimizing some measure of network energy. However, these approaches usually define the energy functional in terms of some statistical measure of spiking activity (ex. firing rates), which does not allow independent control and optimization of neurodynamical parameters. In this paper, we introduce a new spiking neuron and population model where the dynamical and spiking responses of neurons can be derived directly from a network objective or energy functional of continuous-valued neural variables like the membrane potential. The key advantage of the model is that it allows for independent control over three neuro-dynamical properties: (a) control over the steady-state population dynamics that encodes the minimum of an exact network energy functional; (b) control over the shape of the action potentials generated by individual neurons in the network without affecting the network minimum; and (c) control over spiking statistics and transient population dynamics without affecting the network minimum or the shape of action potentials. At the core of the proposed model are different variants of Growth Transform dynamical systems that produce stable and interpretable population dynamics, irrespective of the network size and the type of neuronal connectivity (inhibitory or excitatory). In this paper, we present several examples where the proposed model has been configured to produce different types of single-neuron dynamics as well as population dynamics. In one such example, the network is shown to adapt such that it encodes the steady-state solution using a reduced number of spikes upon convergence to the optimal solution. In this paper, we use this network to construct a spiking associative memory that uses fewer spikes compared to conventional architectures, while maintaining high recall accuracy at high memory loads.', 'Supervised Learning Algorithm for Multilayer Spiking Neural Networks with Long-Term Memory Spike Response Model As a new brain-inspired computational model of artificial neural networks, spiking neural networks transmit and process information via precisely timed spike trains. Constructing efficient learning methods is a significant research field in spiking neural networks. In this paper, we present a supervised learning algorithm for multilayer feedforward spiking neural networks; all neurons can fire multiple spikes in all layers. The feedforward network consists of spiking neurons governed by biologically plausible long-term memory spike response model, in which the effect of earlier spikes on the refractoriness is not neglected to incorporate adaptation effects. The gradient descent method is employed to derive synaptic weight updating rule for learning spike trains. The proposed algorithm is tested and verified on spatiotemporal pattern learning problems, including a set of spike train learning tasks and nonlinear pattern classification problems on four UCI datasets. Simulation results indicate that the proposed algorithm can improve learning accuracy in comparison with other supervised learning algorithms.']"
14,883,14_imaging_mri_brain_diffusion,"['imaging', 'mri', 'brain', 'diffusion', 'dmri', 'tractography', 'resonance', 'resolution', 'tensor', 'data']","['Sparse Reconstruction Challenge for diffusion MRI: Validation on a physical phantom to determine which acquisition scheme and analysis method to use? Diffusion magnetic resonance imaging (dMRI) is the modality of choice for investigating in-vivo white matter connectivity and neural tissue architecture of the brain. The diffusion-weighted signal in dMRI reflects the diffusivity of water molecules in brain tissue and can be utilized to produce image-based biomarkers for clinical research. Due to the constraints on scanning time, a limited number of measurements can be acquired within a clinically feasible scan time. In order to reconstruct the dMRI signal from a discrete set of measurements, a large number of algorithms have been proposed in recent years in conjunction with varying sampling schemes, i.e., with varying b-values and gradient directions. Thus, it is imperative to compare the performance of these reconstruction methods on a single data set to provide appropriate guidelines to neuroscientists on making an informed decision while designing their acquisition protocols. For this purpose, the SPArse Reconstruction Challenge (SPARC) was held along with the workshop on Computational Diffusion MRI (at MICCAI 2014) to validate the performance of multiple reconstruction methods using data acquired from a physical phantom. A total of 16 reconstruction algorithms (9 teams) participated in this community challenge. The goal was to reconstruct single b-value and/or multiple b-value data from a sparse set of measurements. In particular, the aim was to determine an appropriate acquisition protocol (in terms of the number of measurements, b-values) and the analysis method to use for a neuroimaging study. The challenge did not delve on the accuracy of these methods in estimating model specific measures such as fractional anisotropy (FA) or mean diffusivity, but on the accuracy of these methods to fit the data. This paper presents several quantitative results pertaining to each reconstruction algorithm. The conclusions in this paper provide a valuable guideline for choosing a suitable algorithm and the corresponding data-sampling scheme for clinical neuroscience applications. (C) 2015 Elsevier B.V. All rights reserved.', 'Processing and visualization for diffusion tensor MRI This paper presents processing and visualization techniques for Diffusion Tensor Magnetic Resonance Imaging (DT-MRI). In DT-MRI, each voxel is assigned a tensor that describes local water diffusion. The geometric nature of diffusion tensors enables us to quantitatively characterize the local structure in tissues such as bone, muscle, and white matter of the brain. This makes DT-MRI an interesting modality for image analysis. In this paper we present a novel analytical solution to the Stejskal-Tanner diffusion equation system whereby a dual tensor basis, derived from the diffusion sensitizing gradient configuration, eliminates the need to solve this equation for each voxel. We further describe decomposition of the diffusion tensor based on its symmetrical properties, which in turn describe the geometry of the diffusion ellipsoid. A simple anisotropy measure follows naturally from this analysis. We describe how the geometry or shape of the tensor can be visualized using a coloring scheme based on the derived shape measures. In addition, we demonstrate that human brain tensor data when filtered can effectively describe macrostructural diffusion, which is important in the assessment of fiber-tract organization. We also describe how white matter pathways can be monitored with the methods introduced in this paper. DT-MRI tractography is useful for demonstrating neural connectivity (in vivo) in healthy and diseased brain tissue. (C) 2002 Elsevier Science B.V. All rights reserved.', 'A joint compressed-sensing and super-resolution approach for very high-resolution diffusion imaging Diffusion MRI (dMRI) can provide invaluable information about the structure of different tissue types in the brain. Standard dMRI acquisitions facilitate a proper analysis (e.g. tracing) of medium-to-large white matter bundles. However, smaller fiber bundles connecting very small cortical or sub-cortical regions cannot be traced accurately in images with large voxel sizes. Yet, the ability to trace such fiber bundles is critical for several applications such as deep brain stimulation and neurosurgery. In this work, we propose a novel acquisition and reconstruction scheme for obtaining high spatial resolution dMRI images using multiple low resolution (LR) images, which is effective in reducing acquisition time while improving the signal-to-noise ratio (SNR). The proposed method called compressed-sensing super resolution reconstruction (CS-SRR), uses multiple overlapping thick-slice dMRI volumes that are under-sampled in q-space to reconstruct diffusion signal with complex orientations. The proposed method combines the twin concepts of compressed sensing and super-resolution to model the diffusion signal (at a given b-value) in a basis of spherical ridgelets with total-variation (TV) regularization to account for signal correlation in neighboring voxels. A computationally efficient algorithm based on the alternating direction method of multipliers (ADMM) is introduced for solving the CS-SRR problem. The performance of the proposed method is quantitatively evaluated on several in-vivo human data sets including a true SRR scenario. Our experimental results demonstrate that the proposed method can be used for reconstructing sub-millimeter super resolution dMRI data with very good data fidelity in clinically feasible acquisition time. (C) 2015 Elsevier Inc. All rights reserved.']"
15,862,15_epilepsy_epileptic_seizures_seizure,"['epilepsy', 'epileptic', 'seizures', 'seizure', 'epileptogenic', 'epileptiform', 'electroencephalogram', 'electroencephalography', 'neural', 'brain']","['Exploring Hermite transformation in brain signal analysis for the detection of epileptic seizure Automatic detection of epileptic seizure from brain signal data (e.g. electroencephalogram (EEG)) is very crucial due to dynamic and complex nature of EEG signal (e.g. non-stationarity, aperiodic and chaotic). Owing to these natures, manual interpretation and detection of epileptic seizure is not reliable and efficient process. Hence, this study is intended to develop a new computer-aided detection system that can automatically and efficiently identify epileptic seizure from huge amount EEG data. In this study, Hermite Transform is introduced for extracting discriminating information from EEG data for the detection of epileptic seizure. The analysis is performed in three stages: EEG signal transformation into a new form by Hermite Transform; computation of three types of features, namely permutation entropy, histogram feature and statistical feature; and classification of obtained features by least square support vector machine. The classification outcomes reveal the presence of epileptic seizure. The proposed method is evaluated on a benchmark Epileptic EEG database (Bonn University data) and the performance of this method is compared with several state-of-art algorithms for the same database. The experimental results demonstrate that the proposed scheme has the ability to efficiently detect epileptic seizure from EEG data outperforming competing techniques in terms of overall classification accuracy.', 'Machine Learning Characterization of Ictal and Interictal States in EEG Aimed at Automated Seizure Detection Background: The development of automated seizure detection methods using EEG signals could be of great importance for the diagnosis and the monitoring of patients with epilepsy. These methods are often patient-specific and require high accuracy in detecting seizures but also very low false-positive rates. The aim of this study is to evaluate the performance of a seizure detection method using EEG signals by investigating its performance in correctly identifying seizures and in minimizing false alarms and to determine if it is generalizable to different patients. Methods: We tested the method on about two hours of preictal/ictal and about ten hours of interictal EEG recordings of one patient from the Freiburg Seizure Prediction EEG database using machine learning techniques for data mining. Then, we tested the obtained model on six other patients of the same database. Results: The method achieved very high performance in detecting seizures (close to 100% of correctly classified positive elements) with a very low false-positive rate when tested on one patient. Furthermore, the model portability or transfer analysis revealed that the method achieved good performance in one out of six patients from the same dataset. Conclusions: This result suggests a strategy to discover clusters of similar patients, for which it would be possible to train a general-purpose model for seizure detection.', 'Fuzzy-Based Automatic Epileptic Seizure Detection Framework Detection of epileptic seizures on the basis of Electroencephalogram (EEG) recordings is a challenging task due to the complex, non-stationary and non-linear nature of these biomedical signals. In the existing literature, a number of automatic epileptic seizure detection methods have been proposed that extract useful features from EEG segments and classify them using machine learning algorithms. Some characterizing features of epileptic and non-epileptic EEG signals overlap; therefore, it requires that analysis of signals must be performed from diverse perspectives. Few studies analyzed these signals in diverse domains to identify distinguishing characteristics of epileptic EEG signals. To pose the challenge mentioned above, in this paper, a fuzzy-based epileptic seizure detection model is proposed that incorporates a novel feature extraction and selection method along with fuzzy classifiers. The proposed work extracts pattern features along with time-domain, frequency domain, and non-linear analysis of signals. It applies a feature selection strategy on extracted features to get more discriminating features that build fuzzy machine learning classifiers for the detection of epileptic seizures. The empirical evaluation of the proposed model was conducted on the benchmark Bonn EEG dataset. It shows significant accuracy of 98% to 100% for normal vs. ictal classification cases while for three class classification of normal vs. inter-ictal vs. ictal accuracy reaches to above 97.5%. The obtained results for ten classification cases (including normal, seizure or ictal, and seizure-free or inter-ictal classes) prove the superior performance of proposed work as compared to other state-of-the-art counterparts.']"
16,859,16_neurodegenerative_neural_pd_disorders,"['neurodegenerative', 'neural', 'pd', 'disorders', 'disorder', 'dopaminergic', 'diagnosis', 'disease', 'brain', 'symptoms']","[""Machine Learning for the Diagnosis of Parkinson's Disease: A Review of Literature Diagnosis of Parkinson's disease (PD) is commonly based on medical observations and assessment of clinical signs, including the characterization of a variety of motor symptoms. However, traditional diagnostic approaches may suffer from subjectivity as they rely on the evaluation of movements that are sometimes subtle to human eyes and therefore difficult to classify, leading to possible misclassification. In the meantime, early non-motor symptoms of PD may be mild and can be caused by many other conditions. Therefore, these symptoms are often overlooked, making diagnosis of PD at an early stage challenging. To address these difficulties and to refine the diagnosis and assessment procedures of PD, machine learning methods have been implemented for the classification of PD and healthy controls or patients with similar clinical presentations (e.g., movement disorders or other Parkinsonian syndromes). To provide a comprehensive overview of data modalities and machine learning methods that have been used in the diagnosis and differential diagnosis of PD, in this study, we conducted a literature review of studies published until February 14, 2020, using the PubMed and IEEE Xplore databases. A total of 209 studies were included, extracted for relevant information and presented in this review, with an investigation of their aims, sources of data, types of data, machine learning methods and associated outcomes. These studies demonstrate a high potential for adaptation of machine learning methods and novel biomarkers in clinical decision making, leading to increasingly systematic, informed diagnosis of PD."", ""A computerized method to assess Parkinson's disease severity from gait variability based on gender Parkinson's disease (PD) is related to dopaminergic neuronal loss and it is progressive. Although there is no available cure for the disease yet, symptom-based treatments are available. PD can be clinically misdiagnosed in early stages because motor features become evident long after the onset of neuronal loss. Therefore, different remote monitoring tests were studied by the scholars for early detection. It has shown that people with PD exhibit gait variability with respect to healthy subjects. In this study, gait signals of PD patients were analyzed to detect severity of PD. Gait signals were converted to fuzzy recurrence plots and deep features were extracted. Machine learning techniques were applied to perform several classification experiments. Binary classifications to discriminate PD patients and multiclass classifications to predict the disease severity based on gender were conducted. Experimental results were assessed with different performance metrics. In PD severity prediction, gender based classification tests produced better performances than the test involving all cases. Proposed system produced state of the art results. The system estimated the disease severity with 1.00 and 0.99 accuracies for females and males respectively."", ""Age-gender specific prediction model for Parkinson' s severity assessment using gait biomarkers Parkinson's disease (PD) causes gait impairments resulting in tremor, balance instabilities, increased fall risk, and disability. The current clinical diagnosis success rate is around 80%. Thus, automated classification of these impairments in gait with machine learning techniques can serve as an assessment tool for identification of PD. The primary focus of the study is to investigate anthropometric parameter-based models for classification of non-PD and PD subjects together with their severity. The proposed work performs the computation of clinically relevant features using Vertical Ground Reaction Force (VGRF) data from a total of 165 individuals' database consisting 93 Parkinson's and 72 healthy controls. All extracted features are tested for significance and redundancy among other gait characteristics. The optimal combination of features is selected using Recursive Feature Elimination technique with 10-fold cross validation for classification. In this study, wide range of machine learning techniques from different domains are used and their performance is evaluated based on accuracy, specificity, recall, precision and F1-score. Both gender and age-gender specific models outperformed the generalized model for PD as well as PD severity assessment. The highest prediction accuracy reported for age-gender specific models is 98.50% (non-PD and PD) using Support Vector Machine (SVM) classifier and 97.76% (non-PD and PD with severity scales) using k-Nearest Neighbor (kNN) and SVM. This study demonstrates integration of gait data with machine learning techniques as a potential biomarker for assessment of PD severity. (C) 2021 Karabuk University. Publishing services by Elsevier B.V.""]"
17,817,17_emotions_emotion_emotional_affective,"['emotions', 'emotion', 'emotional', 'affective', 'stimuli', 'neural', 'recognition', 'electroencephalogram', 'brain', 'signals']","['Emotion recognition using spatial-temporal EEG features through convolutional graph attention network Objective. Constructing an efficient human emotion recognition model based on electroencephalogram (EEG) signals is significant for realizing emotional brain-computer interaction and improving machine intelligence. Approach. In this paper, we present a spatial-temporal feature fused convolutional graph attention network (STFCGAT) model based on multi-channel EEG signals for human emotion recognition. First, we combined the single-channel differential entropy (DE) feature with the cross-channel functional connectivity (FC) feature to extract both the temporal variation and spatial topological information of EEG. After that, a novel convolutional graph attention network was used to fuse the DE and FC features and further extract higher-level graph structural information with sufficient expressive power for emotion recognition. Furthermore, we introduced a multi-headed attention mechanism in graph neural networks to improve the generalization ability of the model. Main results. We evaluated the emotion recognition performance of our proposed model on the public SEED and DEAP datasets, which achieved a classification accuracy of 99.11% +/- 0.83% and 94.83% +/- 3.41% in the subject-dependent and subject-independent experiments on the SEED dataset, and achieved an accuracy of 91.19% +/- 1.24% and 92.03% +/- 4.57% for discrimination of arousal and valence in subject-independent experiments on DEAP dataset. Notably, our model achieved state-of-the-art performance on cross-subject emotion recognition tasks for both datasets. In addition, we gained insight into the proposed frame through both the ablation experiments and the analysis of spatial patterns of FC and DE features. Significance. All these results prove the effectiveness of the STFCGAT architecture for emotion recognition and also indicate that there are significant differences in the spatial-temporal characteristics of the brain under different emotional states.', ""Improving BCI-based emotion recognition by combining EEG feature selection and kernel classifiers Current emotion recognition computational techniques have been successful on associating the emotional changes with the EEG signals, and so they can be identified and classified from EEG signals if appropriate stimuli are applied. However, automatic recognition is usually restricted to a small number of emotions classes mainly due to signal's features and noise, EEG constraints and subject-dependent issues. In order to address these issues, in this paper a novel feature-based emotion recognition model is proposed for EEG based Brain-Computer Interfaces. Unlike other approaches, our method explores a wider set of emotion types and incorporates additional features which are relevant for signal pre-processing and recognition classification tasks, based on a dimensional model of emotions: Valence and Arousal. It aims to improve the accuracy of the emotion classification task by combining mutual information based feature selection methods and kernel classifiers. Experiments using our approach for emotion classification which combines efficient feature selection methods and efficient kernel-based classifiers on standard EEG datasets show the promise of the approach when compared with state-of-the-art computational methods. (C) 2015 Elsevier Ltd. All rights reserved."", ""Expression-EEG Based Collaborative Multimodal Emotion Recognition Using Deep AutoEncoder Emotion recognition has shown many valuable roles in people's lives under the background of artificial intelligence technology. However, most existing emotion recognition methods have poor recognition performance, which prevents their promotion in practical applications. To alleviate this problem, we proposed an expression-EEG interaction multi-modal emotion recognition method using a deep automatic encoder. Firstly, decision tree is applied as objective feature selection method. Then, based on the facial expression features recognized by sparse representation, the solution vector coefficients are analyzed to determine the facial expression category of the test samples. After that, the bimodal deep automatic encoder is adopted to fuse the EEG signals and facial expression signals. The third layer of BDAE extracts features for training of supervised learning. Finally, LIBSVM classifier is used to complete classification task. We carried out experiments on a constructed video library to verify the proposed emotion recognition method. The results show that the proposed method can effectively extract and integrate high-level emotion-related features in EEG and facial expression signals. The recognition rate of discrete emotion state type and the average emotion recognition rate have been improved relatively, in which the average emotion recognition rate is 85.71%. Overall, the emotion recognition ability has been greatly improved.""]"
18,753,18_virtual_reality_experiences_dementia,"['virtual', 'reality', 'experiences', 'dementia', 'illusion', 'experience', 'cognitive', 'immersive', 'schizophrenia', 'visual']","[""Virtual Embodiment Using 180 degrees Stereoscopic Video One of the most exciting possibilities of virtual reality is inducing in participants the illusion of owning a virtual body. This has become an established methodological paradigm allowing the study of the psychological and neural correlates of various scenarios that are impossible in the real world, such as gender or age switching. Thus far, full-body ownership illusions have been implemented by using real-time body tracking and avatars based on computer-generated imagery (CGI). We propose an alternative technique to induce perceived ownership over a (photorealistic) virtual body using 180 degrees stereoscopic video, synchronous touch, and narration. We describe the technical components of our novel technique and an example implementation as part of a science-art project that enables participants to experience virtual bodies of different ages, and present the results of an experimental evaluation study based on this experience. Consistent with previous virtual embodiment studies using CGI-based techniques, we found that participants accept a photorealistic virtual body as their own irrespective of its appearance as indicated by similar ratings of the strength of body ownership over a virtual body of a child versus an adult. We further show that our novel technique can alter participants' cognition in accordance with the characteristics of their virtual body. Specifically, young adult participants who were embodied in the virtual body of a child significantly overestimated the duration of the virtual reality experience compared to a control group who was embodied in a virtual body of their own age. This finding corresponds to chronological age differences in time estimations and extends previous research on virtual child embodiment. Overall, these findings provide initial evidence for the potential of our novel technique to create photorealistic embodiment experiences with comparable psychological effects as have been found using CGI-based techniques while reducing the costs and technical complexity in the production and application of virtual body ownership illusions."", 'Virtual reality and mental health in older adults: a systematic review Importance: Virtual reality (VR) is a promising tool with the potential to enhance care of cognitive and affective disorders in the aging population. VR has been implemented in clinical settings with adolescents and children; however, it has been less studied in the geriatric population. Objective: The objective of this study is to determine the existing levels of evidence for VR use in clinical settings and identify areas where more evidence may guide translation of existing VR interventions for older adults. Design and measurements: We conducted a systematic review in PubMed and Web of Science in November 2019 for peer-reviewed journal articles on VR technology and its applications in older adults. We reviewed article content and extracted the number of study participants, study population, goal of the investigation, the level of evidence, and categorized articles based on the indication of the VR technology and the study population. Results: The database search yielded 1554 total results, and 55 articles were included in the final synthesis. The most represented study design was cross-sectional, and the most common study population was subjects with cognitive impairment. Articles fell into three categories for VR Indication: Testing, Training, and Screening. There was a wide variety of VR environments used across studies. Conclusions: Existing evidence offers support for VR as a screening and training tool for cognitive impairment in older adults. VR-based tasks demonstrated validity comparable to some paper-based assessments of cognition, though more work is needed to refine diagnostic specificity. The variety of VR environments used shows a need for standardization before comparisons can be made across VR simulations. Future studies should address key issues such as usability, data privacy, and confidentiality. Since most literature was generated from high-income countries (HICs), it remains unclear how this may be translated to other parts of the world.', 'A Literature Overview of Virtual Reality (VR) in Treatment of Psychiatric Disorders: Recent Advances and Limitations In this paper, we conduct a literature survey on various virtual reality (VR) treatments in psychiatry. We collected 36 studies that used VR to provide clinical trials or therapies for patients with psychiatric disorders. In order to gain a better understanding of the management of pain and stress, we first investigate VR applications for patients to alleviate pain and stress during immersive activities in a virtual environment. VR exposure therapies are particularly effective for anxiety, provoking realistic reactions to feared stimuli. On top of that, exposure therapies with simulated images are beneficial for patients with psychiatric disorders such as phobia and posttraumatic stress disorder (PTSD). Moreover, VR environments have shown the possibility of changing depression, cognition, even social functions. We review empirical evidence from VR-based treatments on psychiatric illnesses such as dementia, mild cognitive impairment (MCI), schizophrenia and autism. Through cognitive training and social skill training, rehabilitation through VR therapies helps patients to improve their quality of life. Recent advances in VR technology also demonstrate potential abilities to address cognitive and functional impairments in dementia. In terms of the different types of VR systems, we discuss the feasibility of the technology within different stages of dementia as well as the methodological limitations. Although there is room for improvement, its widespread adoption in psychiatry is yet to occur due to technical drawbacks such as motion sickness and dry eyes, as well as user issues such as preoccupation and addiction. However, it is worth mentioning that VR systems relatively easily deliver virtual environments with well-controlled sensory stimuli. In the future, VR systems may become an innovative clinical tool for patients with specific psychiatric symptoms.']"
19,682,19_hand_wrist_stimulation_hands,"['hand', 'wrist', 'stimulation', 'hands', 'touch', 'prosthesis', 'arm', 'fingers', 'grip', 'manipulation']","['Surface EMG in advanced hand prosthetics One of the major problems when dealing with highly dexterous, active hand prostheses is their control by the patient wearing them. With the advances in mechatronics, building prosthetic hands with multiple active degrees of freedom is realisable, but actively controlling the position and especially the exerted force of each finger cannot yet be done naturally. This paper deals with advanced robotic hand control via surface electromyography. Building upon recent results, we show that machine learning, together with a simple downsampling algorithm, can be effectively used to control on-line, in real time, finger position as well as finger force of a highly dexterous robotic hand. The system determines the type of grasp a human subject is willing to use, and the required amount of force involved, with a high degree of accuracy. This represents a remarkable improvement with respect to the state-of-the-art of feed-forward control of dexterous mechanical hands, and opens up a scenario in which amputees will be able to control hand prostheses in a much finer way than it has so far been possible.', 'Visual and haptic feedback in the control of force The ability to control index finger and elbow flexion forces was measured while subjects used either haptic feedback or both haptic and visual feedback to control the forces exerted. Over a 120-s time period subjects were able to control the finger forces ranging from 2 to 6 N to within 1 N using only haptic feedback, and elbow flexion forces to within 4.5 N over a force range of 10-30 N, At the same force amplitude there was no significant difference between the two muscle groups in the precision or accuracy with which the force could be controlled, suggesting that there is not a proximal to distal gradient in force control as has been found for the control of limb movement and position.', ""Object Recognition via Evoked Sensory Feedback during Control of a Prosthetic Hand Haptic and proprioceptive feedback is critical for sensorimotor integration when we use our hand to perform daily tasks. Here, we evaluated how externally evoked haptic and proprioceptive feedback and myoelectric control strategies affected the recognition of object properties when participants controlled a prosthetic hand. Fingertip haptic sensation was elicited using a transcutaneous nerve stimulation grid to encode the prosthetic's fingertip forces. An array of tactors elicited patterned vibratory stimuli to encode tactile-proprioceptive kinematic information of the prosthetic finger joint. Myoelectric signals of the finger flexor and extensor were used to control the position or velocity of joint angles of the prosthesis. Participants were asked to perform object property (stiffness and size) recognition, by controlling the prosthetic hand with concurrent haptic and tactile-proprioceptive feedback. With the evoked feedback, intact and amputee participants recognized the object stiffness and size at success rates ranging from 50% to 100% in both position and velocity control with no significant difference across control schemes. Our findings show that evoked somatosensory feedback in a non-invasive manner can facilitate closed-loop control of the prosthetic hand and allowed for simultaneous recognition of different object properties. The outcomes can facilitate our understanding on the role of sensory feedback during bidirectional human-machine interactions, which can potentially promote user experience in object interactions using prosthetic hands.""]"
20,645,20_cognition_cognitive_brain_neural,"['cognition', 'cognitive', 'brain', 'neural', 'neuroscience', 'intelligence', 'cortex', 'intelligent', 'mental', 'consciousness']","['Executive control by fronto-parietal activity explains counterintuitive decision behavior in complex value-based decision-making In real life, humans make decisions by taking into account multiple independent factors, such as delay and probability. Cognitive psychology suggests that cognitive control mechanisms play a key role when facing such complex task conditions. However, in value-based decision-making, it still remains unclear to what extent cognitive control mechanisms become essential when the task condition is complex. In this study, we investigated decision-making behaviors and underlying neural mechanisms using a multifactor gambling task where participants simultaneously considered probability and delay. Decision-making behavior in the multifactor task was modulated by both probability and delay. The behavioral effect of probability was stronger than delay, consistent with previous studies. Furthermore, in a subset of conditions that recruited fronto-parietal activations, reaction times were paradoxically elongated despite lower probabilistic uncertainty. Notably, such a reaction time elongation did not occur in control tasks involving single factors. Meta-analysis of brain activations suggested an interpretation that the paradoxical increase of reaction time may be associated with strategy switching. Consistent with this interpretation, logistic regression analysis of the behavioral data suggested a presence of multiple decision strategies. Taken together, we found that a novel complex value-based decision-making task cause prominent activations in fronto-parietal cortex. Furthermore, we propose that these activations can be interpreted as recruitment of cognitive control system in complex situations.', ""PASAR: An integrated model of prediction, anticipation, sensation, attention and response for artificial sensorimotor systems A wide range of neuroscientific studies suggest the existence of cognitive mechanisms like attention, prediction, anticipation and strong vertical interactions between different hierarchical layers of the brain while performing complex tasks. Despite advances in both cognitive brain research and in the development of brain-inspired artificial cognitive systems, the interplay of these key ingredients of cognition remain largely elusive and unquantified in complex real-world tasks. Furthermore, it has not yet been demonstrated how a self-contained hierarchical cognitive system acting under limited resource constraints can quantifiably benefit from the incorporation of top-down and bottom-up attentional mechanisms. In this context, an open fundamental question is how a data association mechanism can integrate bottom-up sensory information and top-down knowledge. Here, building on the Distributed Adaptive Control (DAC) architecture, we propose a single framework for integrating these different components of cognition and demonstrate the framework's performance in solving real-world and simulated robot tasks. Using the model we quantify the interactions between prediction, anticipation, attention and memory. Our results support the strength of a complete system that incorporates attention, prediction and anticipation mechanisms compared to incomplete systems for real-world and complex tasks. We unveil the relevance of transient memory that underlines the utility of the above mechanisms for intelligent knowledge management in artificial sensorimotor systems. These findings provide concrete predictions for physiological and psychophysical experiments to validate our model in biological cognitive systems. (C) 2011 Elsevier Inc. All rights reserved."", 'Sensory processing and categorization in cortical and deep neural networks Many recent advances in artificial intelligence (AI) are rooted in visual neuroscience. However, ideas from more complicated paradigms like decision-making are less used. Although automated decision-making systems are ubiquitous (driverless cars, pilot support systems, medical diagnosis algorithms etc.), achieving human-level performance in decision making tasks is still a challenge. At the same time, these tasks that are hard for AI are easy for humans. Thus, understanding human brain dynamics during these decision-making tasks and modeling them using deep neural networks could improve AI performance. Here we modelled some of the complex neural interactions during a sensorimotor decision making task. We investigated how brain dynamics flexibly represented and distinguished between sensory processing and categorization in two sensory domains: motion direction and color. We used two different approaches for understanding neural representations. We compared brain responses to 1) the geometry of a sensory or category domain (domain selectivity) and 2) predictions from deep neural networks (computation selectivity). Both approaches gave us similar results. This confirmed the validity of our analyses. Using the first approach, we found that neural representations changed depending on context. We then trained deep recurrent neural networks to perform the same tasks as the animals. Using the second approach, we found that computations in different brain areas also changed flexibly depending on context. Color computations appeared to rely more on sensory processing, while motion computations more on abstract categories. Overall, our results shed light to the biological basis of categorization and differences in selectivity and computations in different brain areas. They also suggest a way for studying sensory and categorical representations in the brain: compare brain responses to both a behavioral model and a deep neural network and test if they give similar results.']"
21,569,21_sleepiness_sleep_circadian_wakefulness,"['sleepiness', 'sleep', 'circadian', 'wakefulness', 'insomnia', 'wake', 'night', 'analysis', 'neural', 'dataset']","[""Transfer Learning Convolutional Neural Network for Sleep Stage Classification Using Two-Stage Data Fusion Framework The most important part of sleep quality assessment is the classification of sleep stages, which helps to diagnose sleep-related disease. In the traditional sleep staging method, subjects have to spend a night in the sleep clinic for recording polysomnogram. Sleep expert classifies the sleep stages by monitoring the signals, which is time consuming and frustrating task and can be affected by human error. New studies propose fully automated techniques for classifying sleep stages that makes sleep scoring possible at home. Despite comprehensive studies have been presented in this field the classification results have not yet reached the gold standard due to the concentration on the use of a limited source of information such as single channel EEG. Therefore, this article introduces a new method for fusing two sources of information, including electroencephalogram (EEG) and electrooculogram (EOG), to achieve promising results in the classification of sleep stages. In the proposed method, extracted features from the EEG and EOG signals, are divided into two feature sets consisting of the EEG features and fused features of EEG and EOG. Then, each feature set transformed into a horizontal visibility graph (HVG). The images of the HVG are produced in a novel framework and classified by proposed transfer learning convolutional neural network for data fusion (TLCNN-DF). Employing transfer learning at the training stage of the model has accelerated the training process of the CNN and improved the performance of the model. The proposed algorithm is used to classify the Sleep-EDF and Sleep-EDFx benchmark datasets. The algorithm can classify the Sleep-EDF dataset with an accuracy of 93.58% and Cohen's kappa coefficient of 0.899. The results show proposed method can achieve superior performance compared to state-of-the-art studies on classification of sleep stages. Furthermore, it can attain reliable results as an alternative to conventional sleep staging."", 'Extracting more information from EEG recordings for a better description of sleep We are introducing and validating an EEG data-based model of the sleep process with an arbitrary number of different sleep stages and a high time resolution allowing modeling of sleep microstructure. In contrast to the standard practice of sleep staging, defined by scoring rules, we describe sleep via posterior probabilities of a finite number of states, not necessarily reflecting the traditional sleep stages. To test the proposed probabilistic sleep model (PSM) for validity, we correlate statistics derived from the state posteriors with the results of psychometric tests, physiological variables and questionnaires collected before and after sleep. Considering short, in this study 3s long, data window the PSM allows describing the sleep process on finer time scale in comparison to the traditional sleep staging based on 20 or 30s long data segments visual inspection. By combining sleep states and using two measures derived from the posterior curves we show that the average absolute correlations between the measures and subjective and objective sleep quality measures are considerably higher when compared with the analogous measures derived from hypnograms based on sleep staging. In most cases these differences are significant. The results obtained with the PSM support its wider use in sleep process modeling research and these results also suggest that EEG signals contain more information about sleep than what sleep profiles based on discrete stages can reveal. Therefore the standardized scoring of sleep may not be sufficient to reveal important sleep changes related to subjective and objective sleep quality indexes. The proposed PSM represents a promising alternative. (C) 2012 Elsevier Ireland Ltd. All rights reserved.', 'Profiling continuous sleep representations for better understanding of the dynamic character of normal sleep The amount and quality of sleep substantially influences health, daily behaviour and overall quality of life. The main goal of this study was to investigate to what extent sleep structure, as derived from the polysomnographic (PSG) recordings of nocturnal human sleep, can provide information about sleep quality in terms of correlating with a set of variables representing the daytime subjective, neurophysiological and cognitive states of a healthy population without serious sleep problems. We focused on a continuous sleep representation derived from the probabilistic sleep model (PSM), which describes the microstructure of sleep by a set of sleep probabilistic curves representing a finite number of sleep microstates. This contrasts with approaches where sleep is characterised by a set of one-dimensional sleep measures derived from the standard discrete sleep staging. Considering this continuous sleep representation, we aimed to identify typical sleep profiles that represent the dynamic aspect of sleep during the night and that are associated with a set of studied daily life quality measures.']"
22,533,22_voltage_circuit_capacitor_electric,"['voltage', 'circuit', 'capacitor', 'electric', 'power', 'insulation', 'converters', 'converter', 'current', 'inverter']","['An Asymmetric Switched-Capacitor Multicell Inverter With Low Number of DC Source and Voltage Stress for Renewable Energy Sources Asymmetric multilevel inverters generate high-quality output voltage using the same number of components as symmetric multilevel inverters. The main drawback of these topologies is that they require many DC voltage sources, and the power switches must endure high voltage stress. In this paper, a switched-capacitor sub-module inverter topology is proposed to reduce the number of DC voltage sources and the voltage stress on the switches of asymmetric multilevel inverters. The proposed sub-module inverter can generate 15 voltage levels by using two DC power supplies and a capacitor. The voltage of the capacitor can be automatically charged at half of the input DC power supply without the need for any sensors. In addition, the capacitor charging operation does not produce an inrush current because it is charged by the direction of the output current; this is an advantage over switched capacitor multilevel inverters. A modular topology is also presented based on the proposed sub-module inverter to achieve high voltage levels while reducing the number of elements. A comprehensive comparison between the proposal and other multilevel inverter topologies is performed to validate the design of the proposed inverter. In addition, thermal and loss distribution simulations of the proposed sub-module inverter are performed. Finally, the performance, efficiency, and accuracy of the proposed inverter are confirmed through laboratory prototyping.', ""An Ultra High Step-Up DC-DC Converter Based on the Boost, Luo, and Voltage Doubler Structure: Mathematical Expression, Simulation, and Experimental This paper presents a novel design of step-up DC-DC converters whose merits are: (i) The continuity of the input current has been kept; (ii) The polarity of the output voltage has been kept positive which provides the same ground of the input source and load; (iii) The low voltage gain of the quadratic converters has been solved that it can increase the input voltage to 10 times more by the low value of the duty cycle; (iv) Apart from the high value of the voltage gain, the semiconductors' voltage and current stresses were lower than the output voltage and input current of the converter which are the highest value of the voltage and current respectively and semiconductor based components do not suffer from high value of the current/voltage stresses; (v) Additionally, the voltage/current stresses are low, and the efficiency is good according to its 90 percent value. The analysis of the non-ideal voltage gain has been done and its better function has been deduced by comparing it with the recently proposed non-isolated topologies. Additionally, the non-isolated voltage gain has been studied for different output power levels. The efficiency has been extracted and discussed for varying duty cycles and output power based on ignoring some losses. Experimental results and simulation outcomes from the PLECS software have been compared along with theoretical relationships. The prototype of the topology has been tested at 100 W output power, 100 V output voltage, and 10 V input voltage."", 'Transformerless High Step-Up DC-DC Converter With Low Voltage Stress for Fuel Cells Conventional dc-dc boost converter has limited boost capacity, and its power device suffers high voltage stress. A novel hybrid Z-source dc-dc converter featured with high step-up capability and low device voltage stress is proposed in this article. Compared with the basic structure, the proposed topology can achieve higher voltage gain under the same duty ratio, and reduce the voltage stresses on the switch and diode under the same output condition. Moreover, the duty ratio is not limited. The detailed analysis and a comparison considering the proposed and other structures are also presented, which confirms its unique advantages. To verify the proposed converter performance, a prototype circuit with 40V-60V input voltage, 400V output voltage and 200W output power is built in the laboratory. Experiment results confirm the analysis and the boost capacity of the proposed converter.']"
23,507,23_semantic_learning_language_languages,"['semantic', 'learning', 'language', 'languages', 'linguistic', 'classification', 'comprehension', 'semantics', 'lexical', 'words']","['Leveraging Contextual Sentences for Text Classification by Using a Neural Attention Model We explored several approaches to incorporate context information in the deep learning framework for text classification, including designing different attention mechanisms based on different neural network and extracting some additional features from text by traditional methods as the part of representation. We propose two kinds of classification algorithms: one is based on convolutional neural network fusing context information and the other is based on bidirectional long and short time memory network. We integrate the context information into the final feature representation by designing attention structures at sentence level and word level, which increases the diversity of feature information. Our experimental results on two datasets validate the advantages of the two models in terms of time efficiency and accuracy compared to the different models with fundamental AM architectures.', ""Language Processing Model Construction and Simulation Based on Hybrid CNN and LSTM Deep learning is the latest trend of machine learning and artificial intelligence research. As a new field with rapid development over the past decade, it has attracted more and more researchers' attention. Convolutional Neural Network (CNN) model is one of the most important classical structures in deep learning models, and its performance has been gradually improved in deep learning tasks in recent years. Convolutional neural networks have been widely used in image classification, target detection, semantic segmentation, and natural language processing because they can automatically learn the feature representation of sample data. Firstly, this paper analyzes the model structure of a typical convolutional neural network model to increase the network depth and width in order to improve its performance, analyzes the network structure that further improves the model performance by using the attention mechanism, and then summarizes and analyzes the current special model structure. In order to further improve the text language processing effect, a convolutional neural network model, Hybrid convolutional neural network (CNN), and Long Short-Term Memory (LSTM) based on the fusion of text features and language knowledge are proposed. The text features and language knowledge are integrated into the language processing model, and the accuracy of the text language processing model is improved by parameter optimization. Experimental results on data sets show that the accuracy of the proposed model reaches 93.0%, which is better than the reference model in the literature."", 'A word-building method based on neural network for text classification Text classification is a foundational task in many natural language processing applications. All traditional text classifiers take words as the basic units and conduct the pre-training process (like word2vec) to directly generate word vectors at the first step. However, none of them have considered the information contained in word structure which is proved to be helpful for text classification. In this paper, we propose a word-building method based on neural network model that can decompose a Chinese word to a sequence of radicals and learn structure information from these radical level features which is a key difference from the existing models. Then, the convolutional neural network is applied to extract structure information of words from radical sequence to generate a word vector, and the long short-term memory is applied to generate the sentence vector for the prediction purpose. The experimental results show that our model outperforms other existing models on Chinese dataset. Our model is also applicable to English as well where an English word can be decomposed down to character level, which demonstrates the excellent generalisation ability of our model. The experimental results have proved that our model also outperforms others on English dataset.']"
